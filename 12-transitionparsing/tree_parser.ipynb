{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tree_parser.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "mtBaxrYX7uKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b22d1f2c-430c-4530-808a-a964c44ace20"
      },
      "cell_type": "code",
      "source": [
        "!pip install dynet\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dynet in /usr/local/lib/python2.7/dist-packages (2.0.3)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from dynet) (1.14.5)\r\n",
            "Requirement already satisfied: cython in /usr/local/lib/python2.7/dist-packages (from dynet) (0.28.5)\n",
            "fatal: destination path 'nn4nlp-code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPwCvUKipLeK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import codecs\n",
        "import time\n",
        "import random\n",
        "import dynet as dy\n",
        "import numpy as np\n",
        "#from tree import Tree\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cMn-jsONpY4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _tokenize_sexpr(s):\n",
        "    tokker = re.compile(r\" +|[()]|[^ ()]+\")\n",
        "    toks = [t for t in [match.group(0) for match in tokker.finditer(s)] if t[0] != \" \"]\n",
        "    return toks\n",
        "\n",
        "def _within_bracket(toks):\n",
        "    label = next(toks)\n",
        "    children = []\n",
        "    for tok in toks:\n",
        "        if tok == \"(\":\n",
        "            children.append(_within_bracket(toks))\n",
        "        elif tok == \")\":\n",
        "            return Tree(label, children)\n",
        "        else: children.append(Tree(tok, None))\n",
        "    assert(False),list(toks)\n",
        "\n",
        "class Tree(object):\n",
        "    def __init__(self, label, children=None):\n",
        "        self.label = label\n",
        "        self.children = children\n",
        "\n",
        "    @staticmethod\n",
        "    def from_sexpr(string):\n",
        "        toks = iter(_tokenize_sexpr(string))\n",
        "        assert next(toks) == \"(\"\n",
        "        return _within_bracket(toks)\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.children is None: return self.label\n",
        "        return \"[%s %s]\" % (self.label, \" \".join([str(c) for c in self.children]))\n",
        "\n",
        "    def isleaf(self): return self.children==None\n",
        "\n",
        "    def leaves_iter(self):\n",
        "        if self.isleaf():\n",
        "            yield self\n",
        "        else:\n",
        "            for c in self.children:\n",
        "                for l in c.leaves_iter(): yield l\n",
        "\n",
        "    def leaves(self): return list(self.leaves_iter())\n",
        "\n",
        "    def nonterms_iter(self):\n",
        "        if not self.isleaf():\n",
        "            yield self\n",
        "            for c in self.children:\n",
        "                for n in c.nonterms_iter(): yield n\n",
        "        \n",
        "    def nonterms(self): return list(self.nonterms_iter())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO3uiL-77w8J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_dataset(filename):\n",
        "    return [Tree.from_sexpr(line.strip()) for line in codecs.open(filename,\"r\")]\n",
        "\n",
        "def get_vocabs(trees):\n",
        "    label_vocab = Counter()\n",
        "    word_vocab  = Counter()\n",
        "    for tree in trees:\n",
        "        label_vocab.update([n.label for n in tree.nonterms()])\n",
        "        word_vocab.update([l.label for l in tree.leaves()])\n",
        "    labels = [x for x,c in label_vocab.iteritems() if c > 0]\n",
        "    words  = [\"_UNK_\"] + [x for x,c in word_vocab.iteritems() if c > 0]\n",
        "    l2i = {l:i for i,l in enumerate(labels)}\n",
        "    w2i = {w:i for i,w in enumerate(words)}\n",
        "    return l2i, w2i, labels, words\n",
        "\n",
        "train = read_dataset(\"nn4nlp-code/data/parsing/trees/train.txt\")\n",
        "dev = read_dataset(\"nn4nlp-code/data/parsing/trees/dev.txt\")\n",
        "\n",
        "l2i, w2i, i2l, i2w = get_vocabs(train)\n",
        "ntags = len(l2i)\n",
        "nwords = len(w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "93pMfFTUA-le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "39ed10cb-656f-43c6-c4f4-0ff4def6af4c"
      },
      "cell_type": "code",
      "source": [
        "!head \"nn4nlp-code/data/parsing/trees/train.txt\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3 (2 (2 The) (2 Rock)) (4 (3 (2 is) (4 (2 destined) (2 (2 (2 (2 (2 to) (2 (2 be) (2 (2 the) (2 (2 21st) (2 (2 (2 Century) (2 's)) (2 (3 new) (2 (2 ``) (2 Conan)))))))) (2 '')) (2 and)) (3 (2 that) (3 (2 he) (3 (2 's) (3 (2 going) (3 (2 to) (4 (3 (2 make) (3 (3 (2 a) (3 splash)) (2 (2 even) (3 greater)))) (2 (2 than) (2 (2 (2 (2 (1 (2 Arnold) (2 Schwarzenegger)) (2 ,)) (2 (2 Jean-Claud) (2 (2 Van) (2 Damme)))) (2 or)) (2 (2 Steven) (2 Segal))))))))))))) (2 .)))\r\n",
            "(4 (4 (4 (2 The) (4 (3 gorgeously) (3 (2 elaborate) (2 continuation)))) (2 (2 (2 of) (2 ``)) (2 (2 The) (2 (2 (2 Lord) (2 (2 of) (2 (2 the) (2 Rings)))) (2 (2 '') (2 trilogy)))))) (2 (3 (2 (2 is) (2 (2 so) (2 huge))) (2 (2 that) (3 (2 (2 (2 a) (2 column)) (2 (2 of) (2 words))) (2 (2 (2 (2 can) (1 not)) (3 adequately)) (2 (2 describe) (2 (3 (2 (2 co-writer\\/director) (2 (2 Peter) (3 (2 Jackson) (2 's)))) (3 (2 expanded) (2 vision))) (2 (2 of) (2 (2 (2 J.R.R.) (2 (2 Tolkien) (2 's))) (2 Middle-earth))))))))) (2 .)))\r\n",
            "(3 (3 (2 (2 (2 (2 (2 Singer\\/composer) (2 (2 Bryan) (2 Adams))) (2 (2 contributes) (2 (2 (2 a) (2 slew)) (2 (2 of) (2 songs))))) (2 (2 --) (2 (2 (2 (2 a) (2 (2 few) (3 potential))) (2 (2 (2 hits) (2 ,)) (2 (2 (2 a) (2 few)) (1 (1 (2 more) (1 (2 simply) (2 intrusive))) (2 (2 to) (2 (2 the) (2 story))))))) (2 --)))) (2 but)) (3 (4 (2 the) (3 (2 whole) (2 package))) (2 (3 certainly) (3 (2 captures) (2 (1 (2 the) (2 (2 (2 intended) (2 (2 ,) (2 (2 er) (2 ,)))) (3 spirit))) (2 (2 of) (2 (2 the) (2 piece)))))))) (2 .))\r\n",
            "(2 (2 (2 You) (2 (2 'd) (2 (2 think) (2 (2 by) (2 now))))) (2 (2 America) (2 (2 (2 would) (1 (2 have) (2 (2 (2 had) (1 (2 enough) (2 (2 of) (2 (2 plucky) (2 (2 British) (1 eccentrics)))))) (4 (2 with) (4 (3 hearts) (3 (2 of) (3 gold))))))) (2 .))))\r\n",
            "(3 (2 Yet) (3 (2 (2 the) (2 act)) (3 (4 (3 (2 is) (3 (2 still) (4 charming))) (2 here)) (2 .))))\r\n",
            "(4 (2 (2 Whether) (2 (2 (2 (2 or) (1 not)) (3 (2 you) (2 (2 're) (3 (3 enlightened) (2 (2 by) (2 (2 any) (2 (2 of) (2 (2 Derrida) (2 's))))))))) (2 (2 lectures) (2 (2 on) (2 (2 ``) (2 (2 (2 (2 (2 (2 the) (2 other)) (2 '')) (2 and)) (2 ``)) (2 (2 the) (2 self)))))))) (3 (2 ,) (3 (2 '') (3 (2 Derrida) (3 (3 (2 is) (4 (2 an) (4 (4 (2 undeniably) (3 (4 (3 fascinating) (2 and)) (4 playful))) (2 fellow)))) (2 .))))))\r\n",
            "(4 (3 (2 (2 Just) (2 (2 the) (2 labour))) (3 (2 involved) (3 (2 in) (4 (2 creating) (3 (3 (2 the) (3 (3 layered) (2 richness))) (3 (2 of) (3 (2 (2 the) (2 imagery)) (2 (2 in) (3 (2 (2 this) (2 chiaroscuro)) (2 (2 of) (2 (2 (2 madness) (2 and)) (2 light)))))))))))) (3 (3 (2 is) (4 astonishing)) (2 .)))\r\n",
            "(3 (3 (2 Part) (3 (2 of) (4 (2 (2 the) (3 charm)) (2 (2 of) (2 (2 Satin) (2 Rouge)))))) (3 (3 (2 is) (3 (2 that) (3 (2 it) (2 (1 (2 avoids) (2 (2 the) (1 obvious))) (3 (2 with) (3 (3 (3 humour) (2 and)) (2 lightness))))))) (2 .)))\r\n",
            "(4 (2 (2 a) (2 (2 screenplay) (2 more))) (3 (4 ingeniously) (2 (2 constructed) (2 (2 (2 (2 than) (2 ``)) (2 Memento)) (2 '')))))\r\n",
            "(3 (2 ``) (3 (2 (2 Extreme) (2 Ops)) (3 (2 '') (4 (4 (3 exceeds) (2 expectations)) (2 .)))))\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mLQELyrPBibP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q24T23n3712q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Socher-style Tree RNN\n",
        "class TreeRNNBuilder(object):\n",
        "    def __init__(self, model, word_vocab, hdim):\n",
        "        self.W = model.add_parameters((hdim, 2*hdim))\n",
        "        self.E = model.add_lookup_parameters((len(word_vocab),hdim))\n",
        "        self.w2i = word_vocab\n",
        "\n",
        "    def expr_for_tree(self, tree):\n",
        "        if tree.isleaf():\n",
        "            return self.E[self.w2i.get(tree.label,0)]\n",
        "        if len(tree.children) == 1:\n",
        "            assert(tree.children[0].isleaf())\n",
        "            expr = self.expr_for_tree(tree.children[0])\n",
        "            return expr\n",
        "        assert(len(tree.children) == 2),tree.children[0]\n",
        "        e1 = self.expr_for_tree(tree.children[0])\n",
        "        e2 = self.expr_for_tree(tree.children[1])\n",
        "        W = dy.parameter(self.W)\n",
        "        expr = dy.tanh(W*dy.concatenate([e1,e2]))\n",
        "        return expr\n",
        "\n",
        "# Tai-style Tree LSTM\n",
        "class TreeLSTMBuilder(object):\n",
        "    def __init__(self, model, word_vocab, wdim, hdim):\n",
        "        self.WS = [model.add_parameters((hdim, wdim)) for _ in \"iou\"]\n",
        "        self.US = [model.add_parameters((hdim, 2*hdim)) for _ in \"iou\"]\n",
        "        self.UFS =[model.add_parameters((hdim, hdim)) for _ in \"ff\"]\n",
        "        self.BS = [model.add_parameters(hdim) for _ in \"iouf\"]\n",
        "        self.E = model.add_lookup_parameters((len(word_vocab),wdim))\n",
        "        self.w2i = word_vocab\n",
        "\n",
        "    def expr_for_tree(self, tree):\n",
        "        if tree.isleaf():\n",
        "            return self.E[self.w2i.get(tree.label,0)]\n",
        "        if len(tree.children) == 1:\n",
        "            assert(tree.children[0].isleaf())\n",
        "            emb = self.expr_for_tree(tree.children[0])\n",
        "            Wi,Wo,Wu   = [dy.parameter(w) for w in self.WS]\n",
        "            bi,bo,bu,_ = [dy.parameter(b) for b in self.BS]\n",
        "            i = dy.logistic(Wi*emb + bi)\n",
        "            o = dy.logistic(Wo*emb + bo)\n",
        "            u = dy.tanh(    Wu*emb + bu)\n",
        "            c = dy.cmult(i,u)\n",
        "            expr = dy.cmult(o,dy.tanh(c))\n",
        "            return expr\n",
        "        assert(len(tree.children) == 2),tree.children[0]\n",
        "        e1 = self.expr_for_tree(tree.children[0])\n",
        "        e2 = self.expr_for_tree(tree.children[1])\n",
        "        Ui,Uo,Uu = [dy.parameter(u) for u in self.US]\n",
        "        Uf1,Uf2 = [dy.parameter(u) for u in self.UFS]\n",
        "        bi,bo,bu,bf = [dy.parameter(b) for b in self.BS]\n",
        "        e = dy.concatenate([e1,e2])\n",
        "        i = dy.logistic(Ui*e + bi)\n",
        "        o = dy.logistic(Uo*e + bo)\n",
        "        f1 = dy.logistic(Uf1*e1 + bf)\n",
        "        f2 = dy.logistic(Uf2*e2 + bf)\n",
        "        u = dy.tanh(    Uu*e + bu)\n",
        "        c = dy.cmult(i,u) + dy.cmult(f1,e1) + dy.cmult(f2,e2)\n",
        "        h = dy.cmult(o,dy.tanh(c))\n",
        "        expr = h\n",
        "        return expr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDlSLbwt7NFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1673
        },
        "outputId": "2d340100-4b33-41ed-b071-8162fa40884d"
      },
      "cell_type": "code",
      "source": [
        "# Start DyNet and define trainer\n",
        "model = dy.Model()\n",
        "trainer = dy.AdamTrainer(model)\n",
        "\n",
        "# Define the model\n",
        "EMB_SIZE = 64\n",
        "HID_SIZE = 64\n",
        "# builder = TreeRNNBuilder(model, w2i, HID_SIZE)\n",
        "builder = TreeLSTMBuilder(model, w2i, HID_SIZE, EMB_SIZE)\n",
        "W_sm = model.add_parameters((ntags, HID_SIZE))        # Softmax weights\n",
        "b_sm = model.add_parameters((ntags))                  # Softmax bias\n",
        "\n",
        "# A function to calculate scores for one value\n",
        "def calc_scores(tree):\n",
        "  dy.renew_cg()\n",
        "  emb = builder.expr_for_tree(tree)\n",
        "  W_sm_exp = dy.parameter(W_sm)\n",
        "  b_sm_exp = dy.parameter(b_sm)\n",
        "  return W_sm_exp * emb + b_sm_exp\n",
        "\n",
        "for ITER in range(100):\n",
        "  # Perform training\n",
        "  random.shuffle(train)\n",
        "  train_loss = 0.0\n",
        "  start = time.time()\n",
        "  for tree in train:\n",
        "    my_loss = dy.hinge(calc_scores(tree), l2i[tree.label])\n",
        "    # my_loss = dy.pickneglogsoftmax(calc_scores(tree), l2i[tree.label])\n",
        "    train_loss += my_loss.value()\n",
        "    my_loss.backward()\n",
        "    trainer.update()\n",
        "  print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
        "  # Perform testing\n",
        "  test_correct = 0.0\n",
        "  for tree in dev:\n",
        "    scores = calc_scores(tree).npvalue()\n",
        "    predict = np.argmax(scores)\n",
        "    if predict == l2i[tree.label]:\n",
        "      test_correct += 1\n",
        "  print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0: train loss/sent=3.3289, time=20.18s\n",
            "iter 0: test acc=0.3279\n",
            "iter 1: train loss/sent=2.7242, time=19.45s\n",
            "iter 1: test acc=0.3733\n",
            "iter 2: train loss/sent=2.0649, time=19.78s\n",
            "iter 2: test acc=0.3678\n",
            "iter 3: train loss/sent=1.6239, time=19.75s\n",
            "iter 3: test acc=0.3697\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}