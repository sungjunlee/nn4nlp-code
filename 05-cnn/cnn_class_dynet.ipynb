{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-class-dynet.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "atRf8NdTq3lY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "dd8d22f5-4915-49ef-d97a-52f42ca2de08",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526972886877,
          "user_tz": -540,
          "elapsed": 8846,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install dynet\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dynet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/de/181a8380e9fdb89d9aa5838059336bb535503d5f2053e621438e69081407/dyNET-2.0.3-cp27-cp27mu-manylinux1_x86_64.whl (27.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 27.6MB 857kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from dynet) (1.14.3)\n",
            "Collecting cython (from dynet)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/d6/a097bd9913cc0fc974b968f5586d3f0609f46ca58b2aae3b8dfd51c1fe18/Cython-0.28.2-cp27-cp27mu-manylinux1_x86_64.whl (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 6.3MB/s \n",
            "\u001b[?25hInstalling collected packages: cython, dynet\n",
            "Successfully installed cython-0.28.2 dynet-2.0.3\n",
            "fatal: destination path 'nn4nlp-code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RFd0_jW2rAF2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "import random\n",
        "import dynet as dy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9XRE5l-rC-k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            tag, words = line.lower().strip().split(\" ||| \")\n",
        "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
        "\n",
        "# Read in the data\n",
        "train = list(read_dataset(\"nn4nlp-code/data/classes/train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"nn4nlp-code/data/classes/test.txt\"))\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhIk0rmgrFD8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Start DyNet and define trainer\n",
        "model = dy.Model()\n",
        "trainer = dy.AdamTrainer(model)\n",
        "\n",
        "# Define the model\n",
        "EMB_SIZE = 64\n",
        "W_emb = model.add_lookup_parameters((nwords, 1, 1, EMB_SIZE)) # Word embeddings\n",
        "WIN_SIZE = 3\n",
        "FILTER_SIZE = 64\n",
        "W_cnn = model.add_parameters((1, WIN_SIZE, EMB_SIZE, FILTER_SIZE)) # cnn weights\n",
        "b_cnn = model.add_parameters((FILTER_SIZE)) # cnn bias\n",
        "\n",
        "W_sm = model.add_parameters((ntags, FILTER_SIZE))          # Softmax weights\n",
        "b_sm = model.add_parameters((ntags))                      # Softmax bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ckfiOOeurH2e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def calc_scores(words):\n",
        "    dy.renew_cg()\n",
        "    W_cnn_express = dy.parameter(W_cnn)\n",
        "    b_cnn_express = dy.parameter(b_cnn)\n",
        "    W_sm_express = dy.parameter(W_sm)\n",
        "    b_sm_express = dy.parameter(b_sm)\n",
        "    if len(words) < WIN_SIZE:\n",
        "      words += [0] * (WIN_SIZE-len(words))\n",
        "\n",
        "    cnn_in = dy.concatenate([dy.lookup(W_emb, x) for x in words], d=1)\n",
        "    cnn_out = dy.conv2d_bias(cnn_in, W_cnn_express, b_cnn_express, stride=(1, 1), is_valid=False)\n",
        "    pool_out = dy.max_dim(cnn_out, d=1)\n",
        "    pool_out = dy.reshape(pool_out, (FILTER_SIZE,))\n",
        "    pool_out = dy.rectify(pool_out)\n",
        "    return W_sm_express * pool_out + b_sm_express"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMqQeXCRrJ9c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3617
        },
        "outputId": "cda32649-fc81-42c7-cfef-e00a771c0577",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526976617981,
          "user_tz": -540,
          "elapsed": 3093749,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for ITER in range(100):\n",
        "    # Perform training\n",
        "    random.shuffle(train)\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0.0\n",
        "    start = time.time()\n",
        "    for words, tag in train:\n",
        "        scores = calc_scores(words)\n",
        "        predict = np.argmax(scores.npvalue())\n",
        "        if predict == tag:\n",
        "            train_correct += 1\n",
        "\n",
        "        my_loss = dy.pickneglogsoftmax(scores, tag)\n",
        "        train_loss += my_loss.value()\n",
        "        my_loss.backward()\n",
        "        trainer.update()\n",
        "    print(\"iter %r: train loss/sent=%.4f, acc=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), train_correct/len(train), time.time()-start))\n",
        "    # Perform testing\n",
        "    test_correct = 0.0\n",
        "    for words, tag in dev:\n",
        "        scores = calc_scores(words).npvalue()\n",
        "        predict = np.argmax(scores)\n",
        "        if predict == tag:\n",
        "            test_correct += 1\n",
        "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0: train loss/sent=1.6019, acc=0.2983, time=29.13s\n",
            "iter 0: test acc=0.3439\n",
            "iter 1: train loss/sent=1.2562, acc=0.4945, time=29.20s\n",
            "iter 1: test acc=0.3593\n",
            "iter 2: train loss/sent=0.8432, acc=0.6857, time=29.63s\n",
            "iter 2: test acc=0.3643\n",
            "iter 3: train loss/sent=0.4574, acc=0.8406, time=29.07s\n",
            "iter 3: test acc=0.3697\n",
            "iter 4: train loss/sent=0.2109, acc=0.9329, time=29.09s\n",
            "iter 4: test acc=0.3448\n",
            "iter 5: train loss/sent=0.0857, acc=0.9760, time=29.20s\n",
            "iter 5: test acc=0.3457\n",
            "iter 6: train loss/sent=0.0309, acc=0.9915, time=29.79s\n",
            "iter 6: test acc=0.3570\n",
            "iter 7: train loss/sent=0.0131, acc=0.9966, time=29.06s\n",
            "iter 7: test acc=0.3611\n",
            "iter 8: train loss/sent=0.0088, acc=0.9979, time=29.09s\n",
            "iter 8: test acc=0.3710\n",
            "iter 9: train loss/sent=0.0046, acc=0.9986, time=29.08s\n",
            "iter 9: test acc=0.3615\n",
            "iter 10: train loss/sent=0.0060, acc=0.9984, time=29.42s\n",
            "iter 10: test acc=0.3552\n",
            "iter 11: train loss/sent=0.0036, acc=0.9991, time=29.06s\n",
            "iter 11: test acc=0.3484\n",
            "iter 12: train loss/sent=0.0030, acc=0.9991, time=29.22s\n",
            "iter 12: test acc=0.3557\n",
            "iter 13: train loss/sent=0.0023, acc=0.9996, time=29.20s\n",
            "iter 13: test acc=0.3593\n",
            "iter 14: train loss/sent=0.0045, acc=0.9989, time=29.02s\n",
            "iter 14: test acc=0.3507\n",
            "iter 15: train loss/sent=0.0042, acc=0.9985, time=28.97s\n",
            "iter 15: test acc=0.3371\n",
            "iter 16: train loss/sent=0.0039, acc=0.9987, time=29.04s\n",
            "iter 16: test acc=0.3624\n",
            "iter 17: train loss/sent=0.0024, acc=0.9992, time=29.17s\n",
            "iter 17: test acc=0.3271\n",
            "iter 18: train loss/sent=0.0065, acc=0.9985, time=29.13s\n",
            "iter 18: test acc=0.3525\n",
            "iter 19: train loss/sent=0.0042, acc=0.9981, time=29.06s\n",
            "iter 19: test acc=0.3602\n",
            "iter 20: train loss/sent=0.0028, acc=0.9988, time=29.00s\n",
            "iter 20: test acc=0.3317\n",
            "iter 21: train loss/sent=0.0031, acc=0.9992, time=29.19s\n",
            "iter 21: test acc=0.3471\n",
            "iter 22: train loss/sent=0.0041, acc=0.9991, time=29.02s\n",
            "iter 22: test acc=0.3416\n",
            "iter 23: train loss/sent=0.0025, acc=0.9989, time=28.99s\n",
            "iter 23: test acc=0.3516\n",
            "iter 24: train loss/sent=0.0066, acc=0.9974, time=28.94s\n",
            "iter 24: test acc=0.3330\n",
            "iter 25: train loss/sent=0.0025, acc=0.9993, time=29.03s\n",
            "iter 25: test acc=0.3434\n",
            "iter 26: train loss/sent=0.0040, acc=0.9986, time=29.04s\n",
            "iter 26: test acc=0.3448\n",
            "iter 27: train loss/sent=0.0039, acc=0.9982, time=29.31s\n",
            "iter 27: test acc=0.3484\n",
            "iter 28: train loss/sent=0.0034, acc=0.9985, time=29.23s\n",
            "iter 28: test acc=0.3588\n",
            "iter 29: train loss/sent=0.0050, acc=0.9984, time=29.26s\n",
            "iter 29: test acc=0.3190\n",
            "iter 30: train loss/sent=0.0050, acc=0.9981, time=29.02s\n",
            "iter 30: test acc=0.3480\n",
            "iter 31: train loss/sent=0.0045, acc=0.9981, time=29.17s\n",
            "iter 31: test acc=0.3416\n",
            "iter 32: train loss/sent=0.0030, acc=0.9989, time=29.33s\n",
            "iter 32: test acc=0.3357\n",
            "iter 33: train loss/sent=0.0040, acc=0.9991, time=29.46s\n",
            "iter 33: test acc=0.3538\n",
            "iter 34: train loss/sent=0.0061, acc=0.9981, time=29.18s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "iter 34: test acc=0.3462\n",
            "iter 35: train loss/sent=0.0028, acc=0.9995, time=29.29s\n",
            "iter 35: test acc=0.3566\n",
            "iter 36: train loss/sent=0.0031, acc=0.9988, time=29.26s\n",
            "iter 36: test acc=0.3511\n",
            "iter 37: train loss/sent=0.0027, acc=0.9992, time=29.31s\n",
            "iter 37: test acc=0.3688\n",
            "iter 38: train loss/sent=0.0031, acc=0.9992, time=29.94s\n",
            "iter 38: test acc=0.3584\n",
            "iter 39: train loss/sent=0.0032, acc=0.9988, time=37.57s\n",
            "iter 39: test acc=0.3457\n",
            "iter 40: train loss/sent=0.0040, acc=0.9989, time=29.17s\n",
            "iter 40: test acc=0.3584\n",
            "iter 41: train loss/sent=0.0033, acc=0.9991, time=29.37s\n",
            "iter 41: test acc=0.3593\n",
            "iter 42: train loss/sent=0.0024, acc=0.9991, time=29.00s\n",
            "iter 42: test acc=0.3471\n",
            "iter 43: train loss/sent=0.0058, acc=0.9980, time=29.17s\n",
            "iter 43: test acc=0.3480\n",
            "iter 44: train loss/sent=0.0023, acc=0.9989, time=29.06s\n",
            "iter 44: test acc=0.3502\n",
            "iter 45: train loss/sent=0.0028, acc=0.9992, time=29.35s\n",
            "iter 45: test acc=0.3724\n",
            "iter 46: train loss/sent=0.0068, acc=0.9977, time=29.07s\n",
            "iter 46: test acc=0.3588\n",
            "iter 47: train loss/sent=0.0069, acc=0.9977, time=29.34s\n",
            "iter 47: test acc=0.3507\n",
            "iter 48: train loss/sent=0.0073, acc=0.9981, time=29.20s\n",
            "iter 48: test acc=0.3452\n",
            "iter 49: train loss/sent=0.0059, acc=0.9974, time=29.47s\n",
            "iter 49: test acc=0.3439\n",
            "iter 50: train loss/sent=0.0040, acc=0.9988, time=29.05s\n",
            "iter 50: test acc=0.3502\n",
            "iter 51: train loss/sent=0.0039, acc=0.9985, time=29.14s\n",
            "iter 51: test acc=0.3520\n",
            "iter 52: train loss/sent=0.0068, acc=0.9982, time=29.14s\n",
            "iter 52: test acc=0.3258\n",
            "iter 53: train loss/sent=0.0039, acc=0.9985, time=29.33s\n",
            "iter 53: test acc=0.3466\n",
            "iter 54: train loss/sent=0.0061, acc=0.9985, time=28.99s\n",
            "iter 54: test acc=0.3344\n",
            "iter 55: train loss/sent=0.0041, acc=0.9987, time=29.15s\n",
            "iter 55: test acc=0.3548\n",
            "iter 56: train loss/sent=0.0056, acc=0.9984, time=29.17s\n",
            "iter 56: test acc=0.3412\n",
            "iter 57: train loss/sent=0.0044, acc=0.9986, time=29.40s\n",
            "iter 57: test acc=0.3502\n",
            "iter 58: train loss/sent=0.0052, acc=0.9984, time=29.02s\n",
            "iter 58: test acc=0.3439\n",
            "iter 59: train loss/sent=0.0062, acc=0.9981, time=29.21s\n",
            "iter 59: test acc=0.3475\n",
            "iter 60: train loss/sent=0.0036, acc=0.9987, time=29.20s\n",
            "iter 60: test acc=0.3457\n",
            "iter 61: train loss/sent=0.0043, acc=0.9991, time=29.62s\n",
            "iter 61: test acc=0.3543\n",
            "iter 62: train loss/sent=0.0101, acc=0.9979, time=29.01s\n",
            "iter 62: test acc=0.3439\n",
            "iter 63: train loss/sent=0.0067, acc=0.9978, time=29.27s\n",
            "iter 63: test acc=0.3566\n",
            "iter 64: train loss/sent=0.0041, acc=0.9986, time=29.16s\n",
            "iter 64: test acc=0.3434\n",
            "iter 65: train loss/sent=0.0085, acc=0.9979, time=29.08s\n",
            "iter 65: test acc=0.3552\n",
            "iter 66: train loss/sent=0.0055, acc=0.9982, time=29.02s\n",
            "iter 66: test acc=0.3529\n",
            "iter 67: train loss/sent=0.0024, acc=0.9988, time=29.16s\n",
            "iter 67: test acc=0.3805\n",
            "iter 68: train loss/sent=0.0034, acc=0.9991, time=29.15s\n",
            "iter 68: test acc=0.3570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "iter 69: train loss/sent=0.0046, acc=0.9987, time=29.22s\n",
            "iter 69: test acc=0.3480\n",
            "iter 70: train loss/sent=0.0060, acc=0.9982, time=29.20s\n",
            "iter 70: test acc=0.3416\n",
            "iter 71: train loss/sent=0.0087, acc=0.9973, time=29.34s\n",
            "iter 71: test acc=0.3452\n",
            "iter 72: train loss/sent=0.0084, acc=0.9984, time=29.15s\n",
            "iter 72: test acc=0.3421\n",
            "iter 73: train loss/sent=0.0056, acc=0.9987, time=29.00s\n",
            "iter 73: test acc=0.3597\n",
            "iter 74: train loss/sent=0.0049, acc=0.9985, time=29.10s\n",
            "iter 74: test acc=0.3516\n",
            "iter 75: train loss/sent=0.0064, acc=0.9980, time=29.01s\n",
            "iter 75: test acc=0.3385\n",
            "iter 76: train loss/sent=0.0067, acc=0.9984, time=29.27s\n",
            "iter 76: test acc=0.3566\n",
            "iter 77: train loss/sent=0.0067, acc=0.9984, time=28.95s\n",
            "iter 77: test acc=0.3570\n",
            "iter 78: train loss/sent=0.0078, acc=0.9985, time=29.18s\n",
            "iter 78: test acc=0.3471\n",
            "iter 79: train loss/sent=0.0047, acc=0.9985, time=29.01s\n",
            "iter 79: test acc=0.3443\n",
            "iter 80: train loss/sent=0.0059, acc=0.9979, time=29.69s\n",
            "iter 80: test acc=0.3615\n",
            "iter 81: train loss/sent=0.0039, acc=0.9989, time=28.96s\n",
            "iter 81: test acc=0.3489\n",
            "iter 82: train loss/sent=0.0108, acc=0.9979, time=29.23s\n",
            "iter 82: test acc=0.3448\n",
            "iter 83: train loss/sent=0.0061, acc=0.9984, time=29.14s\n",
            "iter 83: test acc=0.3412\n",
            "iter 84: train loss/sent=0.0054, acc=0.9986, time=29.28s\n",
            "iter 84: test acc=0.3452\n",
            "iter 85: train loss/sent=0.0059, acc=0.9985, time=29.02s\n",
            "iter 85: test acc=0.3335\n",
            "iter 86: train loss/sent=0.0054, acc=0.9987, time=29.14s\n",
            "iter 86: test acc=0.3692\n",
            "iter 87: train loss/sent=0.0084, acc=0.9978, time=29.12s\n",
            "iter 87: test acc=0.3652\n",
            "iter 88: train loss/sent=0.0053, acc=0.9988, time=29.63s\n",
            "iter 88: test acc=0.3557\n",
            "iter 89: train loss/sent=0.0090, acc=0.9980, time=29.27s\n",
            "iter 89: test acc=0.3443\n",
            "iter 90: train loss/sent=0.0073, acc=0.9985, time=29.83s\n",
            "iter 90: test acc=0.3575\n",
            "iter 91: train loss/sent=0.0043, acc=0.9985, time=29.31s\n",
            "iter 91: test acc=0.3557\n",
            "iter 92: train loss/sent=0.0035, acc=0.9987, time=29.57s\n",
            "iter 92: test acc=0.3462\n",
            "iter 93: train loss/sent=0.0049, acc=0.9985, time=29.23s\n",
            "iter 93: test acc=0.3457\n",
            "iter 94: train loss/sent=0.0046, acc=0.9988, time=29.87s\n",
            "iter 94: test acc=0.3507\n",
            "iter 95: train loss/sent=0.0047, acc=0.9991, time=29.36s\n",
            "iter 95: test acc=0.3692\n",
            "iter 96: train loss/sent=0.0066, acc=0.9986, time=29.43s\n",
            "iter 96: test acc=0.3507\n",
            "iter 97: train loss/sent=0.0043, acc=0.9986, time=29.73s\n",
            "iter 97: test acc=0.3534\n",
            "iter 98: train loss/sent=0.0022, acc=0.9993, time=29.40s\n",
            "iter 98: test acc=0.3443\n",
            "iter 99: train loss/sent=0.0025, acc=0.9993, time=29.57s\n",
            "iter 99: test acc=0.3534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PmSPKZ7rLue",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}