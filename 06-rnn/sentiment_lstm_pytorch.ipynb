{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-lstm-pytorch.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lMH16s0Ic6mD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2fb0608b-745c-4e56-d4a6-f5b88d3d91db",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527779027558,
          "user_tz": -540,
          "elapsed": 3719,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "fatal: destination path 'nn4nlp-code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Athiy6-ec__S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaCfHYbhdFj_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"<unk>\"]\n",
        "\n",
        "\n",
        "def read_dataset(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            tag, words = line.lower().strip().split(\" ||| \")\n",
        "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
        "\n",
        "\n",
        "# Read in the data\n",
        "train = list(read_dataset(\"nn4nlp-code/data/classes/train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"nn4nlp-code/data/classes/test.txt\"))\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyeVN31YdHMc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_batch(source, i):\n",
        "  seq_len = batch_size\n",
        "  data = source[i*batch_size:min((i+1)*batch_size, len(source))]\n",
        "  \n",
        "  inputs, targets = zip(*data)\n",
        "  \n",
        "  max_len = max([len(x) for x in inputs])\n",
        "  inputs = torch.stack([F.pad(torch.LongTensor(e), (max_len - len(e), 0)) for e in inputs], 0)\n",
        "  targets = torch.LongTensor(targets)\n",
        "  return inputs.cuda(), targets.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-6fePCUgrLl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SentimentModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
        "    super(SentimentModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "    self.linear = nn.Linear(hidden_dim*2, num_class)\n",
        "    \n",
        "  def init_hidden(self, batch_size):\n",
        "    if torch.cuda.is_available():\n",
        "      return (torch.zeros(2, batch_size, self.hidden_dim).cuda(), torch.zeros(2, batch_size, self.hidden_dim).cuda())\n",
        "    else:\n",
        "      return (torch.zeros(2, batch_size, self.hidden_dim), torch.zeros(2, batch_size, self.hidden_dim))\n",
        "    \n",
        "  def forward(self, sent):\n",
        "    batch_size, seq_len = sent.shape\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "    x = self.embeddings(sent).transpose(0,1)\n",
        "    lstm_out, hidden = self.lstm(x, hidden)\n",
        "    return self.linear(lstm_out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_dwArSDuag_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecb9afa4-e806-42ad-e344-e09ac04c79e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527779030638,
          "user_tz": -540,
          "elapsed": 428,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "jcKuxSPgl3pv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "batch_size = 64\n",
        "\n",
        "model = SentimentModel(nwords, EMBED_DIM, HIDDEN_DIM, ntags).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oh1Wna_hmIAz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bT1jh1EqiqV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_accuracy(truth, pred):\n",
        "  assert len(truth) == len(pred)\n",
        "  right = 0\n",
        "  for i in range(len(truth)):\n",
        "    if truth[i].cpu().numpy() == pred[i]:\n",
        "      right += 1.0\n",
        "  return right / len(truth)\n",
        "\n",
        "def evaluate(model, loss_function):\n",
        "  model.eval()\n",
        "  avg_loss = 0.0\n",
        "  truth_res = []\n",
        "  pred_res = []\n",
        "  for ix in range(len(dev) // batch_size):\n",
        "    sent, label = get_batch(dev, ix)\n",
        "#     label.data.sub_(1)\n",
        "    truth_res += list(label.data)\n",
        "    pred = model(sent)\n",
        "    pred_label = pred.data.max(1)[1].cpu().long().numpy()\n",
        "    pred_res += [x for x in pred_label]\n",
        "    loss = loss_function(pred, label)\n",
        "    avg_loss += loss.data[0]\n",
        "  avg_loss /= len(dev)\n",
        "  acc = get_accuracy(truth_res, pred_res)\n",
        "  print('eval: loss %.4f acc %.2f' % (avg_loss, acc*100))\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRMIPgvbmLOG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "c2a25322-3af4-4e60-be3a-c2cca792af5c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527779311516,
          "user_tz": -540,
          "elapsed": 31662,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch_i in range(10):\n",
        "  model.train()\n",
        "  total_loss = 0.\n",
        "  for ix in range(len(train) // batch_size):\n",
        "    model.zero_grad()\n",
        "\n",
        "    inputs, targets = get_batch(train, ix)\n",
        "    logit = model(inputs)\n",
        "    loss = criterion(logit, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(\"Epoch: {} | train loss/sent: {}\".format(epoch_i, total_loss / batch_size / (len(train) // batch_size)))\n",
        "  \n",
        "  evaluate(model, criterion)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | train loss/sent: 0.018923526839878326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval: loss 0.0281 acc 29.00\n",
            "Epoch: 1 | train loss/sent: 0.017219470281686102\n",
            "eval: loss 0.0288 acc 29.69\n",
            "Epoch: 2 | train loss/sent: 0.015084911536957537\n",
            "eval: loss 0.0302 acc 30.51\n",
            "Epoch: 3 | train loss/sent: 0.01301752532923356\n",
            "eval: loss 0.0317 acc 30.61\n",
            "Epoch: 4 | train loss/sent: 0.011400441989246616\n",
            "eval: loss 0.0331 acc 30.10\n",
            "Epoch: 5 | train loss/sent: 0.00981439536269334\n",
            "eval: loss 0.0349 acc 30.01\n",
            "Epoch: 6 | train loss/sent: 0.008510743148792955\n",
            "eval: loss 0.0368 acc 29.92\n",
            "Epoch: 7 | train loss/sent: 0.007502611085800524\n",
            "eval: loss 0.0388 acc 28.54\n",
            "Epoch: 8 | train loss/sent: 0.006587495701737646\n",
            "eval: loss 0.0400 acc 29.27\n",
            "Epoch: 9 | train loss/sent: 0.005823535296743862\n",
            "eval: loss 0.0408 acc 29.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z-qgqOM7oePd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}