{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm-lstm-pytorch.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nnxIkx38IL8n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5b5b14d6-875d-4415-e944-2a6359e8afc7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527774096247,
          "user_tz": -540,
          "elapsed": 3930,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "fatal: destination path 'nn4nlp-code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zvQW-cY_IM8b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mck_AJYpISzF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# format of files: each line is \"word1 word2 ...\"\n",
        "train_file = \"nn4nlp-code/data/ptb/train.txt\"\n",
        "test_file = \"nn4nlp-code/data/ptb/valid.txt\"\n",
        "\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "\n",
        "\n",
        "def read(fname):\n",
        "    \"\"\"\n",
        "    Read a file where each line is of the form \"word1 word2 ...\"\n",
        "    Yields lists of the form [word1, word2, ...]\n",
        "    \"\"\"\n",
        "    with open(fname, \"r\") as fh:\n",
        "        for line in fh:\n",
        "            sent = [w2i[x] for x in line.strip().split()]\n",
        "            sent.append(w2i[\"<s>\"])\n",
        "            yield sent\n",
        "\n",
        "\n",
        "train = list(read(train_file))\n",
        "nwords = len(w2i)\n",
        "test = list(read(test_file))\n",
        "S = w2i[\"<s>\"]\n",
        "assert (nwords == len(w2i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCOyUKbAP_hJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def batchify(data, bsz):\n",
        "  nbatch = data.size(0) // bsz\n",
        "  data = data.narrow(0, 0, nbatch * bsz)\n",
        "  data = data.view(bsz, -1).t().contiguous()\n",
        "  return data.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQdLt0QvRIR5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f865f1a4-4a1e-4b91-a150-faa584cbd2f3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527774098897,
          "user_tz": -540,
          "elapsed": 517,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "bptt_size = 64\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_flatten = torch.LongTensor(list(itertools.chain.from_iterable(train)))\n",
        "test_flatten = torch.LongTensor(list(itertools.chain.from_iterable(test)))\n",
        "\n",
        "train_data = batchify(train_flatten, batch_size)\n",
        "test_data = batchify(test_flatten, batch_size)\n",
        "\n",
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29049, 32]), torch.Size([2305, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "dqhxtsNrIXCh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  def __init__(self, nwords, emb_size, hidden_size):\n",
        "    super(LanguageModel, self).__init__()\n",
        "    self.nwords = nwords\n",
        "    self.emb_size = emb_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.encoder = nn.Embedding(nwords, emb_size)\n",
        "    self.rnn = nn.LSTM(emb_size, hidden_size)\n",
        "    self.decoder = nn.Linear(hidden_size, nwords)\n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "    emb = self.encoder(x)\n",
        "    output, hidden = self.rnn(emb, hidden)\n",
        "    decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
        "    return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbQHOXmdJYcE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EMBED_SIZE = 64\n",
        "HIDDEN_SIZE = 128\n",
        "log_interval = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4BCfhhRJHCH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = LanguageModel(nwords, EMBED_SIZE, HIDDEN_SIZE).to(device)\n",
        "trainer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb5VRgU2U13U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def repackage_hidden(h):\n",
        "  if isinstance(h, torch.Tensor):\n",
        "    return h.detach()\n",
        "  else:\n",
        "    return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def get_batch(source, i):\n",
        "  seq_len = min(bptt_size, len(source) - 1 - i)\n",
        "  data = source[i:i+seq_len]\n",
        "  target = source[i+1:i+1+seq_len].view(-1)\n",
        "  return data, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DrK4shtvTI2P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss = 0.\n",
        "  start_time = time.time()\n",
        "  hidden = (torch.zeros(1, batch_size, HIDDEN_SIZE).to(device), torch.zeros(1, batch_size, HIDDEN_SIZE).to(device))\n",
        "\n",
        "  for batch_ix, i in enumerate(range(0, train_data.size(0) - 1, bptt_size)):\n",
        "    data, targets = get_batch(train_data, i)\n",
        "    hidden = repackage_hidden(hidden)\n",
        "    model.zero_grad()\n",
        "    output, hidden = model(data, hidden)\n",
        "    loss = criterion(output.view(-1, nwords), targets)\n",
        "    loss.backward()\n",
        "\n",
        "    trainer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    if batch_ix % log_interval == 0 and batch_ix > 0:\n",
        "      cur_loss = total_loss / log_interval\n",
        "      elapsed = time.time() - start_time\n",
        "      print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n",
        "              'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "          epoch, batch_ix, len(train_data) // bptt_size, \n",
        "          elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "      total_loss = 0\n",
        "      start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcyRUCBCatMd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def evaluate(data_source):\n",
        "  model.eval()\n",
        "  total_loss = 0.\n",
        "  hidden = (torch.zeros(1, batch_size, HIDDEN_SIZE).to(device), torch.zeros(1, batch_size, HIDDEN_SIZE).to(device))\n",
        "  with torch.no_grad():\n",
        "    for i in range(0, data_source.size(0) - 1, bptt_size):\n",
        "      data, targets = get_batch(data_source, i)\n",
        "      output, hidden = model(data, hidden)\n",
        "      output_flat = output.view(-1, nwords)\n",
        "      total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "      hidden = repackage_hidden(hidden)\n",
        "  \n",
        "  return total_loss / len(data_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REx3l4YvUUjO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 9017
        },
        "outputId": "18798e41-974a-4387-e38c-92f9941790d3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527775627568,
          "user_tz": -540,
          "elapsed": 1318390,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "  epoch_start_time = time.time()\n",
        "  train()\n",
        "  val_loss = evaluate(test_data)\n",
        "  print('-' * 89)\n",
        "  print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "  print('-' * 89)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   0 |   200/  453 batches | ms/batch 29.06 | loss  5.50 | ppl   244.28\n",
            "| epoch   0 |   400/  453 batches | ms/batch 28.16 | loss  5.35 | ppl   211.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   0 | time: 13.32s | valid loss  5.43 | valid ppl   228.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   1 |   200/  453 batches | ms/batch 28.26 | loss  5.36 | ppl   211.96\n",
            "| epoch   1 |   400/  453 batches | ms/batch 28.19 | loss  5.23 | ppl   185.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 13.18s | valid loss  5.35 | valid ppl   210.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/  453 batches | ms/batch 28.30 | loss  5.24 | ppl   189.32\n",
            "| epoch   2 |   400/  453 batches | ms/batch 28.11 | loss  5.12 | ppl   167.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 13.16s | valid loss  5.29 | valid ppl   197.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/  453 batches | ms/batch 28.36 | loss  5.15 | ppl   172.17\n",
            "| epoch   3 |   400/  453 batches | ms/batch 28.21 | loss  5.03 | ppl   153.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 13.20s | valid loss  5.24 | valid ppl   188.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   200/  453 batches | ms/batch 28.35 | loss  5.07 | ppl   158.53\n",
            "| epoch   4 |   400/  453 batches | ms/batch 28.23 | loss  4.95 | ppl   141.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 13.20s | valid loss  5.20 | valid ppl   180.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   200/  453 batches | ms/batch 28.31 | loss  4.99 | ppl   147.33\n",
            "| epoch   5 |   400/  453 batches | ms/batch 28.18 | loss  4.88 | ppl   132.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 13.18s | valid loss  5.16 | valid ppl   174.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   200/  453 batches | ms/batch 28.26 | loss  4.93 | ppl   138.00\n",
            "| epoch   6 |   400/  453 batches | ms/batch 28.19 | loss  4.82 | ppl   123.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 13.16s | valid loss  5.14 | valid ppl   170.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   200/  453 batches | ms/batch 28.28 | loss  4.87 | ppl   130.13\n",
            "| epoch   7 |   400/  453 batches | ms/batch 28.18 | loss  4.76 | ppl   117.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 13.18s | valid loss  5.12 | valid ppl   166.67\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   200/  453 batches | ms/batch 28.41 | loss  4.82 | ppl   123.38\n",
            "| epoch   8 |   400/  453 batches | ms/batch 28.19 | loss  4.71 | ppl   111.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 13.20s | valid loss  5.10 | valid ppl   163.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   200/  453 batches | ms/batch 28.34 | loss  4.77 | ppl   117.51\n",
            "| epoch   9 |   400/  453 batches | ms/batch 28.18 | loss  4.66 | ppl   106.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 13.18s | valid loss  5.09 | valid ppl   161.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   200/  453 batches | ms/batch 28.30 | loss  4.72 | ppl   112.31\n",
            "| epoch  10 |   400/  453 batches | ms/batch 28.16 | loss  4.62 | ppl   101.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 13.16s | valid loss  5.08 | valid ppl   160.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |   200/  453 batches | ms/batch 28.29 | loss  4.68 | ppl   107.68\n",
            "| epoch  11 |   400/  453 batches | ms/batch 28.20 | loss  4.58 | ppl    97.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 13.17s | valid loss  5.07 | valid ppl   159.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |   200/  453 batches | ms/batch 28.30 | loss  4.64 | ppl   103.50\n",
            "| epoch  12 |   400/  453 batches | ms/batch 28.11 | loss  4.54 | ppl    93.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 13.15s | valid loss  5.06 | valid ppl   158.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |   200/  453 batches | ms/batch 28.30 | loss  4.60 | ppl    99.74\n",
            "| epoch  13 |   400/  453 batches | ms/batch 28.21 | loss  4.50 | ppl    90.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 13.18s | valid loss  5.06 | valid ppl   157.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |   200/  453 batches | ms/batch 28.25 | loss  4.57 | ppl    96.26\n",
            "| epoch  14 |   400/  453 batches | ms/batch 28.09 | loss  4.47 | ppl    87.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 13.14s | valid loss  5.06 | valid ppl   157.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |   200/  453 batches | ms/batch 28.18 | loss  4.53 | ppl    93.09\n",
            "| epoch  15 |   400/  453 batches | ms/batch 28.07 | loss  4.44 | ppl    84.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 13.13s | valid loss  5.06 | valid ppl   157.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |   200/  453 batches | ms/batch 28.31 | loss  4.50 | ppl    90.17\n",
            "| epoch  16 |   400/  453 batches | ms/batch 28.23 | loss  4.41 | ppl    81.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 13.19s | valid loss  5.06 | valid ppl   157.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |   200/  453 batches | ms/batch 28.38 | loss  4.47 | ppl    87.47\n",
            "| epoch  17 |   400/  453 batches | ms/batch 28.28 | loss  4.38 | ppl    79.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 13.21s | valid loss  5.06 | valid ppl   157.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |   200/  453 batches | ms/batch 28.29 | loss  4.44 | ppl    84.97\n",
            "| epoch  18 |   400/  453 batches | ms/batch 28.08 | loss  4.35 | ppl    77.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 13.14s | valid loss  5.06 | valid ppl   157.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |   200/  453 batches | ms/batch 28.17 | loss  4.41 | ppl    82.63\n",
            "| epoch  19 |   400/  453 batches | ms/batch 28.14 | loss  4.32 | ppl    75.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 13.13s | valid loss  5.07 | valid ppl   158.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |   200/  453 batches | ms/batch 28.24 | loss  4.39 | ppl    80.46\n",
            "| epoch  20 |   400/  453 batches | ms/batch 28.16 | loss  4.29 | ppl    73.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 13.15s | valid loss  5.07 | valid ppl   159.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |   200/  453 batches | ms/batch 28.28 | loss  4.36 | ppl    78.42\n",
            "| epoch  21 |   400/  453 batches | ms/batch 28.17 | loss  4.27 | ppl    71.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 13.16s | valid loss  5.08 | valid ppl   160.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |   200/  453 batches | ms/batch 28.30 | loss  4.34 | ppl    76.50\n",
            "| epoch  22 |   400/  453 batches | ms/batch 28.11 | loss  4.24 | ppl    69.67\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 13.15s | valid loss  5.08 | valid ppl   161.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |   200/  453 batches | ms/batch 28.19 | loss  4.31 | ppl    74.69\n",
            "| epoch  23 |   400/  453 batches | ms/batch 28.08 | loss  4.22 | ppl    68.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 13.12s | valid loss  5.09 | valid ppl   162.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |   200/  453 batches | ms/batch 28.23 | loss  4.29 | ppl    72.99\n",
            "| epoch  24 |   400/  453 batches | ms/batch 28.10 | loss  4.20 | ppl    66.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 13.13s | valid loss  5.10 | valid ppl   163.68\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  25 |   200/  453 batches | ms/batch 28.29 | loss  4.27 | ppl    71.39\n",
            "| epoch  25 |   400/  453 batches | ms/batch 28.04 | loss  4.18 | ppl    65.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 13.14s | valid loss  5.11 | valid ppl   164.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |   200/  453 batches | ms/batch 28.18 | loss  4.25 | ppl    69.87\n",
            "| epoch  26 |   400/  453 batches | ms/batch 28.04 | loss  4.15 | ppl    63.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 13.11s | valid loss  5.11 | valid ppl   166.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |   200/  453 batches | ms/batch 28.21 | loss  4.23 | ppl    68.42\n",
            "| epoch  27 |   400/  453 batches | ms/batch 28.09 | loss  4.13 | ppl    62.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 13.13s | valid loss  5.12 | valid ppl   167.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |   200/  453 batches | ms/batch 28.14 | loss  4.21 | ppl    67.05\n",
            "| epoch  28 |   400/  453 batches | ms/batch 27.98 | loss  4.11 | ppl    61.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 13.09s | valid loss  5.13 | valid ppl   169.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |   200/  453 batches | ms/batch 28.17 | loss  4.19 | ppl    65.75\n",
            "| epoch  29 |   400/  453 batches | ms/batch 27.97 | loss  4.10 | ppl    60.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 13.09s | valid loss  5.14 | valid ppl   171.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |   200/  453 batches | ms/batch 28.21 | loss  4.17 | ppl    64.52\n",
            "| epoch  30 |   400/  453 batches | ms/batch 27.92 | loss  4.08 | ppl    58.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 13.09s | valid loss  5.15 | valid ppl   172.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |   200/  453 batches | ms/batch 28.16 | loss  4.15 | ppl    63.33\n",
            "| epoch  31 |   400/  453 batches | ms/batch 28.03 | loss  4.06 | ppl    57.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 13.10s | valid loss  5.16 | valid ppl   174.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |   200/  453 batches | ms/batch 28.11 | loss  4.13 | ppl    62.20\n",
            "| epoch  32 |   400/  453 batches | ms/batch 28.01 | loss  4.04 | ppl    56.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 13.08s | valid loss  5.17 | valid ppl   176.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |   200/  453 batches | ms/batch 28.18 | loss  4.11 | ppl    61.14\n",
            "| epoch  33 |   400/  453 batches | ms/batch 28.00 | loss  4.02 | ppl    55.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 13.09s | valid loss  5.18 | valid ppl   178.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |   200/  453 batches | ms/batch 28.13 | loss  4.10 | ppl    60.10\n",
            "| epoch  34 |   400/  453 batches | ms/batch 27.98 | loss  4.01 | ppl    55.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 13.07s | valid loss  5.19 | valid ppl   180.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |   200/  453 batches | ms/batch 28.02 | loss  4.08 | ppl    59.13\n",
            "| epoch  35 |   400/  453 batches | ms/batch 27.87 | loss  3.99 | ppl    54.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 13.04s | valid loss  5.21 | valid ppl   182.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |   200/  453 batches | ms/batch 28.07 | loss  4.06 | ppl    58.21\n",
            "| epoch  36 |   400/  453 batches | ms/batch 27.90 | loss  3.98 | ppl    53.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 13.05s | valid loss  5.22 | valid ppl   184.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |   200/  453 batches | ms/batch 28.00 | loss  4.05 | ppl    57.32\n",
            "| epoch  37 |   400/  453 batches | ms/batch 27.86 | loss  3.96 | ppl    52.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 13.01s | valid loss  5.23 | valid ppl   186.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |   200/  453 batches | ms/batch 28.02 | loss  4.03 | ppl    56.45\n",
            "| epoch  38 |   400/  453 batches | ms/batch 27.88 | loss  3.95 | ppl    51.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 13.03s | valid loss  5.24 | valid ppl   188.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |   200/  453 batches | ms/batch 28.08 | loss  4.02 | ppl    55.60\n",
            "| epoch  39 |   400/  453 batches | ms/batch 27.94 | loss  3.93 | ppl    50.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 13.06s | valid loss  5.25 | valid ppl   190.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |   200/  453 batches | ms/batch 28.10 | loss  4.00 | ppl    54.80\n",
            "| epoch  40 |   400/  453 batches | ms/batch 27.98 | loss  3.92 | ppl    50.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 13.07s | valid loss  5.26 | valid ppl   192.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  41 |   200/  453 batches | ms/batch 28.09 | loss  3.99 | ppl    54.04\n",
            "| epoch  41 |   400/  453 batches | ms/batch 28.05 | loss  3.90 | ppl    49.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 13.10s | valid loss  5.27 | valid ppl   195.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |   200/  453 batches | ms/batch 28.19 | loss  3.98 | ppl    53.30\n",
            "| epoch  42 |   400/  453 batches | ms/batch 27.96 | loss  3.89 | ppl    48.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 13.09s | valid loss  5.29 | valid ppl   197.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |   200/  453 batches | ms/batch 28.10 | loss  3.96 | ppl    52.61\n",
            "| epoch  43 |   400/  453 batches | ms/batch 28.03 | loss  3.88 | ppl    48.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 13.11s | valid loss  5.30 | valid ppl   199.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |   200/  453 batches | ms/batch 28.09 | loss  3.95 | ppl    51.94\n",
            "| epoch  44 |   400/  453 batches | ms/batch 27.96 | loss  3.86 | ppl    47.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 13.08s | valid loss  5.31 | valid ppl   202.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |   200/  453 batches | ms/batch 28.23 | loss  3.94 | ppl    51.29\n",
            "| epoch  45 |   400/  453 batches | ms/batch 27.98 | loss  3.85 | ppl    46.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 13.10s | valid loss  5.32 | valid ppl   204.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |   200/  453 batches | ms/batch 28.08 | loss  3.93 | ppl    50.66\n",
            "| epoch  46 |   400/  453 batches | ms/batch 27.90 | loss  3.84 | ppl    46.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 13.04s | valid loss  5.34 | valid ppl   207.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |   200/  453 batches | ms/batch 28.06 | loss  3.91 | ppl    50.04\n",
            "| epoch  47 |   400/  453 batches | ms/batch 27.90 | loss  3.83 | ppl    45.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 13.05s | valid loss  5.35 | valid ppl   210.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |   200/  453 batches | ms/batch 28.18 | loss  3.90 | ppl    49.45\n",
            "| epoch  48 |   400/  453 batches | ms/batch 28.00 | loss  3.81 | ppl    45.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 13.09s | valid loss  5.36 | valid ppl   212.74\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |   200/  453 batches | ms/batch 28.08 | loss  3.89 | ppl    48.89\n",
            "| epoch  49 |   400/  453 batches | ms/batch 28.06 | loss  3.80 | ppl    44.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 13.10s | valid loss  5.37 | valid ppl   215.22\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  50 |   200/  453 batches | ms/batch 28.19 | loss  3.88 | ppl    48.34\n",
            "| epoch  50 |   400/  453 batches | ms/batch 28.01 | loss  3.79 | ppl    44.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 13.10s | valid loss  5.38 | valid ppl   217.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  51 |   200/  453 batches | ms/batch 28.06 | loss  3.87 | ppl    47.79\n",
            "| epoch  51 |   400/  453 batches | ms/batch 28.09 | loss  3.78 | ppl    43.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 13.09s | valid loss  5.39 | valid ppl   220.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |   200/  453 batches | ms/batch 28.09 | loss  3.86 | ppl    47.27\n",
            "| epoch  52 |   400/  453 batches | ms/batch 27.94 | loss  3.77 | ppl    43.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 13.06s | valid loss  5.41 | valid ppl   222.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |   200/  453 batches | ms/batch 28.13 | loss  3.84 | ppl    46.74\n",
            "| epoch  53 |   400/  453 batches | ms/batch 27.96 | loss  3.76 | ppl    42.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 13.08s | valid loss  5.42 | valid ppl   225.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |   200/  453 batches | ms/batch 28.43 | loss  3.83 | ppl    46.23\n",
            "| epoch  54 |   400/  453 batches | ms/batch 28.26 | loss  3.75 | ppl    42.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 13.24s | valid loss  5.43 | valid ppl   228.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |   200/  453 batches | ms/batch 28.45 | loss  3.82 | ppl    45.71\n",
            "| epoch  55 |   400/  453 batches | ms/batch 28.18 | loss  3.74 | ppl    41.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 13.20s | valid loss  5.44 | valid ppl   231.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |   200/  453 batches | ms/batch 28.31 | loss  3.81 | ppl    45.22\n",
            "| epoch  56 |   400/  453 batches | ms/batch 28.16 | loss  3.73 | ppl    41.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 13.17s | valid loss  5.46 | valid ppl   234.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |   200/  453 batches | ms/batch 28.26 | loss  3.80 | ppl    44.74\n",
            "| epoch  57 |   400/  453 batches | ms/batch 28.13 | loss  3.72 | ppl    41.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 13.15s | valid loss  5.47 | valid ppl   237.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |   200/  453 batches | ms/batch 28.26 | loss  3.79 | ppl    44.28\n",
            "| epoch  58 |   400/  453 batches | ms/batch 28.13 | loss  3.71 | ppl    40.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 13.15s | valid loss  5.48 | valid ppl   240.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |   200/  453 batches | ms/batch 28.26 | loss  3.78 | ppl    43.91\n",
            "| epoch  59 |   400/  453 batches | ms/batch 28.11 | loss  3.70 | ppl    40.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 13.15s | valid loss  5.49 | valid ppl   243.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |   200/  453 batches | ms/batch 28.26 | loss  3.77 | ppl    43.42\n",
            "| epoch  60 |   400/  453 batches | ms/batch 28.11 | loss  3.69 | ppl    40.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 13.15s | valid loss  5.51 | valid ppl   246.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  61 |   200/  453 batches | ms/batch 28.28 | loss  3.76 | ppl    42.97\n",
            "| epoch  61 |   400/  453 batches | ms/batch 28.07 | loss  3.68 | ppl    39.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time: 13.14s | valid loss  5.52 | valid ppl   249.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |   200/  453 batches | ms/batch 28.20 | loss  3.75 | ppl    42.55\n",
            "| epoch  62 |   400/  453 batches | ms/batch 28.08 | loss  3.67 | ppl    39.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time: 13.14s | valid loss  5.53 | valid ppl   252.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |   200/  453 batches | ms/batch 28.25 | loss  3.74 | ppl    42.15\n",
            "| epoch  63 |   400/  453 batches | ms/batch 28.10 | loss  3.66 | ppl    38.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time: 13.14s | valid loss  5.54 | valid ppl   255.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |   200/  453 batches | ms/batch 28.25 | loss  3.73 | ppl    41.78\n",
            "| epoch  64 |   400/  453 batches | ms/batch 28.12 | loss  3.65 | ppl    38.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time: 13.15s | valid loss  5.56 | valid ppl   258.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |   200/  453 batches | ms/batch 28.30 | loss  3.72 | ppl    41.39\n",
            "| epoch  65 |   400/  453 batches | ms/batch 28.14 | loss  3.65 | ppl    38.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time: 13.15s | valid loss  5.57 | valid ppl   261.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |   200/  453 batches | ms/batch 28.21 | loss  3.71 | ppl    41.02\n",
            "| epoch  66 |   400/  453 batches | ms/batch 28.02 | loss  3.64 | ppl    37.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time: 13.11s | valid loss  5.58 | valid ppl   264.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |   200/  453 batches | ms/batch 28.19 | loss  3.70 | ppl    40.65\n",
            "| epoch  67 |   400/  453 batches | ms/batch 28.10 | loss  3.63 | ppl    37.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time: 13.12s | valid loss  5.59 | valid ppl   268.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |   200/  453 batches | ms/batch 28.21 | loss  3.70 | ppl    40.29\n",
            "| epoch  68 |   400/  453 batches | ms/batch 28.20 | loss  3.62 | ppl    37.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time: 13.15s | valid loss  5.60 | valid ppl   270.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |   200/  453 batches | ms/batch 28.29 | loss  3.69 | ppl    39.95\n",
            "| epoch  69 |   400/  453 batches | ms/batch 28.13 | loss  3.61 | ppl    37.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time: 13.16s | valid loss  5.61 | valid ppl   274.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |   200/  453 batches | ms/batch 28.35 | loss  3.68 | ppl    39.64\n",
            "| epoch  70 |   400/  453 batches | ms/batch 28.21 | loss  3.61 | ppl    36.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 13.19s | valid loss  5.63 | valid ppl   277.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  71 |   200/  453 batches | ms/batch 28.25 | loss  3.67 | ppl    39.33\n",
            "| epoch  71 |   400/  453 batches | ms/batch 28.08 | loss  3.60 | ppl    36.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time: 13.14s | valid loss  5.64 | valid ppl   280.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |   200/  453 batches | ms/batch 28.30 | loss  3.66 | ppl    39.02\n",
            "| epoch  72 |   400/  453 batches | ms/batch 28.26 | loss  3.59 | ppl    36.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time: 13.19s | valid loss  5.65 | valid ppl   282.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |   200/  453 batches | ms/batch 28.26 | loss  3.66 | ppl    38.72\n",
            "| epoch  73 |   400/  453 batches | ms/batch 28.10 | loss  3.58 | ppl    35.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time: 13.14s | valid loss  5.66 | valid ppl   285.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |   200/  453 batches | ms/batch 28.31 | loss  3.65 | ppl    38.42\n",
            "| epoch  74 |   400/  453 batches | ms/batch 28.14 | loss  3.58 | ppl    35.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time: 13.16s | valid loss  5.66 | valid ppl   288.42\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  75 |   200/  453 batches | ms/batch 28.25 | loss  3.64 | ppl    38.15\n",
            "| epoch  75 |   400/  453 batches | ms/batch 28.15 | loss  3.57 | ppl    35.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time: 13.16s | valid loss  5.68 | valid ppl   291.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |   200/  453 batches | ms/batch 28.28 | loss  3.63 | ppl    37.87\n",
            "| epoch  76 |   400/  453 batches | ms/batch 28.19 | loss  3.56 | ppl    35.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time: 13.18s | valid loss  5.69 | valid ppl   294.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |   200/  453 batches | ms/batch 28.30 | loss  3.63 | ppl    37.57\n",
            "| epoch  77 |   400/  453 batches | ms/batch 28.23 | loss  3.55 | ppl    34.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time: 13.18s | valid loss  5.70 | valid ppl   297.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |   200/  453 batches | ms/batch 28.30 | loss  3.62 | ppl    37.29\n",
            "| epoch  78 |   400/  453 batches | ms/batch 28.22 | loss  3.55 | ppl    34.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time: 13.18s | valid loss  5.71 | valid ppl   300.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |   200/  453 batches | ms/batch 28.43 | loss  3.61 | ppl    37.01\n",
            "| epoch  79 |   400/  453 batches | ms/batch 28.34 | loss  3.54 | ppl    34.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time: 13.25s | valid loss  5.72 | valid ppl   303.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |   200/  453 batches | ms/batch 28.49 | loss  3.60 | ppl    36.76\n",
            "| epoch  80 |   400/  453 batches | ms/batch 28.37 | loss  3.53 | ppl    34.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time: 13.26s | valid loss  5.73 | valid ppl   306.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  81 |   200/  453 batches | ms/batch 28.46 | loss  3.60 | ppl    36.49\n",
            "| epoch  81 |   400/  453 batches | ms/batch 28.35 | loss  3.53 | ppl    34.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time: 13.25s | valid loss  5.74 | valid ppl   310.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |   200/  453 batches | ms/batch 28.50 | loss  3.59 | ppl    36.25\n",
            "| epoch  82 |   400/  453 batches | ms/batch 28.31 | loss  3.52 | ppl    33.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time: 13.25s | valid loss  5.75 | valid ppl   313.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |   200/  453 batches | ms/batch 28.42 | loss  3.58 | ppl    36.02\n",
            "| epoch  83 |   400/  453 batches | ms/batch 28.37 | loss  3.51 | ppl    33.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time: 13.24s | valid loss  5.76 | valid ppl   315.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |   200/  453 batches | ms/batch 28.53 | loss  3.58 | ppl    35.79\n",
            "| epoch  84 |   400/  453 batches | ms/batch 28.36 | loss  3.51 | ppl    33.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time: 13.28s | valid loss  5.76 | valid ppl   318.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |   200/  453 batches | ms/batch 28.58 | loss  3.57 | ppl    35.61\n",
            "| epoch  85 |   400/  453 batches | ms/batch 28.44 | loss  3.50 | ppl    33.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time: 13.32s | valid loss  5.77 | valid ppl   322.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |   200/  453 batches | ms/batch 28.72 | loss  3.57 | ppl    35.40\n",
            "| epoch  86 |   400/  453 batches | ms/batch 28.47 | loss  3.50 | ppl    32.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time: 13.35s | valid loss  5.78 | valid ppl   325.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |   200/  453 batches | ms/batch 28.63 | loss  3.56 | ppl    35.20\n",
            "| epoch  87 |   400/  453 batches | ms/batch 28.48 | loss  3.49 | ppl    32.72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time: 13.33s | valid loss  5.79 | valid ppl   328.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |   200/  453 batches | ms/batch 28.74 | loss  3.55 | ppl    34.98\n",
            "| epoch  88 |   400/  453 batches | ms/batch 28.65 | loss  3.48 | ppl    32.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time: 13.39s | valid loss  5.80 | valid ppl   331.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |   200/  453 batches | ms/batch 28.70 | loss  3.55 | ppl    34.80\n",
            "| epoch  89 |   400/  453 batches | ms/batch 28.70 | loss  3.48 | ppl    32.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time: 13.39s | valid loss  5.81 | valid ppl   334.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |   200/  453 batches | ms/batch 28.86 | loss  3.54 | ppl    34.59\n",
            "| epoch  90 |   400/  453 batches | ms/batch 28.39 | loss  3.47 | ppl    32.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time: 13.33s | valid loss  5.82 | valid ppl   337.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  91 |   200/  453 batches | ms/batch 28.53 | loss  3.54 | ppl    34.40\n",
            "| epoch  91 |   400/  453 batches | ms/batch 28.71 | loss  3.46 | ppl    31.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time: 13.36s | valid loss  5.83 | valid ppl   341.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |   200/  453 batches | ms/batch 28.86 | loss  3.53 | ppl    34.21\n",
            "| epoch  92 |   400/  453 batches | ms/batch 28.65 | loss  3.46 | ppl    31.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time: 13.41s | valid loss  5.85 | valid ppl   345.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |   200/  453 batches | ms/batch 28.79 | loss  3.53 | ppl    34.04\n",
            "| epoch  93 |   400/  453 batches | ms/batch 28.49 | loss  3.45 | ppl    31.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time: 13.35s | valid loss  5.86 | valid ppl   350.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |   200/  453 batches | ms/batch 28.77 | loss  3.52 | ppl    33.88\n",
            "| epoch  94 |   400/  453 batches | ms/batch 28.62 | loss  3.45 | ppl    31.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time: 13.39s | valid loss  5.87 | valid ppl   353.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |   200/  453 batches | ms/batch 28.69 | loss  3.52 | ppl    33.71\n",
            "| epoch  95 |   400/  453 batches | ms/batch 28.59 | loss  3.44 | ppl    31.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time: 13.37s | valid loss  5.88 | valid ppl   356.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |   200/  453 batches | ms/batch 28.80 | loss  3.51 | ppl    33.56\n",
            "| epoch  96 |   400/  453 batches | ms/batch 28.61 | loss  3.44 | ppl    31.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time: 13.40s | valid loss  5.89 | valid ppl   360.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |   200/  453 batches | ms/batch 28.79 | loss  3.51 | ppl    33.39\n",
            "| epoch  97 |   400/  453 batches | ms/batch 28.64 | loss  3.43 | ppl    30.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time: 13.40s | valid loss  5.90 | valid ppl   364.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |   200/  453 batches | ms/batch 28.82 | loss  3.50 | ppl    33.19\n",
            "| epoch  98 |   400/  453 batches | ms/batch 28.64 | loss  3.42 | ppl    30.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time: 13.40s | valid loss  5.91 | valid ppl   368.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |   200/  453 batches | ms/batch 28.88 | loss  3.49 | ppl    32.94\n",
            "| epoch  99 |   400/  453 batches | ms/batch 28.74 | loss  3.42 | ppl    30.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time: 13.45s | valid loss  5.92 | valid ppl   371.79\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_fT_X-SwK0_e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}