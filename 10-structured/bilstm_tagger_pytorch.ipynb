{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bilstm-tagger-pytorch.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1bq06RrNiNJE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "0e0c9eb7-26ab-46a6-89c9-97d198cc2738",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532006005362,
          "user_tz": -540,
          "elapsed": 98267,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchtext\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 484.0MB 24kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5c906000 @  0x7ffaad8f71c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 11.0MB/s \n",
            "\u001b[?25hCollecting tqdm (from torchtext)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torch, tqdm, torchtext\n",
            "Successfully installed torch-0.4.0 torchtext-0.2.3 tqdm-4.23.4\n",
            "Cloning into 'nn4nlp-code'...\n",
            "remote: Counting objects: 372, done.\u001b[K\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "remote: Total 372 (delta 0), reused 0 (delta 0), pack-reused 372\u001b[K\r\n",
            "Receiving objects: 100% (372/372)   \rReceiving objects: 100% (372/372), 6.33 MiB | 22.04 MiB/s, done.\r\n",
            "Resolving deltas:   0% (0/131)   \rResolving deltas:   2% (3/131)   \rResolving deltas:   6% (9/131)   \rResolving deltas:  10% (14/131)   \rResolving deltas:  22% (29/131)   \rResolving deltas:  23% (31/131)   \rResolving deltas:  26% (35/131)   \rResolving deltas:  35% (46/131)   \rResolving deltas:  36% (48/131)   \rResolving deltas:  38% (50/131)   \rResolving deltas:  40% (53/131)   \rResolving deltas:  41% (54/131)   \rResolving deltas:  43% (57/131)   \rResolving deltas:  45% (60/131)   \rResolving deltas:  46% (61/131)   \rResolving deltas:  68% (90/131)   \rResolving deltas:  71% (94/131)   \rResolving deltas:  73% (96/131)   \rResolving deltas:  74% (98/131)   \rResolving deltas:  75% (99/131)   \rResolving deltas:  77% (101/131)   \rResolving deltas:  78% (103/131)   \rResolving deltas:  91% (120/131)   \rResolving deltas:  93% (123/131)   \rResolving deltas:  94% (124/131)   \rResolving deltas:  95% (125/131)   \rResolving deltas:  96% (126/131)   \rResolving deltas:  98% (129/131)   \rResolving deltas:  99% (130/131)   \rResolving deltas: 100% (131/131)   \rResolving deltas: 100% (131/131), done.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TzkbV7NTiTRY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8YhJNGxikrJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# format of files: each line is \"word1|tag1 word2|tag2 ...\"\n",
        "train_file = \"nn4nlp-code/data/tags/train.txt\"\n",
        "dev_file = \"nn4nlp-code/data/tags/dev.txt\"\n",
        "\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "\n",
        "\n",
        "def read(fname):\n",
        "    \"\"\"\n",
        "    Read tagged file\n",
        "    \"\"\"\n",
        "    with open(fname, \"r\") as f:\n",
        "        for line in f:\n",
        "            words, tags = [], []\n",
        "            for wt in line.strip().split():\n",
        "                w, t = wt.split('|')\n",
        "                words.append(w2i[w])\n",
        "                tags.append(t2i[t])\n",
        "            yield (words, tags)\n",
        "\n",
        "\n",
        "# Read the data\n",
        "train = list(read(train_file))\n",
        "unk_word = w2i[\"<unk>\"]\n",
        "w2i = defaultdict(lambda: unk_word, w2i)\n",
        "unk_tag = t2i[\"<unk>\"]\n",
        "t2i = defaultdict(lambda: unk_tag, t2i)\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)\n",
        "dev = list(read(dev_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eXyYn3lQyc4U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "fd7f81da-0264-4614-e2e3-0b5d79851e25",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532007931659,
          "user_tz": -540,
          "elapsed": 710,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "t2i"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'<unk>': 9,\n",
              "             'B-LOC': 7,\n",
              "             'B-MISC': 5,\n",
              "             'B-ORG': 8,\n",
              "             'B-PER': 6,\n",
              "             'I-LOC': 4,\n",
              "             'I-MISC': 0,\n",
              "             'I-ORG': 3,\n",
              "             'I-PER': 2,\n",
              "             'O': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "XL2Vhh0QiqV2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "dbd97c44-47e1-4c87-c8ad-02f5355fa3f8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532006026246,
          "user_tz": -540,
          "elapsed": 2512,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!head nn4nlp-code/data/tags/train.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The|I-MISC Oxford|I-MISC Companion|I-MISC to|I-MISC Philosophy|I-MISC says|O ,|O \"|O there|O is|O no|O single|O defining|O position|O that|O all|O anarchists|O hold|O ,|O and|O those|O considered|O anarchists|O at|O best|O share|O a|O certain|O family|O resemblance|O .|O \"|O\r\n",
            "In|O the|O end|O ,|O for|O anarchist|O historian|O Daniel|I-PER Guerin|I-PER \"|O Some|O anarchists|O are|O more|O individualistic|O than|O social|O ,|O some|O more|O social|O than|O individualistic|O .|O\r\n",
            "From|O this|O climate|O William|I-PER Godwin|I-PER developed|O what|O many|O consider|O the|O first|O expression|O of|O modern|O anarchist|O thought|O .|O\r\n",
            "Godwin|I-PER was|O ,|O according|O to|O Peter|I-PER Kropotkin|I-PER ,|O \"|O the|O first|O to|O formulate|O the|O political|O and|O economical|O conceptions|O of|O anarchism|O ,|O even|O though|O he|O did|O not|O give|O that|O name|O to|O the|O ideas|O developed|O in|O his|O work|O \"|O ,|O while|O Godwin|I-PER attached|O his|O anarchist|O ideas|O to|O an|O early|O Edmund|I-PER Burke|I-PER .|O\r\n",
            "The|O first|O to|O describe|O himself|O as|O an|O anarchist|O was|O Pierre-Joseph|I-PER Proudhon|I-PER ,|O a|O French|I-MISC philosopher|O and|O politician|O ,|O which|O led|O some|O to|O call|O him|O the|O founder|O of|O modern|O anarchist|O theory|O .|O\r\n",
            "Its|O classical|O period|O ,|O which|O scholars|O demarcate|O as|O from|O 1860|O to|O 1939|O ,|O is|O associated|O with|O the|O working-class|O movements|O of|O the|O nineteenth|O century|O and|O the|O Spanish|I-MISC Civil|I-MISC War-era|I-MISC struggles|O against|O fascism|O .|O\r\n",
            "Due|O to|O its|O links|O to|O active|O workers|O '|O movements|O ,|O the|I-MISC International|I-MISC became|O a|O significant|O organization|O .|O\r\n",
            "Karl|I-PER Marx|I-PER became|O a|O leading|O figure|O in|O the|I-MISC International|I-MISC and|O a|O member|O of|O its|O General|I-ORG Council|I-ORG .|O\r\n",
            "Proudhon|I-PER 's|O followers|O ,|O the|O mutualists|O ,|O opposed|O Marx|I-PER 's|O state|O socialism|O ,|O advocating|O political|O abstentionism|O and|O small|O property|O holdings|O .|O\r\n",
            "They|O allied|O themselves|O with|O the|O federalist|O socialist|O sections|O of|O the|I-MISC International|I-MISC ,|O who|O advocated|O the|O revolutionary|O overthrow|O of|O the|O state|O and|O the|O collectivization|O of|O property|O .|O\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5RzOTaIi4ri",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, tag_size, embed_dim, hidden_size, num_layers=1):\n",
        "    super(BiLSTM, self).__init__()\n",
        "    \n",
        "    self.vocab_size = vocab_size\n",
        "    self.tag_size = tag_size\n",
        "    self.embed_dim = embed_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, bidirectional=True)\n",
        "    self.fc = nn.Linear(hidden_size*2, tag_size)\n",
        "  \n",
        "  def init_hidden(self, bs):\n",
        "    return (torch.zeros(2, bs, self.hidden_size, device=device), \n",
        "            torch.zeros(2, bs, self.hidden_size, device=device))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    seq_len, bs = x.shape\n",
        "    h = self.init_hidden(bs)\n",
        "    x = self.embeddings(x)\n",
        "    x, h = self.lstm(x, h)\n",
        "    x = self.fc(x.view(seq_len*bs, -1)).view(seq_len, bs, -1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k2mCD_2ejMZc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class TaggerDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, ix):\n",
        "    return torch.LongTensor(self.data[ix][0]), torch.LongTensor(self.data[ix][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjj5mVvWlaV_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def pad_tensor(vec, pad, dim):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        pad - the size to pad to\n",
        "        dim - dimension to pad\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'pad' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = list(vec.shape)\n",
        "    pad_size[dim] = pad - vec.size(dim)\n",
        "    return torch.cat([vec, torch.zeros(*pad_size).long()], dim=dim)\n",
        "\n",
        "\n",
        "class PadCollate:\n",
        "    \"\"\"\n",
        "    a variant of callate_fn that pads according to the longest sequence in\n",
        "    a batch of sequences\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim=0):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            dim - the dimension to be padded (dimension of time in sequences)\n",
        "        \"\"\"\n",
        "        self.dim = dim\n",
        "\n",
        "    def pad_collate(self, batch):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            batch - list of (tensor, label)\n",
        "\n",
        "        reutrn:\n",
        "            xs - a tensor of all examples in 'batch' after padding\n",
        "            ys - a LongTensor of all labels in batch\n",
        "        \"\"\"\n",
        "        # find longest sequence\n",
        "        xlens = list(map(lambda x: x[0].shape[self.dim], batch))\n",
        "        ylens = list(map(lambda x: x[1].shape[self.dim], batch))\n",
        "        max_xlen = max(xlens)\n",
        "        max_ylen = max(ylens)\n",
        "        # pad according to max_len\n",
        "        batch = list(map(lambda x:\n",
        "                    (pad_tensor(x[0], pad=max_xlen, dim=self.dim), \n",
        "                    pad_tensor(x[1], pad=max_ylen, dim=self.dim)), batch))\n",
        "        # stack all\n",
        "        xs = torch.stack(list(map(lambda x: x[0], batch)), dim=0)\n",
        "        ys = torch.stack(list(map(lambda x: x[1], batch)), dim=0)\n",
        "        return xs, ys, torch.LongTensor(xlens), torch.LongTensor(ylens)\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        return self.pad_collate(batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6cualM5wyeh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "hidden_dim = 64\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "model = BiLSTM(nwords, ntags, embed_dim, hidden_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=9)\n",
        "trainer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgNGD0hnj7OI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = TaggerDataset(train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=PadCollate(dim=0))\n",
        "\n",
        "dev_dataset = TaggerDataset(dev)\n",
        "dev_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=PadCollate(dim=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0uaJ7Fvnu36",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mqkt17GMj8Li",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "fe49c176-c933-4109-ae7c-5a57c0fce492",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532009911095,
          "user_tz": -540,
          "elapsed": 114250,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch_i in range(10):\n",
        "  model.train()\n",
        "  total_loss = 0.\n",
        "  for batch_i, batch in enumerate(train_dataloader):\n",
        "    xs, ys, xlens, ylens = batch\n",
        "    logits = model(xs.transpose(0, 1))\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss = criterion(logits.transpose(0,1).contiguous().view(-1, ntags), ys.view(-1))\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    trainer.step()\n",
        "\n",
        "    if batch_i % 200 == 0:\n",
        "      print(f\"epoch {epoch_i} | batch {batch_i} | avg_loss: {total_loss/(batch_i+1):.4f}\")\n",
        "    \n",
        "  model.eval()\n",
        "  val_loss = 0.\n",
        "  val_correct = 0\n",
        "  val_cnt = 0\n",
        "  for batch_i, batch in enumerate(dev_dataloader):\n",
        "    xs, ys, xlens, ylens = batch\n",
        "    logits = model(xs.transpose(0, 1))\n",
        "    loss = criterion(logits.transpose(0,1).contiguous().view(-1, ntags), ys.view(-1))\n",
        "    val_loss += loss.item()\n",
        "    mask = torch.arange(ys.shape[1]).unsqueeze(0).expand_as(ys) - ylens.float().unsqueeze(1) < 0 \n",
        "    correct = ((torch.argmax(logits, -1).transpose(0, 1) == ys)  & mask).sum()\n",
        "    val_cnt += ylens.sum().item()\n",
        "    val_correct += correct.item()\n",
        "  print(f\"val_acc: {1. * val_correct / val_cnt} | val_loss: {val_loss/(batch_i+1)}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 | batch 0 | avg_loss: 0.0035\n",
            "epoch 0 | batch 200 | avg_loss: 0.0027\n",
            "epoch 0 | batch 400 | avg_loss: 0.0027\n",
            "epoch 0 | batch 600 | avg_loss: 0.0027\n",
            "val_acc: 0.9639813254420694 | val_loss: 0.0020012864457676187\n",
            "epoch 1 | batch 0 | avg_loss: 0.0013\n",
            "epoch 1 | batch 200 | avg_loss: 0.0017\n",
            "epoch 1 | batch 400 | avg_loss: 0.0019\n",
            "epoch 1 | batch 600 | avg_loss: 0.0018\n",
            "val_acc: 0.9640700215289593 | val_loss: 0.0013139211153116775\n",
            "epoch 2 | batch 0 | avg_loss: 0.0049\n",
            "epoch 2 | batch 200 | avg_loss: 0.0011\n",
            "epoch 2 | batch 400 | avg_loss: 0.0011\n",
            "epoch 2 | batch 600 | avg_loss: 0.0012\n",
            "val_acc: 0.9641506543352228 | val_loss: 0.0009995323370341795\n",
            "epoch 3 | batch 0 | avg_loss: 0.0003\n",
            "epoch 3 | batch 200 | avg_loss: 0.0009\n",
            "epoch 3 | batch 400 | avg_loss: 0.0008\n",
            "epoch 3 | batch 600 | avg_loss: 0.0008\n",
            "val_acc: 0.9642716035446182 | val_loss: 0.0004485483444899728\n",
            "epoch 4 | batch 0 | avg_loss: 0.0004\n",
            "epoch 4 | batch 200 | avg_loss: 0.0005\n",
            "epoch 4 | batch 400 | avg_loss: 0.0004\n",
            "epoch 4 | batch 600 | avg_loss: 0.0004\n",
            "val_acc: 0.964267571904305 | val_loss: 0.00029493814907982597\n",
            "epoch 5 | batch 0 | avg_loss: 0.0001\n",
            "epoch 5 | batch 200 | avg_loss: 0.0003\n",
            "epoch 5 | batch 400 | avg_loss: 0.0004\n",
            "epoch 5 | batch 600 | avg_loss: 0.0004\n",
            "val_acc: 0.9642796668252445 | val_loss: 0.00023493965155539626\n",
            "epoch 6 | batch 0 | avg_loss: 0.0003\n",
            "epoch 6 | batch 200 | avg_loss: 0.0002\n",
            "epoch 6 | batch 400 | avg_loss: 0.0002\n",
            "epoch 6 | batch 600 | avg_loss: 0.0003\n",
            "val_acc: 0.964199034018981 | val_loss: 0.000504999180507366\n",
            "epoch 7 | batch 0 | avg_loss: 0.0001\n",
            "epoch 7 | batch 200 | avg_loss: 0.0003\n",
            "epoch 7 | batch 400 | avg_loss: 0.0015\n",
            "epoch 7 | batch 600 | avg_loss: 0.0018\n",
            "val_acc: 0.9636426676557625 | val_loss: 0.002260374998187035\n",
            "epoch 8 | batch 0 | avg_loss: 0.0004\n",
            "epoch 8 | batch 200 | avg_loss: 0.0016\n",
            "epoch 8 | batch 400 | avg_loss: 0.0016\n",
            "epoch 8 | batch 600 | avg_loss: 0.0017\n",
            "val_acc: 0.9641345277739701 | val_loss: 0.0007344841062611522\n",
            "epoch 9 | batch 0 | avg_loss: 0.0002\n",
            "epoch 9 | batch 200 | avg_loss: 0.0010\n",
            "epoch 9 | batch 400 | avg_loss: 0.0007\n",
            "epoch 9 | batch 600 | avg_loss: 0.0007\n",
            "val_acc: 0.9642070972996073 | val_loss: 0.0003440211608165555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-QSOQlQdw7wX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}