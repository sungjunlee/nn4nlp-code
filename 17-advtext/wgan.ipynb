{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uRxZ-U2ZI9Z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e4aa6be1-df46-4dec-a68d-c7a9cf74e2dd"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zLzGK8cqJCJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjUrZemBJEUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06aYj285JpKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sys.argv = ['dummy']\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')\n",
        "parser.add_argument('--batch_size', type=int, default=64, help='size of the batches')\n",
        "parser.add_argument('--lr', type=float, default=0.00005, help='learning rate')\n",
        "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
        "parser.add_argument('--latent_dim', type=int, default=100, help='dimensionality of the latent space')\n",
        "parser.add_argument('--img_size', type=int, default=28, help='size of each image dimension')\n",
        "parser.add_argument('--channels', type=int, default=1, help='number of image channels')\n",
        "parser.add_argument('--n_critic', type=int, default=5, help='number of training steps for discriminator per iter')\n",
        "parser.add_argument('--clip_value', type=float, default=0.01, help='lower and upper clip value for disc. weights')\n",
        "parser.add_argument('--sample_interval', type=int, default=400, help='interval betwen image samples')\n",
        "opt = parser.parse_args()\n",
        "print(opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tk9EPOj6Jtl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [  nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(opt.latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.shape[0], *img_shape)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1zWWfQZ2J06r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs('data/mnist', exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data/mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                   ])),\n",
        "    batch_size=opt.batch_size, shuffle=True)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\n",
        "optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4kdf7LkI8AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163151
        },
        "outputId": "0a05cfa7-d9bd-4d6b-93e2-835ac6b3fbf0"
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "batches_done = 0\n",
        "for epoch in range(opt.n_epochs):\n",
        "\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        fake_imgs = generator(z).detach()\n",
        "        # Adversarial loss\n",
        "        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Clip weights of discriminator\n",
        "        for p in discriminator.parameters():\n",
        "            p.data.clamp_(-opt.clip_value, opt.clip_value)\n",
        "\n",
        "        # Train the generator every n_critic iterations\n",
        "        if i % opt.n_critic == 0:\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Generate a batch of images\n",
        "            gen_imgs = generator(z)\n",
        "            # Adversarial loss\n",
        "            loss_G = -torch.mean(discriminator(gen_imgs))\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, opt.n_epochs,\n",
        "                                                            batches_done % len(dataloader), len(dataloader),\n",
        "                                                            loss_D.item(), loss_G.item()))\n",
        "\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            save_image(gen_imgs.data[:25], 'images/%d.png' % batches_done, nrow=5, normalize=True)\n",
        "        batches_done += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=64, channels=1, clip_value=0.01, img_size=28, latent_dim=100, lr=5e-05, n_cpu=8, n_critic=5, n_epochs=200, sample_interval=400)\n",
            "[Epoch 0/200] [Batch 0/938] [D loss: -0.138592] [G loss: 0.009771]\n",
            "[Epoch 0/200] [Batch 5/938] [D loss: -0.121358] [G loss: 0.009536]\n",
            "[Epoch 0/200] [Batch 10/938] [D loss: -0.385432] [G loss: 0.008605]\n",
            "[Epoch 0/200] [Batch 15/938] [D loss: -0.845041] [G loss: 0.006180]\n",
            "[Epoch 0/200] [Batch 20/938] [D loss: -1.453767] [G loss: 0.000161]\n",
            "[Epoch 0/200] [Batch 25/938] [D loss: -2.142226] [G loss: -0.012865]\n",
            "[Epoch 0/200] [Batch 30/938] [D loss: -2.809798] [G loss: -0.031920]\n",
            "[Epoch 0/200] [Batch 35/938] [D loss: -3.643089] [G loss: -0.056735]\n",
            "[Epoch 0/200] [Batch 40/938] [D loss: -4.494615] [G loss: -0.091574]\n",
            "[Epoch 0/200] [Batch 45/938] [D loss: -5.337285] [G loss: -0.130923]\n",
            "[Epoch 0/200] [Batch 50/938] [D loss: -6.162086] [G loss: -0.183140]\n",
            "[Epoch 0/200] [Batch 55/938] [D loss: -6.875985] [G loss: -0.239656]\n",
            "[Epoch 0/200] [Batch 60/938] [D loss: -7.575027] [G loss: -0.308473]\n",
            "[Epoch 0/200] [Batch 65/938] [D loss: -8.590622] [G loss: -0.390499]\n",
            "[Epoch 0/200] [Batch 70/938] [D loss: -9.583084] [G loss: -0.469893]\n",
            "[Epoch 0/200] [Batch 75/938] [D loss: -10.214071] [G loss: -0.578740]\n",
            "[Epoch 0/200] [Batch 80/938] [D loss: -10.919633] [G loss: -0.677002]\n",
            "[Epoch 0/200] [Batch 85/938] [D loss: -11.618788] [G loss: -0.801456]\n",
            "[Epoch 0/200] [Batch 90/938] [D loss: -12.723137] [G loss: -0.921139]\n",
            "[Epoch 0/200] [Batch 95/938] [D loss: -13.108072] [G loss: -1.060792]\n",
            "[Epoch 0/200] [Batch 100/938] [D loss: -13.856660] [G loss: -1.208454]\n",
            "[Epoch 0/200] [Batch 105/938] [D loss: -14.681889] [G loss: -1.365182]\n",
            "[Epoch 0/200] [Batch 110/938] [D loss: -15.391846] [G loss: -1.554740]\n",
            "[Epoch 0/200] [Batch 115/938] [D loss: -15.643943] [G loss: -1.733232]\n",
            "[Epoch 0/200] [Batch 120/938] [D loss: -16.734262] [G loss: -1.967142]\n",
            "[Epoch 0/200] [Batch 125/938] [D loss: -17.131004] [G loss: -2.148129]\n",
            "[Epoch 0/200] [Batch 130/938] [D loss: -17.353067] [G loss: -2.400618]\n",
            "[Epoch 0/200] [Batch 135/938] [D loss: -18.217720] [G loss: -2.615872]\n",
            "[Epoch 0/200] [Batch 140/938] [D loss: -19.147888] [G loss: -2.913434]\n",
            "[Epoch 0/200] [Batch 145/938] [D loss: -19.522617] [G loss: -3.122768]\n",
            "[Epoch 0/200] [Batch 150/938] [D loss: -19.622673] [G loss: -3.449095]\n",
            "[Epoch 0/200] [Batch 155/938] [D loss: -20.207537] [G loss: -3.732233]\n",
            "[Epoch 0/200] [Batch 160/938] [D loss: -20.912766] [G loss: -3.992709]\n",
            "[Epoch 0/200] [Batch 165/938] [D loss: -21.556046] [G loss: -4.282373]\n",
            "[Epoch 0/200] [Batch 170/938] [D loss: -21.949100] [G loss: -4.544852]\n",
            "[Epoch 0/200] [Batch 175/938] [D loss: -21.556694] [G loss: -4.974558]\n",
            "[Epoch 0/200] [Batch 180/938] [D loss: -22.298964] [G loss: -5.493814]\n",
            "[Epoch 0/200] [Batch 185/938] [D loss: -22.796530] [G loss: -5.720957]\n",
            "[Epoch 0/200] [Batch 190/938] [D loss: -22.572355] [G loss: -6.030179]\n",
            "[Epoch 0/200] [Batch 195/938] [D loss: -23.095446] [G loss: -6.563299]\n",
            "[Epoch 0/200] [Batch 200/938] [D loss: -22.709671] [G loss: -6.726679]\n",
            "[Epoch 0/200] [Batch 205/938] [D loss: -23.117891] [G loss: -7.099753]\n",
            "[Epoch 0/200] [Batch 210/938] [D loss: -23.693888] [G loss: -7.303706]\n",
            "[Epoch 0/200] [Batch 215/938] [D loss: -23.310307] [G loss: -7.952722]\n",
            "[Epoch 0/200] [Batch 220/938] [D loss: -23.154081] [G loss: -8.323670]\n",
            "[Epoch 0/200] [Batch 225/938] [D loss: -23.376545] [G loss: -8.222774]\n",
            "[Epoch 0/200] [Batch 230/938] [D loss: -22.775009] [G loss: -8.614047]\n",
            "[Epoch 0/200] [Batch 235/938] [D loss: -21.594570] [G loss: -9.883948]\n",
            "[Epoch 0/200] [Batch 240/938] [D loss: -21.112591] [G loss: -10.251326]\n",
            "[Epoch 0/200] [Batch 245/938] [D loss: -22.019142] [G loss: -10.022571]\n",
            "[Epoch 0/200] [Batch 250/938] [D loss: -22.175465] [G loss: -10.521816]\n",
            "[Epoch 0/200] [Batch 255/938] [D loss: -21.591084] [G loss: -10.623224]\n",
            "[Epoch 0/200] [Batch 260/938] [D loss: -21.163548] [G loss: -11.393963]\n",
            "[Epoch 0/200] [Batch 265/938] [D loss: -20.225555] [G loss: -11.802608]\n",
            "[Epoch 0/200] [Batch 270/938] [D loss: -19.710667] [G loss: -11.681808]\n",
            "[Epoch 0/200] [Batch 275/938] [D loss: -20.843117] [G loss: -11.947982]\n",
            "[Epoch 0/200] [Batch 280/938] [D loss: -20.901316] [G loss: -12.243868]\n",
            "[Epoch 0/200] [Batch 285/938] [D loss: -19.662237] [G loss: -12.552916]\n",
            "[Epoch 0/200] [Batch 290/938] [D loss: -18.570560] [G loss: -13.672353]\n",
            "[Epoch 0/200] [Batch 295/938] [D loss: -19.163727] [G loss: -13.675473]\n",
            "[Epoch 0/200] [Batch 300/938] [D loss: -18.518105] [G loss: -14.240013]\n",
            "[Epoch 0/200] [Batch 305/938] [D loss: -17.687996] [G loss: -14.577715]\n",
            "[Epoch 0/200] [Batch 310/938] [D loss: -16.813267] [G loss: -14.948856]\n",
            "[Epoch 0/200] [Batch 315/938] [D loss: -17.363432] [G loss: -15.230556]\n",
            "[Epoch 0/200] [Batch 320/938] [D loss: -17.612610] [G loss: -15.514398]\n",
            "[Epoch 0/200] [Batch 325/938] [D loss: -15.704376] [G loss: -16.465303]\n",
            "[Epoch 0/200] [Batch 330/938] [D loss: -15.898806] [G loss: -16.160208]\n",
            "[Epoch 0/200] [Batch 335/938] [D loss: -15.306870] [G loss: -16.660488]\n",
            "[Epoch 0/200] [Batch 340/938] [D loss: -15.631731] [G loss: -16.807188]\n",
            "[Epoch 0/200] [Batch 345/938] [D loss: -15.354160] [G loss: -16.829403]\n",
            "[Epoch 0/200] [Batch 350/938] [D loss: -15.713823] [G loss: -16.778898]\n",
            "[Epoch 0/200] [Batch 355/938] [D loss: -13.891020] [G loss: -17.589048]\n",
            "[Epoch 0/200] [Batch 360/938] [D loss: -14.583012] [G loss: -17.130825]\n",
            "[Epoch 0/200] [Batch 365/938] [D loss: -14.628160] [G loss: -17.699795]\n",
            "[Epoch 0/200] [Batch 370/938] [D loss: -13.912624] [G loss: -18.308208]\n",
            "[Epoch 0/200] [Batch 375/938] [D loss: -14.173763] [G loss: -17.519541]\n",
            "[Epoch 0/200] [Batch 380/938] [D loss: -13.361626] [G loss: -18.495611]\n",
            "[Epoch 0/200] [Batch 385/938] [D loss: -13.023159] [G loss: -18.422640]\n",
            "[Epoch 0/200] [Batch 390/938] [D loss: -12.591770] [G loss: -18.906321]\n",
            "[Epoch 0/200] [Batch 395/938] [D loss: -12.504217] [G loss: -19.312143]\n",
            "[Epoch 0/200] [Batch 400/938] [D loss: -12.086309] [G loss: -19.476135]\n",
            "[Epoch 0/200] [Batch 405/938] [D loss: -11.563408] [G loss: -19.763353]\n",
            "[Epoch 0/200] [Batch 410/938] [D loss: -10.971075] [G loss: -19.978310]\n",
            "[Epoch 0/200] [Batch 415/938] [D loss: -12.191948] [G loss: -19.341274]\n",
            "[Epoch 0/200] [Batch 420/938] [D loss: -11.612700] [G loss: -19.846199]\n",
            "[Epoch 0/200] [Batch 425/938] [D loss: -9.825150] [G loss: -21.293896]\n",
            "[Epoch 0/200] [Batch 430/938] [D loss: -11.212044] [G loss: -20.065405]\n",
            "[Epoch 0/200] [Batch 435/938] [D loss: -8.755352] [G loss: -22.004025]\n",
            "[Epoch 0/200] [Batch 440/938] [D loss: -10.417223] [G loss: -20.599380]\n",
            "[Epoch 0/200] [Batch 445/938] [D loss: -10.663275] [G loss: -20.596582]\n",
            "[Epoch 0/200] [Batch 450/938] [D loss: -10.886885] [G loss: -20.133665]\n",
            "[Epoch 0/200] [Batch 455/938] [D loss: -10.590727] [G loss: -20.233587]\n",
            "[Epoch 0/200] [Batch 460/938] [D loss: -9.156330] [G loss: -21.294180]\n",
            "[Epoch 0/200] [Batch 465/938] [D loss: -10.059553] [G loss: -21.135292]\n",
            "[Epoch 0/200] [Batch 470/938] [D loss: -9.223970] [G loss: -20.862425]\n",
            "[Epoch 0/200] [Batch 475/938] [D loss: -9.857183] [G loss: -20.562704]\n",
            "[Epoch 0/200] [Batch 480/938] [D loss: -10.756311] [G loss: -20.042759]\n",
            "[Epoch 0/200] [Batch 485/938] [D loss: -9.616768] [G loss: -20.843328]\n",
            "[Epoch 0/200] [Batch 490/938] [D loss: -9.201996] [G loss: -20.762669]\n",
            "[Epoch 0/200] [Batch 495/938] [D loss: -7.863934] [G loss: -22.254261]\n",
            "[Epoch 0/200] [Batch 500/938] [D loss: -9.452883] [G loss: -20.998775]\n",
            "[Epoch 0/200] [Batch 505/938] [D loss: -8.057076] [G loss: -22.005831]\n",
            "[Epoch 0/200] [Batch 510/938] [D loss: -8.523718] [G loss: -21.140835]\n",
            "[Epoch 0/200] [Batch 515/938] [D loss: -7.989710] [G loss: -21.605579]\n",
            "[Epoch 0/200] [Batch 520/938] [D loss: -8.068607] [G loss: -21.823063]\n",
            "[Epoch 0/200] [Batch 525/938] [D loss: -9.415791] [G loss: -20.274061]\n",
            "[Epoch 0/200] [Batch 530/938] [D loss: -8.627266] [G loss: -20.656239]\n",
            "[Epoch 0/200] [Batch 535/938] [D loss: -7.308081] [G loss: -21.488457]\n",
            "[Epoch 0/200] [Batch 540/938] [D loss: -8.069309] [G loss: -21.048307]\n",
            "[Epoch 0/200] [Batch 545/938] [D loss: -6.883316] [G loss: -22.150166]\n",
            "[Epoch 0/200] [Batch 550/938] [D loss: -7.314842] [G loss: -21.470377]\n",
            "[Epoch 0/200] [Batch 555/938] [D loss: -7.778084] [G loss: -21.241608]\n",
            "[Epoch 0/200] [Batch 560/938] [D loss: -7.129782] [G loss: -21.440245]\n",
            "[Epoch 0/200] [Batch 565/938] [D loss: -5.957253] [G loss: -22.420431]\n",
            "[Epoch 0/200] [Batch 570/938] [D loss: -7.682041] [G loss: -21.238331]\n",
            "[Epoch 0/200] [Batch 575/938] [D loss: -6.686937] [G loss: -21.874334]\n",
            "[Epoch 0/200] [Batch 580/938] [D loss: -7.627619] [G loss: -20.829227]\n",
            "[Epoch 0/200] [Batch 585/938] [D loss: -7.179623] [G loss: -21.043247]\n",
            "[Epoch 0/200] [Batch 590/938] [D loss: -7.772341] [G loss: -21.108046]\n",
            "[Epoch 0/200] [Batch 595/938] [D loss: -5.871952] [G loss: -22.074450]\n",
            "[Epoch 0/200] [Batch 600/938] [D loss: -6.470507] [G loss: -21.261021]\n",
            "[Epoch 0/200] [Batch 605/938] [D loss: -7.451281] [G loss: -20.866796]\n",
            "[Epoch 0/200] [Batch 610/938] [D loss: -6.316689] [G loss: -21.162296]\n",
            "[Epoch 0/200] [Batch 615/938] [D loss: -6.681513] [G loss: -21.139683]\n",
            "[Epoch 0/200] [Batch 620/938] [D loss: -5.878685] [G loss: -21.230072]\n",
            "[Epoch 0/200] [Batch 625/938] [D loss: -6.416769] [G loss: -21.027500]\n",
            "[Epoch 0/200] [Batch 630/938] [D loss: -7.197805] [G loss: -20.088680]\n",
            "[Epoch 0/200] [Batch 635/938] [D loss: -6.646360] [G loss: -20.741356]\n",
            "[Epoch 0/200] [Batch 640/938] [D loss: -6.042604] [G loss: -21.395632]\n",
            "[Epoch 0/200] [Batch 645/938] [D loss: -6.561127] [G loss: -20.774025]\n",
            "[Epoch 0/200] [Batch 650/938] [D loss: -6.952639] [G loss: -20.643570]\n",
            "[Epoch 0/200] [Batch 655/938] [D loss: -6.768885] [G loss: -20.441278]\n",
            "[Epoch 0/200] [Batch 660/938] [D loss: -7.109016] [G loss: -20.080526]\n",
            "[Epoch 0/200] [Batch 665/938] [D loss: -6.799648] [G loss: -20.125252]\n",
            "[Epoch 0/200] [Batch 670/938] [D loss: -6.700686] [G loss: -20.097212]\n",
            "[Epoch 0/200] [Batch 675/938] [D loss: -5.623058] [G loss: -20.583591]\n",
            "[Epoch 0/200] [Batch 680/938] [D loss: -7.169994] [G loss: -19.766245]\n",
            "[Epoch 0/200] [Batch 685/938] [D loss: -5.897963] [G loss: -19.943558]\n",
            "[Epoch 0/200] [Batch 690/938] [D loss: -5.365406] [G loss: -20.346798]\n",
            "[Epoch 0/200] [Batch 695/938] [D loss: -6.250126] [G loss: -20.099813]\n",
            "[Epoch 0/200] [Batch 700/938] [D loss: -6.075491] [G loss: -19.872812]\n",
            "[Epoch 0/200] [Batch 705/938] [D loss: -5.465057] [G loss: -20.351976]\n",
            "[Epoch 0/200] [Batch 710/938] [D loss: -5.912588] [G loss: -19.963991]\n",
            "[Epoch 0/200] [Batch 715/938] [D loss: -5.684200] [G loss: -19.996506]\n",
            "[Epoch 0/200] [Batch 720/938] [D loss: -5.790592] [G loss: -19.734186]\n",
            "[Epoch 0/200] [Batch 725/938] [D loss: -6.043673] [G loss: -19.847807]\n",
            "[Epoch 0/200] [Batch 730/938] [D loss: -5.915318] [G loss: -19.658314]\n",
            "[Epoch 0/200] [Batch 735/938] [D loss: -5.356995] [G loss: -19.479927]\n",
            "[Epoch 0/200] [Batch 740/938] [D loss: -5.509121] [G loss: -19.607870]\n",
            "[Epoch 0/200] [Batch 745/938] [D loss: -5.343899] [G loss: -19.719236]\n",
            "[Epoch 0/200] [Batch 750/938] [D loss: -4.964947] [G loss: -20.091003]\n",
            "[Epoch 0/200] [Batch 755/938] [D loss: -5.299068] [G loss: -19.692862]\n",
            "[Epoch 0/200] [Batch 760/938] [D loss: -5.050409] [G loss: -19.908463]\n",
            "[Epoch 0/200] [Batch 765/938] [D loss: -5.505457] [G loss: -19.341496]\n",
            "[Epoch 0/200] [Batch 770/938] [D loss: -5.121639] [G loss: -19.617882]\n",
            "[Epoch 0/200] [Batch 775/938] [D loss: -5.616735] [G loss: -19.075039]\n",
            "[Epoch 0/200] [Batch 780/938] [D loss: -4.980844] [G loss: -19.311766]\n",
            "[Epoch 0/200] [Batch 785/938] [D loss: -5.495813] [G loss: -19.194086]\n",
            "[Epoch 0/200] [Batch 790/938] [D loss: -4.633469] [G loss: -19.534334]\n",
            "[Epoch 0/200] [Batch 795/938] [D loss: -4.841713] [G loss: -19.154156]\n",
            "[Epoch 0/200] [Batch 800/938] [D loss: -4.775776] [G loss: -19.188503]\n",
            "[Epoch 0/200] [Batch 805/938] [D loss: -4.939201] [G loss: -19.164883]\n",
            "[Epoch 0/200] [Batch 810/938] [D loss: -4.110880] [G loss: -19.386477]\n",
            "[Epoch 0/200] [Batch 815/938] [D loss: -5.125565] [G loss: -19.145039]\n",
            "[Epoch 0/200] [Batch 820/938] [D loss: -4.527628] [G loss: -19.409222]\n",
            "[Epoch 0/200] [Batch 825/938] [D loss: -5.335703] [G loss: -18.438442]\n",
            "[Epoch 0/200] [Batch 830/938] [D loss: -4.897799] [G loss: -18.776278]\n",
            "[Epoch 0/200] [Batch 835/938] [D loss: -5.354290] [G loss: -18.705664]\n",
            "[Epoch 0/200] [Batch 840/938] [D loss: -4.902458] [G loss: -18.717527]\n",
            "[Epoch 0/200] [Batch 845/938] [D loss: -4.788830] [G loss: -18.361061]\n",
            "[Epoch 0/200] [Batch 850/938] [D loss: -4.559938] [G loss: -18.623276]\n",
            "[Epoch 0/200] [Batch 855/938] [D loss: -4.902952] [G loss: -18.519285]\n",
            "[Epoch 0/200] [Batch 860/938] [D loss: -4.950079] [G loss: -18.382822]\n",
            "[Epoch 0/200] [Batch 865/938] [D loss: -4.852650] [G loss: -18.332718]\n",
            "[Epoch 0/200] [Batch 870/938] [D loss: -4.838774] [G loss: -18.329107]\n",
            "[Epoch 0/200] [Batch 875/938] [D loss: -4.519779] [G loss: -18.435562]\n",
            "[Epoch 0/200] [Batch 880/938] [D loss: -3.627995] [G loss: -18.743452]\n",
            "[Epoch 0/200] [Batch 885/938] [D loss: -3.997917] [G loss: -18.608536]\n",
            "[Epoch 0/200] [Batch 890/938] [D loss: -4.792463] [G loss: -17.934010]\n",
            "[Epoch 0/200] [Batch 895/938] [D loss: -4.057549] [G loss: -18.354130]\n",
            "[Epoch 0/200] [Batch 900/938] [D loss: -4.234148] [G loss: -17.755362]\n",
            "[Epoch 0/200] [Batch 905/938] [D loss: -4.158566] [G loss: -18.209362]\n",
            "[Epoch 0/200] [Batch 910/938] [D loss: -3.797338] [G loss: -18.300526]\n",
            "[Epoch 0/200] [Batch 915/938] [D loss: -4.013317] [G loss: -18.059814]\n",
            "[Epoch 0/200] [Batch 920/938] [D loss: -4.150642] [G loss: -17.802193]\n",
            "[Epoch 0/200] [Batch 925/938] [D loss: -3.762905] [G loss: -18.159748]\n",
            "[Epoch 0/200] [Batch 930/938] [D loss: -4.560961] [G loss: -18.050224]\n",
            "[Epoch 0/200] [Batch 935/938] [D loss: -4.499508] [G loss: -17.610804]\n",
            "[Epoch 1/200] [Batch 0/938] [D loss: -2.993715] [G loss: -18.176966]\n",
            "[Epoch 1/200] [Batch 5/938] [D loss: -3.562088] [G loss: -17.855169]\n",
            "[Epoch 1/200] [Batch 10/938] [D loss: -4.057083] [G loss: -17.750761]\n",
            "[Epoch 1/200] [Batch 15/938] [D loss: -3.670210] [G loss: -17.769213]\n",
            "[Epoch 1/200] [Batch 20/938] [D loss: -4.032059] [G loss: -17.656469]\n",
            "[Epoch 1/200] [Batch 25/938] [D loss: -3.432844] [G loss: -17.642515]\n",
            "[Epoch 1/200] [Batch 30/938] [D loss: -3.850395] [G loss: -17.625113]\n",
            "[Epoch 1/200] [Batch 35/938] [D loss: -3.864182] [G loss: -17.627607]\n",
            "[Epoch 1/200] [Batch 40/938] [D loss: -2.965742] [G loss: -17.652542]\n",
            "[Epoch 1/200] [Batch 45/938] [D loss: -3.629322] [G loss: -17.425989]\n",
            "[Epoch 1/200] [Batch 50/938] [D loss: -4.033762] [G loss: -17.445446]\n",
            "[Epoch 1/200] [Batch 55/938] [D loss: -4.011637] [G loss: -17.316633]\n",
            "[Epoch 1/200] [Batch 60/938] [D loss: -3.212017] [G loss: -17.660109]\n",
            "[Epoch 1/200] [Batch 65/938] [D loss: -2.919069] [G loss: -17.308861]\n",
            "[Epoch 1/200] [Batch 70/938] [D loss: -3.845900] [G loss: -17.465960]\n",
            "[Epoch 1/200] [Batch 75/938] [D loss: -3.426294] [G loss: -17.364168]\n",
            "[Epoch 1/200] [Batch 80/938] [D loss: -3.059889] [G loss: -17.444469]\n",
            "[Epoch 1/200] [Batch 85/938] [D loss: -2.836489] [G loss: -17.299171]\n",
            "[Epoch 1/200] [Batch 90/938] [D loss: -3.469994] [G loss: -16.982561]\n",
            "[Epoch 1/200] [Batch 95/938] [D loss: -3.036261] [G loss: -17.433985]\n",
            "[Epoch 1/200] [Batch 100/938] [D loss: -3.228703] [G loss: -17.079990]\n",
            "[Epoch 1/200] [Batch 105/938] [D loss: -3.133104] [G loss: -17.120687]\n",
            "[Epoch 1/200] [Batch 110/938] [D loss: -3.208549] [G loss: -17.068256]\n",
            "[Epoch 1/200] [Batch 115/938] [D loss: -3.566233] [G loss: -16.934095]\n",
            "[Epoch 1/200] [Batch 120/938] [D loss: -3.159512] [G loss: -17.164801]\n",
            "[Epoch 1/200] [Batch 125/938] [D loss: -2.421974] [G loss: -17.265081]\n",
            "[Epoch 1/200] [Batch 130/938] [D loss: -2.713444] [G loss: -17.131824]\n",
            "[Epoch 1/200] [Batch 135/938] [D loss: -3.483053] [G loss: -16.736351]\n",
            "[Epoch 1/200] [Batch 140/938] [D loss: -2.908243] [G loss: -16.846371]\n",
            "[Epoch 1/200] [Batch 145/938] [D loss: -2.601519] [G loss: -17.147102]\n",
            "[Epoch 1/200] [Batch 150/938] [D loss: -2.678745] [G loss: -16.838327]\n",
            "[Epoch 1/200] [Batch 155/938] [D loss: -2.675518] [G loss: -17.015226]\n",
            "[Epoch 1/200] [Batch 160/938] [D loss: -2.591030] [G loss: -16.998165]\n",
            "[Epoch 1/200] [Batch 165/938] [D loss: -2.960901] [G loss: -16.711573]\n",
            "[Epoch 1/200] [Batch 170/938] [D loss: -2.482994] [G loss: -16.936058]\n",
            "[Epoch 1/200] [Batch 175/938] [D loss: -2.688873] [G loss: -16.774483]\n",
            "[Epoch 1/200] [Batch 180/938] [D loss: -2.469879] [G loss: -16.856651]\n",
            "[Epoch 1/200] [Batch 185/938] [D loss: -2.511988] [G loss: -16.822390]\n",
            "[Epoch 1/200] [Batch 190/938] [D loss: -2.387154] [G loss: -16.658520]\n",
            "[Epoch 1/200] [Batch 195/938] [D loss: -3.236120] [G loss: -16.863901]\n",
            "[Epoch 1/200] [Batch 200/938] [D loss: -2.067051] [G loss: -16.666378]\n",
            "[Epoch 1/200] [Batch 205/938] [D loss: -2.619902] [G loss: -16.793394]\n",
            "[Epoch 1/200] [Batch 210/938] [D loss: -2.855080] [G loss: -16.492592]\n",
            "[Epoch 1/200] [Batch 215/938] [D loss: -2.298029] [G loss: -16.782146]\n",
            "[Epoch 1/200] [Batch 220/938] [D loss: -2.118738] [G loss: -16.733818]\n",
            "[Epoch 1/200] [Batch 225/938] [D loss: -2.544497] [G loss: -16.747929]\n",
            "[Epoch 1/200] [Batch 230/938] [D loss: -2.151035] [G loss: -16.614004]\n",
            "[Epoch 1/200] [Batch 235/938] [D loss: -1.666281] [G loss: -16.654753]\n",
            "[Epoch 1/200] [Batch 240/938] [D loss: -2.163603] [G loss: -16.598803]\n",
            "[Epoch 1/200] [Batch 245/938] [D loss: -2.257532] [G loss: -16.732887]\n",
            "[Epoch 1/200] [Batch 250/938] [D loss: -2.318583] [G loss: -16.656063]\n",
            "[Epoch 1/200] [Batch 255/938] [D loss: -2.753618] [G loss: -16.669527]\n",
            "[Epoch 1/200] [Batch 260/938] [D loss: -2.261665] [G loss: -16.560545]\n",
            "[Epoch 1/200] [Batch 265/938] [D loss: -2.671051] [G loss: -16.586445]\n",
            "[Epoch 1/200] [Batch 270/938] [D loss: -2.261581] [G loss: -16.428699]\n",
            "[Epoch 1/200] [Batch 275/938] [D loss: -1.700085] [G loss: -16.558752]\n",
            "[Epoch 1/200] [Batch 280/938] [D loss: -1.892626] [G loss: -16.570683]\n",
            "[Epoch 1/200] [Batch 285/938] [D loss: -2.076632] [G loss: -16.355116]\n",
            "[Epoch 1/200] [Batch 290/938] [D loss: -1.737179] [G loss: -16.436073]\n",
            "[Epoch 1/200] [Batch 295/938] [D loss: -2.040003] [G loss: -16.496611]\n",
            "[Epoch 1/200] [Batch 300/938] [D loss: -1.541447] [G loss: -16.484880]\n",
            "[Epoch 1/200] [Batch 305/938] [D loss: -2.078436] [G loss: -16.440126]\n",
            "[Epoch 1/200] [Batch 310/938] [D loss: -2.096531] [G loss: -16.585829]\n",
            "[Epoch 1/200] [Batch 315/938] [D loss: -2.115685] [G loss: -16.435337]\n",
            "[Epoch 1/200] [Batch 320/938] [D loss: -1.783936] [G loss: -16.426229]\n",
            "[Epoch 1/200] [Batch 325/938] [D loss: -2.237736] [G loss: -16.444561]\n",
            "[Epoch 1/200] [Batch 330/938] [D loss: -1.923283] [G loss: -16.431986]\n",
            "[Epoch 1/200] [Batch 335/938] [D loss: -1.430311] [G loss: -16.417757]\n",
            "[Epoch 1/200] [Batch 340/938] [D loss: -1.600138] [G loss: -16.448057]\n",
            "[Epoch 1/200] [Batch 345/938] [D loss: -1.421238] [G loss: -16.417143]\n",
            "[Epoch 1/200] [Batch 350/938] [D loss: -2.016325] [G loss: -16.349545]\n",
            "[Epoch 1/200] [Batch 355/938] [D loss: -1.631117] [G loss: -16.371811]\n",
            "[Epoch 1/200] [Batch 360/938] [D loss: -1.654861] [G loss: -16.413300]\n",
            "[Epoch 1/200] [Batch 365/938] [D loss: -1.511343] [G loss: -16.457571]\n",
            "[Epoch 1/200] [Batch 370/938] [D loss: -1.225191] [G loss: -16.430576]\n",
            "[Epoch 1/200] [Batch 375/938] [D loss: -1.348667] [G loss: -16.429260]\n",
            "[Epoch 1/200] [Batch 380/938] [D loss: -1.495962] [G loss: -16.381794]\n",
            "[Epoch 1/200] [Batch 385/938] [D loss: -1.520279] [G loss: -16.379480]\n",
            "[Epoch 1/200] [Batch 390/938] [D loss: -1.254435] [G loss: -16.343296]\n",
            "[Epoch 1/200] [Batch 395/938] [D loss: -1.180302] [G loss: -16.416965]\n",
            "[Epoch 1/200] [Batch 400/938] [D loss: -1.724915] [G loss: -16.378609]\n",
            "[Epoch 1/200] [Batch 405/938] [D loss: -1.572392] [G loss: -16.302401]\n",
            "[Epoch 1/200] [Batch 410/938] [D loss: -1.761648] [G loss: -16.359535]\n",
            "[Epoch 1/200] [Batch 415/938] [D loss: -0.919260] [G loss: -16.403589]\n",
            "[Epoch 1/200] [Batch 420/938] [D loss: -1.086357] [G loss: -16.475536]\n",
            "[Epoch 1/200] [Batch 425/938] [D loss: -1.123722] [G loss: -16.471956]\n",
            "[Epoch 1/200] [Batch 430/938] [D loss: -1.461805] [G loss: -16.387615]\n",
            "[Epoch 1/200] [Batch 435/938] [D loss: -1.530035] [G loss: -16.331520]\n",
            "[Epoch 1/200] [Batch 440/938] [D loss: -1.323277] [G loss: -16.438559]\n",
            "[Epoch 1/200] [Batch 445/938] [D loss: -1.414431] [G loss: -16.460833]\n",
            "[Epoch 1/200] [Batch 450/938] [D loss: -1.273928] [G loss: -16.491013]\n",
            "[Epoch 1/200] [Batch 455/938] [D loss: -1.486975] [G loss: -16.340378]\n",
            "[Epoch 1/200] [Batch 460/938] [D loss: -0.878429] [G loss: -16.389322]\n",
            "[Epoch 1/200] [Batch 465/938] [D loss: -1.347099] [G loss: -16.338171]\n",
            "[Epoch 1/200] [Batch 470/938] [D loss: -1.438349] [G loss: -16.402071]\n",
            "[Epoch 1/200] [Batch 475/938] [D loss: -1.417744] [G loss: -16.430920]\n",
            "[Epoch 1/200] [Batch 480/938] [D loss: -1.761887] [G loss: -16.327887]\n",
            "[Epoch 1/200] [Batch 485/938] [D loss: -1.521179] [G loss: -16.151134]\n",
            "[Epoch 1/200] [Batch 490/938] [D loss: -1.654902] [G loss: -16.187977]\n",
            "[Epoch 1/200] [Batch 495/938] [D loss: -1.044981] [G loss: -16.375654]\n",
            "[Epoch 1/200] [Batch 500/938] [D loss: -1.065090] [G loss: -16.300642]\n",
            "[Epoch 1/200] [Batch 505/938] [D loss: -1.290201] [G loss: -16.314512]\n",
            "[Epoch 1/200] [Batch 510/938] [D loss: -1.255272] [G loss: -16.389807]\n",
            "[Epoch 1/200] [Batch 515/938] [D loss: -0.841019] [G loss: -16.446272]\n",
            "[Epoch 1/200] [Batch 520/938] [D loss: -1.228308] [G loss: -16.325718]\n",
            "[Epoch 1/200] [Batch 525/938] [D loss: -1.249310] [G loss: -16.428482]\n",
            "[Epoch 1/200] [Batch 530/938] [D loss: -1.121296] [G loss: -16.341961]\n",
            "[Epoch 1/200] [Batch 535/938] [D loss: -1.111660] [G loss: -16.244648]\n",
            "[Epoch 1/200] [Batch 540/938] [D loss: -0.537004] [G loss: -16.442337]\n",
            "[Epoch 1/200] [Batch 545/938] [D loss: -0.953007] [G loss: -16.508749]\n",
            "[Epoch 1/200] [Batch 550/938] [D loss: -0.591494] [G loss: -16.540844]\n",
            "[Epoch 1/200] [Batch 555/938] [D loss: -1.157885] [G loss: -16.330193]\n",
            "[Epoch 1/200] [Batch 560/938] [D loss: -0.769535] [G loss: -16.447063]\n",
            "[Epoch 1/200] [Batch 565/938] [D loss: -1.072018] [G loss: -16.430380]\n",
            "[Epoch 1/200] [Batch 570/938] [D loss: -0.912651] [G loss: -16.394537]\n",
            "[Epoch 1/200] [Batch 575/938] [D loss: -1.016777] [G loss: -16.447105]\n",
            "[Epoch 1/200] [Batch 580/938] [D loss: -1.081598] [G loss: -16.503092]\n",
            "[Epoch 1/200] [Batch 585/938] [D loss: -1.138123] [G loss: -16.457214]\n",
            "[Epoch 1/200] [Batch 590/938] [D loss: -0.804768] [G loss: -16.551517]\n",
            "[Epoch 1/200] [Batch 595/938] [D loss: -1.041225] [G loss: -16.428770]\n",
            "[Epoch 1/200] [Batch 600/938] [D loss: -1.037508] [G loss: -16.554630]\n",
            "[Epoch 1/200] [Batch 605/938] [D loss: -0.936745] [G loss: -16.448484]\n",
            "[Epoch 1/200] [Batch 610/938] [D loss: -0.667349] [G loss: -16.518574]\n",
            "[Epoch 1/200] [Batch 615/938] [D loss: -0.646566] [G loss: -16.592350]\n",
            "[Epoch 1/200] [Batch 620/938] [D loss: -0.553467] [G loss: -16.608467]\n",
            "[Epoch 1/200] [Batch 625/938] [D loss: -1.096504] [G loss: -16.653172]\n",
            "[Epoch 1/200] [Batch 630/938] [D loss: -0.828489] [G loss: -16.624523]\n",
            "[Epoch 1/200] [Batch 635/938] [D loss: -0.784266] [G loss: -16.609173]\n",
            "[Epoch 1/200] [Batch 640/938] [D loss: -0.947737] [G loss: -16.628466]\n",
            "[Epoch 1/200] [Batch 645/938] [D loss: -0.667475] [G loss: -16.732306]\n",
            "[Epoch 1/200] [Batch 650/938] [D loss: -0.636639] [G loss: -16.651850]\n",
            "[Epoch 1/200] [Batch 655/938] [D loss: -0.988594] [G loss: -16.609819]\n",
            "[Epoch 1/200] [Batch 660/938] [D loss: -0.493734] [G loss: -16.623837]\n",
            "[Epoch 1/200] [Batch 665/938] [D loss: -0.898726] [G loss: -16.603374]\n",
            "[Epoch 1/200] [Batch 670/938] [D loss: -0.555542] [G loss: -16.715717]\n",
            "[Epoch 1/200] [Batch 675/938] [D loss: -0.617617] [G loss: -16.740923]\n",
            "[Epoch 1/200] [Batch 680/938] [D loss: -0.669973] [G loss: -16.741941]\n",
            "[Epoch 1/200] [Batch 685/938] [D loss: -0.865030] [G loss: -16.701317]\n",
            "[Epoch 1/200] [Batch 690/938] [D loss: -0.731829] [G loss: -16.684992]\n",
            "[Epoch 1/200] [Batch 695/938] [D loss: -0.611271] [G loss: -16.654043]\n",
            "[Epoch 1/200] [Batch 700/938] [D loss: -0.745569] [G loss: -16.679932]\n",
            "[Epoch 1/200] [Batch 705/938] [D loss: -0.944511] [G loss: -16.710215]\n",
            "[Epoch 1/200] [Batch 710/938] [D loss: -0.502060] [G loss: -16.708204]\n",
            "[Epoch 1/200] [Batch 715/938] [D loss: -0.669289] [G loss: -16.693823]\n",
            "[Epoch 1/200] [Batch 720/938] [D loss: -0.628187] [G loss: -16.836718]\n",
            "[Epoch 1/200] [Batch 725/938] [D loss: -0.885448] [G loss: -16.781477]\n",
            "[Epoch 1/200] [Batch 730/938] [D loss: -0.501949] [G loss: -16.876541]\n",
            "[Epoch 1/200] [Batch 735/938] [D loss: -0.559053] [G loss: -16.892641]\n",
            "[Epoch 1/200] [Batch 740/938] [D loss: -0.985197] [G loss: -16.808666]\n",
            "[Epoch 1/200] [Batch 745/938] [D loss: -0.572315] [G loss: -16.756390]\n",
            "[Epoch 1/200] [Batch 750/938] [D loss: -0.530396] [G loss: -16.842764]\n",
            "[Epoch 1/200] [Batch 755/938] [D loss: -0.722012] [G loss: -16.830261]\n",
            "[Epoch 1/200] [Batch 760/938] [D loss: -0.368763] [G loss: -16.913391]\n",
            "[Epoch 1/200] [Batch 765/938] [D loss: -0.478174] [G loss: -16.934549]\n",
            "[Epoch 1/200] [Batch 770/938] [D loss: -0.635695] [G loss: -16.871202]\n",
            "[Epoch 1/200] [Batch 775/938] [D loss: -0.338581] [G loss: -16.931978]\n",
            "[Epoch 1/200] [Batch 780/938] [D loss: -0.578644] [G loss: -16.861061]\n",
            "[Epoch 1/200] [Batch 785/938] [D loss: -0.566681] [G loss: -16.935789]\n",
            "[Epoch 1/200] [Batch 790/938] [D loss: -0.465940] [G loss: -17.020441]\n",
            "[Epoch 1/200] [Batch 795/938] [D loss: -0.615486] [G loss: -16.945787]\n",
            "[Epoch 1/200] [Batch 800/938] [D loss: -0.602810] [G loss: -16.906675]\n",
            "[Epoch 1/200] [Batch 805/938] [D loss: -0.450783] [G loss: -16.971842]\n",
            "[Epoch 1/200] [Batch 810/938] [D loss: -0.510399] [G loss: -16.976915]\n",
            "[Epoch 1/200] [Batch 815/938] [D loss: -0.473053] [G loss: -16.993376]\n",
            "[Epoch 1/200] [Batch 820/938] [D loss: -0.321314] [G loss: -17.095255]\n",
            "[Epoch 1/200] [Batch 825/938] [D loss: -0.436556] [G loss: -17.018297]\n",
            "[Epoch 1/200] [Batch 830/938] [D loss: -0.414675] [G loss: -16.985876]\n",
            "[Epoch 1/200] [Batch 835/938] [D loss: -0.433945] [G loss: -16.918901]\n",
            "[Epoch 1/200] [Batch 840/938] [D loss: -0.261600] [G loss: -17.063074]\n",
            "[Epoch 1/200] [Batch 845/938] [D loss: -0.388611] [G loss: -16.965397]\n",
            "[Epoch 1/200] [Batch 850/938] [D loss: -0.531984] [G loss: -17.108624]\n",
            "[Epoch 1/200] [Batch 855/938] [D loss: -0.477200] [G loss: -17.057804]\n",
            "[Epoch 1/200] [Batch 860/938] [D loss: -0.302015] [G loss: -16.993378]\n",
            "[Epoch 1/200] [Batch 865/938] [D loss: -0.449291] [G loss: -16.905724]\n",
            "[Epoch 1/200] [Batch 870/938] [D loss: -0.633474] [G loss: -16.929794]\n",
            "[Epoch 1/200] [Batch 875/938] [D loss: -0.549232] [G loss: -16.890362]\n",
            "[Epoch 1/200] [Batch 880/938] [D loss: -0.415594] [G loss: -16.981037]\n",
            "[Epoch 1/200] [Batch 885/938] [D loss: -0.342920] [G loss: -17.020285]\n",
            "[Epoch 1/200] [Batch 890/938] [D loss: -0.735550] [G loss: -16.927410]\n",
            "[Epoch 1/200] [Batch 895/938] [D loss: -0.494627] [G loss: -16.970900]\n",
            "[Epoch 1/200] [Batch 900/938] [D loss: -0.543873] [G loss: -16.933538]\n",
            "[Epoch 1/200] [Batch 905/938] [D loss: -0.292294] [G loss: -16.871996]\n",
            "[Epoch 1/200] [Batch 910/938] [D loss: -0.329161] [G loss: -16.908993]\n",
            "[Epoch 1/200] [Batch 915/938] [D loss: -0.466887] [G loss: -16.780447]\n",
            "[Epoch 1/200] [Batch 920/938] [D loss: -0.543373] [G loss: -16.662094]\n",
            "[Epoch 1/200] [Batch 925/938] [D loss: -0.649628] [G loss: -16.620424]\n",
            "[Epoch 1/200] [Batch 930/938] [D loss: -0.610355] [G loss: -16.661570]\n",
            "[Epoch 1/200] [Batch 935/938] [D loss: -0.503386] [G loss: -16.789259]\n",
            "[Epoch 2/200] [Batch 0/938] [D loss: -0.488289] [G loss: -16.858240]\n",
            "[Epoch 2/200] [Batch 5/938] [D loss: -0.400166] [G loss: -16.736839]\n",
            "[Epoch 2/200] [Batch 10/938] [D loss: -0.468651] [G loss: -16.742340]\n",
            "[Epoch 2/200] [Batch 15/938] [D loss: -0.451756] [G loss: -16.732460]\n",
            "[Epoch 2/200] [Batch 20/938] [D loss: -0.520880] [G loss: -16.639328]\n",
            "[Epoch 2/200] [Batch 25/938] [D loss: -0.405979] [G loss: -16.768982]\n",
            "[Epoch 2/200] [Batch 30/938] [D loss: -0.474047] [G loss: -16.689190]\n",
            "[Epoch 2/200] [Batch 35/938] [D loss: -0.545757] [G loss: -16.694605]\n",
            "[Epoch 2/200] [Batch 40/938] [D loss: -0.355680] [G loss: -16.527948]\n",
            "[Epoch 2/200] [Batch 45/938] [D loss: -0.387905] [G loss: -16.628925]\n",
            "[Epoch 2/200] [Batch 50/938] [D loss: -0.573036] [G loss: -16.559406]\n",
            "[Epoch 2/200] [Batch 55/938] [D loss: -0.281267] [G loss: -16.576666]\n",
            "[Epoch 2/200] [Batch 60/938] [D loss: -0.351614] [G loss: -16.481653]\n",
            "[Epoch 2/200] [Batch 65/938] [D loss: -0.536104] [G loss: -16.430664]\n",
            "[Epoch 2/200] [Batch 70/938] [D loss: -0.483892] [G loss: -16.383299]\n",
            "[Epoch 2/200] [Batch 75/938] [D loss: -0.447290] [G loss: -16.385660]\n",
            "[Epoch 2/200] [Batch 80/938] [D loss: -0.394915] [G loss: -16.372919]\n",
            "[Epoch 2/200] [Batch 85/938] [D loss: -0.499678] [G loss: -16.297493]\n",
            "[Epoch 2/200] [Batch 90/938] [D loss: -0.483519] [G loss: -16.294985]\n",
            "[Epoch 2/200] [Batch 95/938] [D loss: -0.358278] [G loss: -16.262465]\n",
            "[Epoch 2/200] [Batch 100/938] [D loss: -0.540058] [G loss: -16.264412]\n",
            "[Epoch 2/200] [Batch 105/938] [D loss: -0.366434] [G loss: -16.356493]\n",
            "[Epoch 2/200] [Batch 110/938] [D loss: -0.470783] [G loss: -16.343819]\n",
            "[Epoch 2/200] [Batch 115/938] [D loss: -0.492615] [G loss: -16.312086]\n",
            "[Epoch 2/200] [Batch 120/938] [D loss: -0.265541] [G loss: -16.290413]\n",
            "[Epoch 2/200] [Batch 125/938] [D loss: -0.493477] [G loss: -16.183701]\n",
            "[Epoch 2/200] [Batch 130/938] [D loss: -0.393927] [G loss: -16.128735]\n",
            "[Epoch 2/200] [Batch 135/938] [D loss: -0.351749] [G loss: -16.099503]\n",
            "[Epoch 2/200] [Batch 140/938] [D loss: -0.458540] [G loss: -16.068508]\n",
            "[Epoch 2/200] [Batch 145/938] [D loss: -0.370590] [G loss: -16.010452]\n",
            "[Epoch 2/200] [Batch 150/938] [D loss: -0.329885] [G loss: -15.986688]\n",
            "[Epoch 2/200] [Batch 155/938] [D loss: -0.293720] [G loss: -15.965155]\n",
            "[Epoch 2/200] [Batch 160/938] [D loss: -0.476405] [G loss: -15.952688]\n",
            "[Epoch 2/200] [Batch 165/938] [D loss: -0.318921] [G loss: -15.884316]\n",
            "[Epoch 2/200] [Batch 170/938] [D loss: -0.415411] [G loss: -15.812552]\n",
            "[Epoch 2/200] [Batch 175/938] [D loss: -0.418304] [G loss: -15.860857]\n",
            "[Epoch 2/200] [Batch 180/938] [D loss: -0.365626] [G loss: -15.775026]\n",
            "[Epoch 2/200] [Batch 185/938] [D loss: -0.354300] [G loss: -15.716351]\n",
            "[Epoch 2/200] [Batch 190/938] [D loss: -0.361387] [G loss: -15.718363]\n",
            "[Epoch 2/200] [Batch 195/938] [D loss: -0.349514] [G loss: -15.579571]\n",
            "[Epoch 2/200] [Batch 200/938] [D loss: -0.369852] [G loss: -15.538959]\n",
            "[Epoch 2/200] [Batch 205/938] [D loss: -0.331255] [G loss: -15.517567]\n",
            "[Epoch 2/200] [Batch 210/938] [D loss: -0.333386] [G loss: -15.440361]\n",
            "[Epoch 2/200] [Batch 215/938] [D loss: -0.263810] [G loss: -15.442183]\n",
            "[Epoch 2/200] [Batch 220/938] [D loss: -0.427967] [G loss: -15.400104]\n",
            "[Epoch 2/200] [Batch 225/938] [D loss: -0.211598] [G loss: -15.368314]\n",
            "[Epoch 2/200] [Batch 230/938] [D loss: -0.326596] [G loss: -15.296332]\n",
            "[Epoch 2/200] [Batch 235/938] [D loss: -0.361731] [G loss: -15.244064]\n",
            "[Epoch 2/200] [Batch 240/938] [D loss: -0.280906] [G loss: -15.230502]\n",
            "[Epoch 2/200] [Batch 245/938] [D loss: -0.524868] [G loss: -15.187156]\n",
            "[Epoch 2/200] [Batch 250/938] [D loss: -0.429040] [G loss: -15.186242]\n",
            "[Epoch 2/200] [Batch 255/938] [D loss: -0.382610] [G loss: -15.131272]\n",
            "[Epoch 2/200] [Batch 260/938] [D loss: -0.272444] [G loss: -15.139451]\n",
            "[Epoch 2/200] [Batch 265/938] [D loss: -0.377137] [G loss: -15.129224]\n",
            "[Epoch 2/200] [Batch 270/938] [D loss: -0.314528] [G loss: -15.066397]\n",
            "[Epoch 2/200] [Batch 275/938] [D loss: -0.382466] [G loss: -15.001985]\n",
            "[Epoch 2/200] [Batch 280/938] [D loss: -0.329659] [G loss: -14.927193]\n",
            "[Epoch 2/200] [Batch 285/938] [D loss: -0.327604] [G loss: -14.819384]\n",
            "[Epoch 2/200] [Batch 290/938] [D loss: -0.317462] [G loss: -14.782692]\n",
            "[Epoch 2/200] [Batch 295/938] [D loss: -0.374825] [G loss: -14.706041]\n",
            "[Epoch 2/200] [Batch 300/938] [D loss: -0.454037] [G loss: -14.644032]\n",
            "[Epoch 2/200] [Batch 305/938] [D loss: -0.205808] [G loss: -14.590650]\n",
            "[Epoch 2/200] [Batch 310/938] [D loss: -0.332252] [G loss: -14.586039]\n",
            "[Epoch 2/200] [Batch 315/938] [D loss: -0.352432] [G loss: -14.569687]\n",
            "[Epoch 2/200] [Batch 320/938] [D loss: -0.264630] [G loss: -14.545611]\n",
            "[Epoch 2/200] [Batch 325/938] [D loss: -0.284193] [G loss: -14.542650]\n",
            "[Epoch 2/200] [Batch 330/938] [D loss: -0.170294] [G loss: -14.545677]\n",
            "[Epoch 2/200] [Batch 335/938] [D loss: -0.240858] [G loss: -14.514154]\n",
            "[Epoch 2/200] [Batch 340/938] [D loss: -0.103114] [G loss: -14.505459]\n",
            "[Epoch 2/200] [Batch 345/938] [D loss: -0.219721] [G loss: -14.473385]\n",
            "[Epoch 2/200] [Batch 350/938] [D loss: -0.216306] [G loss: -14.482475]\n",
            "[Epoch 2/200] [Batch 355/938] [D loss: -0.050692] [G loss: -14.399737]\n",
            "[Epoch 2/200] [Batch 360/938] [D loss: -0.274264] [G loss: -14.401626]\n",
            "[Epoch 2/200] [Batch 365/938] [D loss: -0.253738] [G loss: -14.442174]\n",
            "[Epoch 2/200] [Batch 370/938] [D loss: -0.200004] [G loss: -14.409549]\n",
            "[Epoch 2/200] [Batch 375/938] [D loss: -0.320897] [G loss: -14.394972]\n",
            "[Epoch 2/200] [Batch 380/938] [D loss: -0.106786] [G loss: -14.350561]\n",
            "[Epoch 2/200] [Batch 385/938] [D loss: -0.180589] [G loss: -14.345133]\n",
            "[Epoch 2/200] [Batch 390/938] [D loss: -0.108462] [G loss: -14.330166]\n",
            "[Epoch 2/200] [Batch 395/938] [D loss: -0.210313] [G loss: -14.256094]\n",
            "[Epoch 2/200] [Batch 400/938] [D loss: -0.117743] [G loss: -14.294706]\n",
            "[Epoch 2/200] [Batch 405/938] [D loss: -0.432408] [G loss: -14.215143]\n",
            "[Epoch 2/200] [Batch 410/938] [D loss: -0.331215] [G loss: -14.217001]\n",
            "[Epoch 2/200] [Batch 415/938] [D loss: -0.136948] [G loss: -14.195354]\n",
            "[Epoch 2/200] [Batch 420/938] [D loss: -0.334984] [G loss: -14.186944]\n",
            "[Epoch 2/200] [Batch 425/938] [D loss: -0.304904] [G loss: -14.206512]\n",
            "[Epoch 2/200] [Batch 430/938] [D loss: -0.273677] [G loss: -14.127834]\n",
            "[Epoch 2/200] [Batch 435/938] [D loss: -0.037217] [G loss: -14.023394]\n",
            "[Epoch 2/200] [Batch 440/938] [D loss: -0.275479] [G loss: -14.057633]\n",
            "[Epoch 2/200] [Batch 445/938] [D loss: -0.256158] [G loss: -14.102164]\n",
            "[Epoch 2/200] [Batch 450/938] [D loss: -0.175806] [G loss: -14.068317]\n",
            "[Epoch 2/200] [Batch 455/938] [D loss: -0.332277] [G loss: -14.093103]\n",
            "[Epoch 2/200] [Batch 460/938] [D loss: -0.200689] [G loss: -14.068001]\n",
            "[Epoch 2/200] [Batch 465/938] [D loss: -0.177943] [G loss: -14.076322]\n",
            "[Epoch 2/200] [Batch 470/938] [D loss: -0.282427] [G loss: -14.136803]\n",
            "[Epoch 2/200] [Batch 475/938] [D loss: -0.214319] [G loss: -14.133208]\n",
            "[Epoch 2/200] [Batch 480/938] [D loss: -0.350601] [G loss: -14.142965]\n",
            "[Epoch 2/200] [Batch 485/938] [D loss: -0.173684] [G loss: -14.243149]\n",
            "[Epoch 2/200] [Batch 490/938] [D loss: -0.160734] [G loss: -14.183152]\n",
            "[Epoch 2/200] [Batch 495/938] [D loss: -0.172758] [G loss: -14.209287]\n",
            "[Epoch 2/200] [Batch 500/938] [D loss: -0.163768] [G loss: -14.140858]\n",
            "[Epoch 2/200] [Batch 505/938] [D loss: -0.215077] [G loss: -14.097424]\n",
            "[Epoch 2/200] [Batch 510/938] [D loss: -0.299243] [G loss: -14.040174]\n",
            "[Epoch 2/200] [Batch 515/938] [D loss: -0.083647] [G loss: -14.095639]\n",
            "[Epoch 2/200] [Batch 520/938] [D loss: -0.102280] [G loss: -14.162011]\n",
            "[Epoch 2/200] [Batch 525/938] [D loss: -0.280670] [G loss: -14.160519]\n",
            "[Epoch 2/200] [Batch 530/938] [D loss: -0.280431] [G loss: -14.187561]\n",
            "[Epoch 2/200] [Batch 535/938] [D loss: -0.252735] [G loss: -14.183277]\n",
            "[Epoch 2/200] [Batch 540/938] [D loss: -0.172960] [G loss: -14.166831]\n",
            "[Epoch 2/200] [Batch 545/938] [D loss: -0.238924] [G loss: -14.158126]\n",
            "[Epoch 2/200] [Batch 550/938] [D loss: -0.332818] [G loss: -14.137952]\n",
            "[Epoch 2/200] [Batch 555/938] [D loss: -0.244676] [G loss: -14.087287]\n",
            "[Epoch 2/200] [Batch 560/938] [D loss: -0.150926] [G loss: -14.079502]\n",
            "[Epoch 2/200] [Batch 565/938] [D loss: -0.112838] [G loss: -14.087113]\n",
            "[Epoch 2/200] [Batch 570/938] [D loss: -0.343844] [G loss: -14.108478]\n",
            "[Epoch 2/200] [Batch 575/938] [D loss: -0.118335] [G loss: -14.118729]\n",
            "[Epoch 2/200] [Batch 580/938] [D loss: -0.273596] [G loss: -14.123281]\n",
            "[Epoch 2/200] [Batch 585/938] [D loss: -0.392721] [G loss: -14.085964]\n",
            "[Epoch 2/200] [Batch 590/938] [D loss: -0.321500] [G loss: -14.156281]\n",
            "[Epoch 2/200] [Batch 595/938] [D loss: -0.317677] [G loss: -14.154882]\n",
            "[Epoch 2/200] [Batch 600/938] [D loss: -0.364607] [G loss: -14.121854]\n",
            "[Epoch 2/200] [Batch 605/938] [D loss: -0.381559] [G loss: -14.064608]\n",
            "[Epoch 2/200] [Batch 610/938] [D loss: -0.157553] [G loss: -14.086458]\n",
            "[Epoch 2/200] [Batch 615/938] [D loss: -0.235895] [G loss: -14.168378]\n",
            "[Epoch 2/200] [Batch 620/938] [D loss: -0.140697] [G loss: -14.168725]\n",
            "[Epoch 2/200] [Batch 625/938] [D loss: -0.211594] [G loss: -14.155791]\n",
            "[Epoch 2/200] [Batch 630/938] [D loss: -0.366552] [G loss: -14.158112]\n",
            "[Epoch 2/200] [Batch 635/938] [D loss: -0.049600] [G loss: -14.187518]\n",
            "[Epoch 2/200] [Batch 640/938] [D loss: -0.204783] [G loss: -14.192343]\n",
            "[Epoch 2/200] [Batch 645/938] [D loss: -0.158118] [G loss: -14.186284]\n",
            "[Epoch 2/200] [Batch 650/938] [D loss: -0.213844] [G loss: -14.211945]\n",
            "[Epoch 2/200] [Batch 655/938] [D loss: -0.251475] [G loss: -14.221515]\n",
            "[Epoch 2/200] [Batch 660/938] [D loss: -0.216268] [G loss: -14.170244]\n",
            "[Epoch 2/200] [Batch 665/938] [D loss: -0.198137] [G loss: -14.248259]\n",
            "[Epoch 2/200] [Batch 670/938] [D loss: -0.214620] [G loss: -14.255389]\n",
            "[Epoch 2/200] [Batch 675/938] [D loss: -0.161243] [G loss: -14.333448]\n",
            "[Epoch 2/200] [Batch 680/938] [D loss: -0.211843] [G loss: -14.235843]\n",
            "[Epoch 2/200] [Batch 685/938] [D loss: -0.281281] [G loss: -14.200551]\n",
            "[Epoch 2/200] [Batch 690/938] [D loss: -0.197177] [G loss: -14.182682]\n",
            "[Epoch 2/200] [Batch 695/938] [D loss: -0.229826] [G loss: -14.181058]\n",
            "[Epoch 2/200] [Batch 700/938] [D loss: -0.087689] [G loss: -14.278253]\n",
            "[Epoch 2/200] [Batch 705/938] [D loss: -0.116190] [G loss: -14.242646]\n",
            "[Epoch 2/200] [Batch 710/938] [D loss: -0.171924] [G loss: -14.238396]\n",
            "[Epoch 2/200] [Batch 715/938] [D loss: -0.181740] [G loss: -14.265393]\n",
            "[Epoch 2/200] [Batch 720/938] [D loss: -0.258878] [G loss: -14.195642]\n",
            "[Epoch 2/200] [Batch 725/938] [D loss: -0.153855] [G loss: -14.285788]\n",
            "[Epoch 2/200] [Batch 730/938] [D loss: -0.127019] [G loss: -14.263649]\n",
            "[Epoch 2/200] [Batch 735/938] [D loss: -0.089998] [G loss: -14.211001]\n",
            "[Epoch 2/200] [Batch 740/938] [D loss: -0.147640] [G loss: -14.240882]\n",
            "[Epoch 2/200] [Batch 745/938] [D loss: -0.035579] [G loss: -14.204467]\n",
            "[Epoch 2/200] [Batch 750/938] [D loss: -0.142326] [G loss: -14.102356]\n",
            "[Epoch 2/200] [Batch 755/938] [D loss: -0.140320] [G loss: -14.106392]\n",
            "[Epoch 2/200] [Batch 760/938] [D loss: -0.125421] [G loss: -14.098579]\n",
            "[Epoch 2/200] [Batch 765/938] [D loss: -0.065136] [G loss: -14.143000]\n",
            "[Epoch 2/200] [Batch 770/938] [D loss: -0.155840] [G loss: -14.145113]\n",
            "[Epoch 2/200] [Batch 775/938] [D loss: 0.008814] [G loss: -14.158754]\n",
            "[Epoch 2/200] [Batch 780/938] [D loss: -0.193232] [G loss: -14.158233]\n",
            "[Epoch 2/200] [Batch 785/938] [D loss: 0.022891] [G loss: -14.049820]\n",
            "[Epoch 2/200] [Batch 790/938] [D loss: -0.121220] [G loss: -14.009628]\n",
            "[Epoch 2/200] [Batch 795/938] [D loss: -0.080195] [G loss: -13.927408]\n",
            "[Epoch 2/200] [Batch 800/938] [D loss: -0.109186] [G loss: -13.871418]\n",
            "[Epoch 2/200] [Batch 805/938] [D loss: -0.005944] [G loss: -13.829298]\n",
            "[Epoch 2/200] [Batch 810/938] [D loss: -0.123347] [G loss: -13.781883]\n",
            "[Epoch 2/200] [Batch 815/938] [D loss: -0.168383] [G loss: -13.800166]\n",
            "[Epoch 2/200] [Batch 820/938] [D loss: -0.126901] [G loss: -13.825125]\n",
            "[Epoch 2/200] [Batch 825/938] [D loss: -0.186236] [G loss: -13.850578]\n",
            "[Epoch 2/200] [Batch 830/938] [D loss: -0.147615] [G loss: -13.729076]\n",
            "[Epoch 2/200] [Batch 835/938] [D loss: -0.105190] [G loss: -13.769447]\n",
            "[Epoch 2/200] [Batch 840/938] [D loss: -0.101438] [G loss: -13.789394]\n",
            "[Epoch 2/200] [Batch 845/938] [D loss: -0.097168] [G loss: -13.754834]\n",
            "[Epoch 2/200] [Batch 850/938] [D loss: -0.156770] [G loss: -13.749117]\n",
            "[Epoch 2/200] [Batch 855/938] [D loss: -0.131277] [G loss: -13.720019]\n",
            "[Epoch 2/200] [Batch 860/938] [D loss: -0.079263] [G loss: -13.628290]\n",
            "[Epoch 2/200] [Batch 865/938] [D loss: 0.001689] [G loss: -13.573965]\n",
            "[Epoch 2/200] [Batch 870/938] [D loss: -0.089634] [G loss: -13.544233]\n",
            "[Epoch 2/200] [Batch 875/938] [D loss: -0.142282] [G loss: -13.507540]\n",
            "[Epoch 2/200] [Batch 880/938] [D loss: -0.122998] [G loss: -13.521249]\n",
            "[Epoch 2/200] [Batch 885/938] [D loss: -0.140211] [G loss: -13.439403]\n",
            "[Epoch 2/200] [Batch 890/938] [D loss: -0.154071] [G loss: -13.436051]\n",
            "[Epoch 2/200] [Batch 895/938] [D loss: -0.206097] [G loss: -13.382780]\n",
            "[Epoch 2/200] [Batch 900/938] [D loss: -0.065066] [G loss: -13.345459]\n",
            "[Epoch 2/200] [Batch 905/938] [D loss: -0.182483] [G loss: -13.350718]\n",
            "[Epoch 2/200] [Batch 910/938] [D loss: -0.018601] [G loss: -13.343287]\n",
            "[Epoch 2/200] [Batch 915/938] [D loss: -0.208548] [G loss: -13.232127]\n",
            "[Epoch 2/200] [Batch 920/938] [D loss: -0.092629] [G loss: -13.183702]\n",
            "[Epoch 2/200] [Batch 925/938] [D loss: -0.186935] [G loss: -13.148750]\n",
            "[Epoch 2/200] [Batch 930/938] [D loss: -0.127790] [G loss: -13.158129]\n",
            "[Epoch 2/200] [Batch 935/938] [D loss: -0.144271] [G loss: -13.125747]\n",
            "[Epoch 3/200] [Batch 0/938] [D loss: -0.159615] [G loss: -13.060790]\n",
            "[Epoch 3/200] [Batch 5/938] [D loss: -0.148326] [G loss: -13.040145]\n",
            "[Epoch 3/200] [Batch 10/938] [D loss: -0.126998] [G loss: -13.013412]\n",
            "[Epoch 3/200] [Batch 15/938] [D loss: -0.136008] [G loss: -12.966408]\n",
            "[Epoch 3/200] [Batch 20/938] [D loss: -0.195543] [G loss: -12.974389]\n",
            "[Epoch 3/200] [Batch 25/938] [D loss: -0.117103] [G loss: -12.892087]\n",
            "[Epoch 3/200] [Batch 30/938] [D loss: -0.136177] [G loss: -12.888163]\n",
            "[Epoch 3/200] [Batch 35/938] [D loss: -0.094267] [G loss: -12.862965]\n",
            "[Epoch 3/200] [Batch 40/938] [D loss: -0.178241] [G loss: -12.831502]\n",
            "[Epoch 3/200] [Batch 45/938] [D loss: -0.057307] [G loss: -12.840962]\n",
            "[Epoch 3/200] [Batch 50/938] [D loss: -0.103819] [G loss: -12.801165]\n",
            "[Epoch 3/200] [Batch 55/938] [D loss: -0.218513] [G loss: -12.821047]\n",
            "[Epoch 3/200] [Batch 60/938] [D loss: -0.173002] [G loss: -12.794155]\n",
            "[Epoch 3/200] [Batch 65/938] [D loss: -0.173494] [G loss: -12.839940]\n",
            "[Epoch 3/200] [Batch 70/938] [D loss: -0.145842] [G loss: -12.882098]\n",
            "[Epoch 3/200] [Batch 75/938] [D loss: -0.043010] [G loss: -12.873212]\n",
            "[Epoch 3/200] [Batch 80/938] [D loss: -0.088628] [G loss: -12.860686]\n",
            "[Epoch 3/200] [Batch 85/938] [D loss: -0.109529] [G loss: -12.861051]\n",
            "[Epoch 3/200] [Batch 90/938] [D loss: -0.194360] [G loss: -12.762533]\n",
            "[Epoch 3/200] [Batch 95/938] [D loss: -0.104370] [G loss: -12.850112]\n",
            "[Epoch 3/200] [Batch 100/938] [D loss: 0.001765] [G loss: -12.840060]\n",
            "[Epoch 3/200] [Batch 105/938] [D loss: -0.125753] [G loss: -12.842809]\n",
            "[Epoch 3/200] [Batch 110/938] [D loss: -0.130813] [G loss: -12.834452]\n",
            "[Epoch 3/200] [Batch 115/938] [D loss: -0.093249] [G loss: -12.873062]\n",
            "[Epoch 3/200] [Batch 120/938] [D loss: -0.154483] [G loss: -12.834675]\n",
            "[Epoch 3/200] [Batch 125/938] [D loss: -0.059626] [G loss: -12.842357]\n",
            "[Epoch 3/200] [Batch 130/938] [D loss: -0.036934] [G loss: -12.833610]\n",
            "[Epoch 3/200] [Batch 135/938] [D loss: 0.022630] [G loss: -12.863301]\n",
            "[Epoch 3/200] [Batch 140/938] [D loss: -0.027050] [G loss: -12.821096]\n",
            "[Epoch 3/200] [Batch 145/938] [D loss: -0.266045] [G loss: -12.803320]\n",
            "[Epoch 3/200] [Batch 150/938] [D loss: 0.015706] [G loss: -12.775300]\n",
            "[Epoch 3/200] [Batch 155/938] [D loss: -0.100419] [G loss: -12.792347]\n",
            "[Epoch 3/200] [Batch 160/938] [D loss: -0.157934] [G loss: -12.760713]\n",
            "[Epoch 3/200] [Batch 165/938] [D loss: -0.050792] [G loss: -12.771657]\n",
            "[Epoch 3/200] [Batch 170/938] [D loss: -0.126308] [G loss: -12.777929]\n",
            "[Epoch 3/200] [Batch 175/938] [D loss: -0.111771] [G loss: -12.773490]\n",
            "[Epoch 3/200] [Batch 180/938] [D loss: -0.058458] [G loss: -12.823515]\n",
            "[Epoch 3/200] [Batch 185/938] [D loss: -0.055400] [G loss: -12.897110]\n",
            "[Epoch 3/200] [Batch 190/938] [D loss: -0.019782] [G loss: -12.938420]\n",
            "[Epoch 3/200] [Batch 195/938] [D loss: -0.166113] [G loss: -12.988081]\n",
            "[Epoch 3/200] [Batch 200/938] [D loss: -0.097097] [G loss: -13.020226]\n",
            "[Epoch 3/200] [Batch 205/938] [D loss: -0.095536] [G loss: -13.014178]\n",
            "[Epoch 3/200] [Batch 210/938] [D loss: -0.085900] [G loss: -13.031768]\n",
            "[Epoch 3/200] [Batch 215/938] [D loss: -0.053481] [G loss: -12.994892]\n",
            "[Epoch 3/200] [Batch 220/938] [D loss: -0.002403] [G loss: -13.083407]\n",
            "[Epoch 3/200] [Batch 225/938] [D loss: -0.070923] [G loss: -13.047724]\n",
            "[Epoch 3/200] [Batch 230/938] [D loss: -0.021605] [G loss: -13.059230]\n",
            "[Epoch 3/200] [Batch 235/938] [D loss: -0.071072] [G loss: -13.055926]\n",
            "[Epoch 3/200] [Batch 240/938] [D loss: -0.033716] [G loss: -13.134808]\n",
            "[Epoch 3/200] [Batch 245/938] [D loss: -0.062305] [G loss: -13.175215]\n",
            "[Epoch 3/200] [Batch 250/938] [D loss: -0.044025] [G loss: -13.242436]\n",
            "[Epoch 3/200] [Batch 255/938] [D loss: -0.009394] [G loss: -13.275020]\n",
            "[Epoch 3/200] [Batch 260/938] [D loss: -0.157905] [G loss: -13.224223]\n",
            "[Epoch 3/200] [Batch 265/938] [D loss: -0.036027] [G loss: -13.339841]\n",
            "[Epoch 3/200] [Batch 270/938] [D loss: -0.098830] [G loss: -13.328382]\n",
            "[Epoch 3/200] [Batch 275/938] [D loss: -0.068106] [G loss: -13.344887]\n",
            "[Epoch 3/200] [Batch 280/938] [D loss: -0.087206] [G loss: -13.343283]\n",
            "[Epoch 3/200] [Batch 285/938] [D loss: -0.066492] [G loss: -13.369234]\n",
            "[Epoch 3/200] [Batch 290/938] [D loss: -0.017970] [G loss: -13.396914]\n",
            "[Epoch 3/200] [Batch 295/938] [D loss: -0.028214] [G loss: -13.357326]\n",
            "[Epoch 3/200] [Batch 300/938] [D loss: -0.141040] [G loss: -13.410902]\n",
            "[Epoch 3/200] [Batch 305/938] [D loss: -0.034600] [G loss: -13.370906]\n",
            "[Epoch 3/200] [Batch 310/938] [D loss: -0.122448] [G loss: -13.414311]\n",
            "[Epoch 3/200] [Batch 315/938] [D loss: -0.111018] [G loss: -13.536732]\n",
            "[Epoch 3/200] [Batch 320/938] [D loss: -0.080438] [G loss: -13.516668]\n",
            "[Epoch 3/200] [Batch 325/938] [D loss: -0.082254] [G loss: -13.491706]\n",
            "[Epoch 3/200] [Batch 330/938] [D loss: -0.122438] [G loss: -13.461851]\n",
            "[Epoch 3/200] [Batch 335/938] [D loss: -0.049751] [G loss: -13.420762]\n",
            "[Epoch 3/200] [Batch 340/938] [D loss: -0.076472] [G loss: -13.491800]\n",
            "[Epoch 3/200] [Batch 345/938] [D loss: -0.122985] [G loss: -13.522108]\n",
            "[Epoch 3/200] [Batch 350/938] [D loss: -0.110580] [G loss: -13.540854]\n",
            "[Epoch 3/200] [Batch 355/938] [D loss: -0.013070] [G loss: -13.514539]\n",
            "[Epoch 3/200] [Batch 360/938] [D loss: -0.058789] [G loss: -13.547587]\n",
            "[Epoch 3/200] [Batch 365/938] [D loss: -0.078330] [G loss: -13.534896]\n",
            "[Epoch 3/200] [Batch 370/938] [D loss: -0.100861] [G loss: -13.617956]\n",
            "[Epoch 3/200] [Batch 375/938] [D loss: -0.104119] [G loss: -13.646961]\n",
            "[Epoch 3/200] [Batch 380/938] [D loss: 0.061845] [G loss: -13.546287]\n",
            "[Epoch 3/200] [Batch 385/938] [D loss: -0.202975] [G loss: -13.635763]\n",
            "[Epoch 3/200] [Batch 390/938] [D loss: -0.139341] [G loss: -13.660634]\n",
            "[Epoch 3/200] [Batch 395/938] [D loss: -0.070821] [G loss: -13.673365]\n",
            "[Epoch 3/200] [Batch 400/938] [D loss: -0.024872] [G loss: -13.634343]\n",
            "[Epoch 3/200] [Batch 405/938] [D loss: -0.054222] [G loss: -13.680422]\n",
            "[Epoch 3/200] [Batch 410/938] [D loss: -0.047554] [G loss: -13.724336]\n",
            "[Epoch 3/200] [Batch 415/938] [D loss: -0.169615] [G loss: -13.764407]\n",
            "[Epoch 3/200] [Batch 420/938] [D loss: -0.241497] [G loss: -13.726250]\n",
            "[Epoch 3/200] [Batch 425/938] [D loss: -0.127643] [G loss: -13.751655]\n",
            "[Epoch 3/200] [Batch 430/938] [D loss: -0.015294] [G loss: -13.789586]\n",
            "[Epoch 3/200] [Batch 435/938] [D loss: -0.052820] [G loss: -13.764282]\n",
            "[Epoch 3/200] [Batch 440/938] [D loss: -0.042380] [G loss: -13.702079]\n",
            "[Epoch 3/200] [Batch 445/938] [D loss: -0.087087] [G loss: -13.706692]\n",
            "[Epoch 3/200] [Batch 450/938] [D loss: -0.164973] [G loss: -13.725632]\n",
            "[Epoch 3/200] [Batch 455/938] [D loss: -0.142724] [G loss: -13.793071]\n",
            "[Epoch 3/200] [Batch 460/938] [D loss: -0.099868] [G loss: -13.843431]\n",
            "[Epoch 3/200] [Batch 465/938] [D loss: -0.070633] [G loss: -13.814606]\n",
            "[Epoch 3/200] [Batch 470/938] [D loss: -0.009264] [G loss: -13.840043]\n",
            "[Epoch 3/200] [Batch 475/938] [D loss: -0.023310] [G loss: -13.817839]\n",
            "[Epoch 3/200] [Batch 480/938] [D loss: -0.069624] [G loss: -13.764300]\n",
            "[Epoch 3/200] [Batch 485/938] [D loss: -0.006542] [G loss: -13.688214]\n",
            "[Epoch 3/200] [Batch 490/938] [D loss: -0.036715] [G loss: -13.671689]\n",
            "[Epoch 3/200] [Batch 495/938] [D loss: 0.012724] [G loss: -13.553155]\n",
            "[Epoch 3/200] [Batch 500/938] [D loss: -0.040646] [G loss: -13.634241]\n",
            "[Epoch 3/200] [Batch 505/938] [D loss: -0.070109] [G loss: -13.685360]\n",
            "[Epoch 3/200] [Batch 510/938] [D loss: -0.049687] [G loss: -13.601844]\n",
            "[Epoch 3/200] [Batch 515/938] [D loss: -0.102522] [G loss: -13.577808]\n",
            "[Epoch 3/200] [Batch 520/938] [D loss: -0.093076] [G loss: -13.452532]\n",
            "[Epoch 3/200] [Batch 525/938] [D loss: -0.042939] [G loss: -13.363778]\n",
            "[Epoch 3/200] [Batch 530/938] [D loss: -0.005321] [G loss: -13.479600]\n",
            "[Epoch 3/200] [Batch 535/938] [D loss: 0.025411] [G loss: -13.241617]\n",
            "[Epoch 3/200] [Batch 540/938] [D loss: -0.080195] [G loss: -13.376706]\n",
            "[Epoch 3/200] [Batch 545/938] [D loss: -0.019176] [G loss: -13.373959]\n",
            "[Epoch 3/200] [Batch 550/938] [D loss: -0.059287] [G loss: -13.244341]\n",
            "[Epoch 3/200] [Batch 555/938] [D loss: 0.047605] [G loss: -13.174234]\n",
            "[Epoch 3/200] [Batch 560/938] [D loss: 0.025595] [G loss: -13.133838]\n",
            "[Epoch 3/200] [Batch 565/938] [D loss: -0.101939] [G loss: -13.126101]\n",
            "[Epoch 3/200] [Batch 570/938] [D loss: -0.060319] [G loss: -13.140897]\n",
            "[Epoch 3/200] [Batch 575/938] [D loss: -0.065144] [G loss: -13.140297]\n",
            "[Epoch 3/200] [Batch 580/938] [D loss: -0.015660] [G loss: -13.150203]\n",
            "[Epoch 3/200] [Batch 585/938] [D loss: -0.044589] [G loss: -13.175200]\n",
            "[Epoch 3/200] [Batch 590/938] [D loss: -0.022106] [G loss: -13.170292]\n",
            "[Epoch 3/200] [Batch 595/938] [D loss: -0.035866] [G loss: -13.187267]\n",
            "[Epoch 3/200] [Batch 600/938] [D loss: -0.076628] [G loss: -13.057964]\n",
            "[Epoch 3/200] [Batch 605/938] [D loss: -0.119340] [G loss: -13.044106]\n",
            "[Epoch 3/200] [Batch 610/938] [D loss: -0.064371] [G loss: -13.078695]\n",
            "[Epoch 3/200] [Batch 615/938] [D loss: -0.050340] [G loss: -13.045811]\n",
            "[Epoch 3/200] [Batch 620/938] [D loss: -0.057112] [G loss: -13.075208]\n",
            "[Epoch 3/200] [Batch 625/938] [D loss: -0.047488] [G loss: -12.992775]\n",
            "[Epoch 3/200] [Batch 630/938] [D loss: -0.099394] [G loss: -13.021404]\n",
            "[Epoch 3/200] [Batch 635/938] [D loss: -0.009478] [G loss: -13.019341]\n",
            "[Epoch 3/200] [Batch 640/938] [D loss: -0.037326] [G loss: -12.998332]\n",
            "[Epoch 3/200] [Batch 645/938] [D loss: -0.034619] [G loss: -13.016129]\n",
            "[Epoch 3/200] [Batch 650/938] [D loss: -0.060761] [G loss: -13.138090]\n",
            "[Epoch 3/200] [Batch 655/938] [D loss: -0.050280] [G loss: -13.085673]\n",
            "[Epoch 3/200] [Batch 660/938] [D loss: -0.034900] [G loss: -12.999961]\n",
            "[Epoch 3/200] [Batch 665/938] [D loss: 0.018572] [G loss: -12.733480]\n",
            "[Epoch 3/200] [Batch 670/938] [D loss: -0.028421] [G loss: -12.930435]\n",
            "[Epoch 3/200] [Batch 675/938] [D loss: -0.017597] [G loss: -12.928686]\n",
            "[Epoch 3/200] [Batch 680/938] [D loss: -0.076809] [G loss: -12.958631]\n",
            "[Epoch 3/200] [Batch 685/938] [D loss: -0.102603] [G loss: -12.945196]\n",
            "[Epoch 3/200] [Batch 690/938] [D loss: -0.104961] [G loss: -12.951213]\n",
            "[Epoch 3/200] [Batch 695/938] [D loss: -0.142600] [G loss: -12.945942]\n",
            "[Epoch 3/200] [Batch 700/938] [D loss: -0.023176] [G loss: -12.936762]\n",
            "[Epoch 3/200] [Batch 705/938] [D loss: -0.172712] [G loss: -12.865163]\n",
            "[Epoch 3/200] [Batch 710/938] [D loss: -0.129328] [G loss: -12.764811]\n",
            "[Epoch 3/200] [Batch 715/938] [D loss: 0.020960] [G loss: -12.786732]\n",
            "[Epoch 3/200] [Batch 720/938] [D loss: -0.020575] [G loss: -12.830021]\n",
            "[Epoch 3/200] [Batch 725/938] [D loss: -0.053672] [G loss: -12.760746]\n",
            "[Epoch 3/200] [Batch 730/938] [D loss: 0.009938] [G loss: -12.815602]\n",
            "[Epoch 3/200] [Batch 735/938] [D loss: -0.018357] [G loss: -12.821505]\n",
            "[Epoch 3/200] [Batch 740/938] [D loss: -0.051452] [G loss: -12.888407]\n",
            "[Epoch 3/200] [Batch 745/938] [D loss: -0.070371] [G loss: -12.885207]\n",
            "[Epoch 3/200] [Batch 750/938] [D loss: -0.054349] [G loss: -13.050664]\n",
            "[Epoch 3/200] [Batch 755/938] [D loss: -0.006138] [G loss: -13.017262]\n",
            "[Epoch 3/200] [Batch 760/938] [D loss: -0.022112] [G loss: -13.123369]\n",
            "[Epoch 3/200] [Batch 765/938] [D loss: 0.028317] [G loss: -12.941335]\n",
            "[Epoch 3/200] [Batch 770/938] [D loss: -0.046356] [G loss: -13.091819]\n",
            "[Epoch 3/200] [Batch 775/938] [D loss: -0.053979] [G loss: -13.276782]\n",
            "[Epoch 3/200] [Batch 780/938] [D loss: -0.026423] [G loss: -13.356723]\n",
            "[Epoch 3/200] [Batch 785/938] [D loss: -0.000328] [G loss: -13.254708]\n",
            "[Epoch 3/200] [Batch 790/938] [D loss: -0.025555] [G loss: -13.338624]\n",
            "[Epoch 3/200] [Batch 795/938] [D loss: -0.010865] [G loss: -13.458502]\n",
            "[Epoch 3/200] [Batch 800/938] [D loss: -0.122723] [G loss: -13.482089]\n",
            "[Epoch 3/200] [Batch 805/938] [D loss: -0.077909] [G loss: -13.450864]\n",
            "[Epoch 3/200] [Batch 810/938] [D loss: -0.059496] [G loss: -13.511961]\n",
            "[Epoch 3/200] [Batch 815/938] [D loss: -0.088914] [G loss: -13.579832]\n",
            "[Epoch 3/200] [Batch 820/938] [D loss: -0.008710] [G loss: -13.639151]\n",
            "[Epoch 3/200] [Batch 825/938] [D loss: 0.004594] [G loss: -13.626759]\n",
            "[Epoch 3/200] [Batch 830/938] [D loss: -0.003846] [G loss: -13.685321]\n",
            "[Epoch 3/200] [Batch 835/938] [D loss: -0.056183] [G loss: -13.879061]\n",
            "[Epoch 3/200] [Batch 840/938] [D loss: -0.041713] [G loss: -13.876167]\n",
            "[Epoch 3/200] [Batch 845/938] [D loss: -0.077038] [G loss: -13.923033]\n",
            "[Epoch 3/200] [Batch 850/938] [D loss: -0.115907] [G loss: -13.968750]\n",
            "[Epoch 3/200] [Batch 855/938] [D loss: -0.015461] [G loss: -14.016200]\n",
            "[Epoch 3/200] [Batch 860/938] [D loss: -0.019337] [G loss: -14.074678]\n",
            "[Epoch 3/200] [Batch 865/938] [D loss: -0.009770] [G loss: -14.140284]\n",
            "[Epoch 3/200] [Batch 870/938] [D loss: -0.102614] [G loss: -14.168344]\n",
            "[Epoch 3/200] [Batch 875/938] [D loss: -0.151838] [G loss: -14.190970]\n",
            "[Epoch 3/200] [Batch 880/938] [D loss: 0.018221] [G loss: -14.088020]\n",
            "[Epoch 3/200] [Batch 885/938] [D loss: -0.112497] [G loss: -14.122583]\n",
            "[Epoch 3/200] [Batch 890/938] [D loss: 0.000566] [G loss: -14.154934]\n",
            "[Epoch 3/200] [Batch 895/938] [D loss: -0.071507] [G loss: -14.228941]\n",
            "[Epoch 3/200] [Batch 900/938] [D loss: 0.045810] [G loss: -14.143686]\n",
            "[Epoch 3/200] [Batch 905/938] [D loss: -0.082414] [G loss: -14.217834]\n",
            "[Epoch 3/200] [Batch 910/938] [D loss: -0.064286] [G loss: -14.259035]\n",
            "[Epoch 3/200] [Batch 915/938] [D loss: 0.005813] [G loss: -14.284617]\n",
            "[Epoch 3/200] [Batch 920/938] [D loss: -0.027290] [G loss: -14.290210]\n",
            "[Epoch 3/200] [Batch 925/938] [D loss: -0.075565] [G loss: -14.361057]\n",
            "[Epoch 3/200] [Batch 930/938] [D loss: -0.025485] [G loss: -14.328409]\n",
            "[Epoch 3/200] [Batch 935/938] [D loss: -0.044719] [G loss: -14.384592]\n",
            "[Epoch 4/200] [Batch 0/938] [D loss: 0.003274] [G loss: -14.284361]\n",
            "[Epoch 4/200] [Batch 5/938] [D loss: -0.129462] [G loss: -14.374094]\n",
            "[Epoch 4/200] [Batch 10/938] [D loss: 0.014786] [G loss: -14.372385]\n",
            "[Epoch 4/200] [Batch 15/938] [D loss: -0.057872] [G loss: -14.473655]\n",
            "[Epoch 4/200] [Batch 20/938] [D loss: -0.013490] [G loss: -14.538910]\n",
            "[Epoch 4/200] [Batch 25/938] [D loss: -0.056686] [G loss: -14.492705]\n",
            "[Epoch 4/200] [Batch 30/938] [D loss: -0.018976] [G loss: -14.475773]\n",
            "[Epoch 4/200] [Batch 35/938] [D loss: -0.094646] [G loss: -14.427513]\n",
            "[Epoch 4/200] [Batch 40/938] [D loss: -0.020056] [G loss: -14.383777]\n",
            "[Epoch 4/200] [Batch 45/938] [D loss: -0.050641] [G loss: -14.427033]\n",
            "[Epoch 4/200] [Batch 50/938] [D loss: -0.045207] [G loss: -14.396544]\n",
            "[Epoch 4/200] [Batch 55/938] [D loss: -0.044540] [G loss: -14.307970]\n",
            "[Epoch 4/200] [Batch 60/938] [D loss: -0.032290] [G loss: -14.329367]\n",
            "[Epoch 4/200] [Batch 65/938] [D loss: -0.112848] [G loss: -14.261462]\n",
            "[Epoch 4/200] [Batch 70/938] [D loss: -0.061266] [G loss: -14.160381]\n",
            "[Epoch 4/200] [Batch 75/938] [D loss: -0.028594] [G loss: -14.021563]\n",
            "[Epoch 4/200] [Batch 80/938] [D loss: -0.014949] [G loss: -14.047660]\n",
            "[Epoch 4/200] [Batch 85/938] [D loss: 0.010006] [G loss: -14.069504]\n",
            "[Epoch 4/200] [Batch 90/938] [D loss: -0.066566] [G loss: -14.095326]\n",
            "[Epoch 4/200] [Batch 95/938] [D loss: -0.016206] [G loss: -13.971000]\n",
            "[Epoch 4/200] [Batch 100/938] [D loss: -0.029869] [G loss: -13.929747]\n",
            "[Epoch 4/200] [Batch 105/938] [D loss: 0.045616] [G loss: -13.559647]\n",
            "[Epoch 4/200] [Batch 110/938] [D loss: -0.030050] [G loss: -13.696771]\n",
            "[Epoch 4/200] [Batch 115/938] [D loss: -0.010921] [G loss: -13.584384]\n",
            "[Epoch 4/200] [Batch 120/938] [D loss: -0.049313] [G loss: -13.562424]\n",
            "[Epoch 4/200] [Batch 125/938] [D loss: -0.021042] [G loss: -13.543571]\n",
            "[Epoch 4/200] [Batch 130/938] [D loss: 0.030835] [G loss: -13.322453]\n",
            "[Epoch 4/200] [Batch 135/938] [D loss: -0.033336] [G loss: -13.187561]\n",
            "[Epoch 4/200] [Batch 140/938] [D loss: -0.073759] [G loss: -13.196610]\n",
            "[Epoch 4/200] [Batch 145/938] [D loss: 0.019206] [G loss: -13.059639]\n",
            "[Epoch 4/200] [Batch 150/938] [D loss: 0.030643] [G loss: -12.866586]\n",
            "[Epoch 4/200] [Batch 155/938] [D loss: -0.038198] [G loss: -12.756950]\n",
            "[Epoch 4/200] [Batch 160/938] [D loss: -0.033948] [G loss: -12.681756]\n",
            "[Epoch 4/200] [Batch 165/938] [D loss: -0.000328] [G loss: -12.711305]\n",
            "[Epoch 4/200] [Batch 170/938] [D loss: 0.019058] [G loss: -12.574377]\n",
            "[Epoch 4/200] [Batch 175/938] [D loss: 0.034118] [G loss: -12.513127]\n",
            "[Epoch 4/200] [Batch 180/938] [D loss: -0.026645] [G loss: -12.534171]\n",
            "[Epoch 4/200] [Batch 185/938] [D loss: -0.008321] [G loss: -12.237658]\n",
            "[Epoch 4/200] [Batch 190/938] [D loss: -0.045259] [G loss: -11.969433]\n",
            "[Epoch 4/200] [Batch 195/938] [D loss: -0.005127] [G loss: -11.797493]\n",
            "[Epoch 4/200] [Batch 200/938] [D loss: -0.024337] [G loss: -11.844394]\n",
            "[Epoch 4/200] [Batch 205/938] [D loss: 0.020839] [G loss: -11.546907]\n",
            "[Epoch 4/200] [Batch 210/938] [D loss: 0.002617] [G loss: -11.417141]\n",
            "[Epoch 4/200] [Batch 215/938] [D loss: -0.065853] [G loss: -11.491529]\n",
            "[Epoch 4/200] [Batch 220/938] [D loss: 0.012631] [G loss: -10.842205]\n",
            "[Epoch 4/200] [Batch 225/938] [D loss: 0.011231] [G loss: -10.998618]\n",
            "[Epoch 4/200] [Batch 230/938] [D loss: -0.047081] [G loss: -11.145560]\n",
            "[Epoch 4/200] [Batch 235/938] [D loss: -0.040585] [G loss: -10.935024]\n",
            "[Epoch 4/200] [Batch 240/938] [D loss: 0.007174] [G loss: -10.807064]\n",
            "[Epoch 4/200] [Batch 245/938] [D loss: -0.058268] [G loss: -10.849161]\n",
            "[Epoch 4/200] [Batch 250/938] [D loss: -0.008639] [G loss: -10.753932]\n",
            "[Epoch 4/200] [Batch 255/938] [D loss: -0.065454] [G loss: -10.830710]\n",
            "[Epoch 4/200] [Batch 260/938] [D loss: -0.014394] [G loss: -10.769774]\n",
            "[Epoch 4/200] [Batch 265/938] [D loss: -0.049780] [G loss: -10.783605]\n",
            "[Epoch 4/200] [Batch 270/938] [D loss: 0.012938] [G loss: -10.666055]\n",
            "[Epoch 4/200] [Batch 275/938] [D loss: -0.025991] [G loss: -10.657765]\n",
            "[Epoch 4/200] [Batch 280/938] [D loss: -0.028429] [G loss: -10.699468]\n",
            "[Epoch 4/200] [Batch 285/938] [D loss: -0.003738] [G loss: -10.642385]\n",
            "[Epoch 4/200] [Batch 290/938] [D loss: 0.022814] [G loss: -10.516850]\n",
            "[Epoch 4/200] [Batch 295/938] [D loss: 0.001744] [G loss: -10.455053]\n",
            "[Epoch 4/200] [Batch 300/938] [D loss: -0.058249] [G loss: -10.424944]\n",
            "[Epoch 4/200] [Batch 305/938] [D loss: -0.082363] [G loss: -10.336313]\n",
            "[Epoch 4/200] [Batch 310/938] [D loss: -0.054082] [G loss: -10.303257]\n",
            "[Epoch 4/200] [Batch 315/938] [D loss: -0.031998] [G loss: -10.266843]\n",
            "[Epoch 4/200] [Batch 320/938] [D loss: -0.058514] [G loss: -10.240517]\n",
            "[Epoch 4/200] [Batch 325/938] [D loss: -0.055911] [G loss: -10.130938]\n",
            "[Epoch 4/200] [Batch 330/938] [D loss: -0.020471] [G loss: -10.095738]\n",
            "[Epoch 4/200] [Batch 335/938] [D loss: -0.025122] [G loss: -10.038386]\n",
            "[Epoch 4/200] [Batch 340/938] [D loss: -0.120994] [G loss: -10.052077]\n",
            "[Epoch 4/200] [Batch 345/938] [D loss: -0.027793] [G loss: -10.035088]\n",
            "[Epoch 4/200] [Batch 350/938] [D loss: -0.075873] [G loss: -10.044047]\n",
            "[Epoch 4/200] [Batch 355/938] [D loss: -0.054421] [G loss: -9.999117]\n",
            "[Epoch 4/200] [Batch 360/938] [D loss: 0.025193] [G loss: -9.785645]\n",
            "[Epoch 4/200] [Batch 365/938] [D loss: -0.005295] [G loss: -9.840117]\n",
            "[Epoch 4/200] [Batch 370/938] [D loss: -0.097130] [G loss: -9.772141]\n",
            "[Epoch 4/200] [Batch 375/938] [D loss: -0.027889] [G loss: -9.719421]\n",
            "[Epoch 4/200] [Batch 380/938] [D loss: -0.008519] [G loss: -9.656981]\n",
            "[Epoch 4/200] [Batch 385/938] [D loss: -0.017526] [G loss: -9.593372]\n",
            "[Epoch 4/200] [Batch 390/938] [D loss: -0.087788] [G loss: -9.653084]\n",
            "[Epoch 4/200] [Batch 395/938] [D loss: 0.043912] [G loss: -9.480296]\n",
            "[Epoch 4/200] [Batch 400/938] [D loss: -0.062571] [G loss: -9.582648]\n",
            "[Epoch 4/200] [Batch 405/938] [D loss: -0.053814] [G loss: -9.584560]\n",
            "[Epoch 4/200] [Batch 410/938] [D loss: -0.041306] [G loss: -9.527312]\n",
            "[Epoch 4/200] [Batch 415/938] [D loss: -0.031980] [G loss: -9.561570]\n",
            "[Epoch 4/200] [Batch 420/938] [D loss: -0.035273] [G loss: -9.587815]\n",
            "[Epoch 4/200] [Batch 425/938] [D loss: -0.048897] [G loss: -9.626458]\n",
            "[Epoch 4/200] [Batch 430/938] [D loss: -0.040151] [G loss: -9.574890]\n",
            "[Epoch 4/200] [Batch 435/938] [D loss: -0.043456] [G loss: -9.688070]\n",
            "[Epoch 4/200] [Batch 440/938] [D loss: -0.041438] [G loss: -9.654173]\n",
            "[Epoch 4/200] [Batch 445/938] [D loss: -0.041050] [G loss: -9.777788]\n",
            "[Epoch 4/200] [Batch 450/938] [D loss: -0.043426] [G loss: -9.797801]\n",
            "[Epoch 4/200] [Batch 455/938] [D loss: -0.064117] [G loss: -9.762300]\n",
            "[Epoch 4/200] [Batch 460/938] [D loss: -0.044621] [G loss: -9.714787]\n",
            "[Epoch 4/200] [Batch 465/938] [D loss: -0.054312] [G loss: -9.550725]\n",
            "[Epoch 4/200] [Batch 470/938] [D loss: -0.011406] [G loss: -9.526974]\n",
            "[Epoch 4/200] [Batch 475/938] [D loss: -0.043629] [G loss: -9.575028]\n",
            "[Epoch 4/200] [Batch 480/938] [D loss: -0.059323] [G loss: -9.564236]\n",
            "[Epoch 4/200] [Batch 485/938] [D loss: -0.014511] [G loss: -9.543217]\n",
            "[Epoch 4/200] [Batch 490/938] [D loss: -0.042636] [G loss: -9.521368]\n",
            "[Epoch 4/200] [Batch 495/938] [D loss: -0.014648] [G loss: -9.486989]\n",
            "[Epoch 4/200] [Batch 500/938] [D loss: 0.019805] [G loss: -9.402733]\n",
            "[Epoch 4/200] [Batch 505/938] [D loss: -0.089912] [G loss: -9.376586]\n",
            "[Epoch 4/200] [Batch 510/938] [D loss: -0.044130] [G loss: -9.351752]\n",
            "[Epoch 4/200] [Batch 515/938] [D loss: -0.076368] [G loss: -9.462135]\n",
            "[Epoch 4/200] [Batch 520/938] [D loss: 0.005263] [G loss: -9.191175]\n",
            "[Epoch 4/200] [Batch 525/938] [D loss: 0.020325] [G loss: -9.014744]\n",
            "[Epoch 4/200] [Batch 530/938] [D loss: -0.003148] [G loss: -8.839138]\n",
            "[Epoch 4/200] [Batch 535/938] [D loss: -0.078176] [G loss: -8.850949]\n",
            "[Epoch 4/200] [Batch 540/938] [D loss: -0.057839] [G loss: -8.757325]\n",
            "[Epoch 4/200] [Batch 545/938] [D loss: -0.030283] [G loss: -8.643187]\n",
            "[Epoch 4/200] [Batch 550/938] [D loss: -0.099523] [G loss: -8.696918]\n",
            "[Epoch 4/200] [Batch 555/938] [D loss: -0.020871] [G loss: -8.467605]\n",
            "[Epoch 4/200] [Batch 560/938] [D loss: 0.061593] [G loss: -8.158744]\n",
            "[Epoch 4/200] [Batch 565/938] [D loss: 0.025794] [G loss: -8.160340]\n",
            "[Epoch 4/200] [Batch 570/938] [D loss: -0.014246] [G loss: -7.973806]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}