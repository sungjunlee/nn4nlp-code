{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batched_enc_dec_pytorch.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "91dNex8ZWL7w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "67f61304-9f7e-4aad-a53d-6f206b8480dd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197731688,
          "user_tz": -540,
          "elapsed": 5435,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchtext\n",
        "!git clone https://github.com/neubig/nn4nlp-code.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.0)\r\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.2.3)\r\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.23.4)\r\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\r\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.4.16)\n",
            "fatal: destination path 'nn4nlp-code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W9qtRb6yWY3d",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "1992e5e9-768a-4ad7-ae00-25af26ed210b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197732465,
          "user_tz": -540,
          "elapsed": 744,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFr_zk1LWR5p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ea441f07-30c6-4165-81bf-47110300db7d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197733243,
          "user_tz": -540,
          "elapsed": 650,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#some of this code borrowed from Qinlan Shen's attention from the MT class last year\n",
        "#much of the beginning is the same as the text retrieval\n",
        "# format of files: each line is \"word1 word2 ...\" aligned line-by-line\n",
        "train_src_file = \"nn4nlp-code/data/parallel/train.ja\"\n",
        "train_trg_file = \"nn4nlp-code/data/parallel/train.en\"\n",
        "dev_src_file = \"nn4nlp-code/data/parallel/dev.ja\"\n",
        "dev_trg_file = \"nn4nlp-code/data/parallel/dev.en\"\n",
        "\n",
        "w2i_src = defaultdict(lambda: len(w2i_src))\n",
        "w2i_trg = defaultdict(lambda: len(w2i_trg))\n",
        "\n",
        "def read(fname_src, fname_trg):\n",
        "    \"\"\"\n",
        "    Read parallel files where each line lines up\n",
        "    \"\"\"\n",
        "    with open(fname_src, \"r\") as f_src, open(fname_trg, \"r\") as f_trg:\n",
        "        for line_src, line_trg in zip(f_src, f_trg):\n",
        "            #need to append EOS tags to at least the target sentence\n",
        "            sent_src = [w2i_src[x] for x in line_src.strip().split() + ['</s>']] \n",
        "            sent_trg = [w2i_trg[x] for x in ['<s>'] + line_trg.strip().split() + ['</s>']] \n",
        "            yield (sent_src, sent_trg)\n",
        "\n",
        "# Read the data\n",
        "train = list(read(train_src_file, train_trg_file))\n",
        "unk_src = w2i_src[\"<unk>\"]\n",
        "eos_src = w2i_src['</s>']\n",
        "w2i_src = defaultdict(lambda: unk_src, w2i_src)\n",
        "unk_trg = w2i_trg[\"<unk>\"]\n",
        "eos_trg = w2i_trg['</s>']\n",
        "sos_trg = w2i_trg['<s>']\n",
        "w2i_trg = defaultdict(lambda: unk_trg, w2i_trg)\n",
        "i2w_trg = {v: k for k, v in w2i_trg.items()}\n",
        "\n",
        "nwords_src = len(w2i_src)\n",
        "nwords_trg = len(w2i_trg)\n",
        "dev = list(read(dev_src_file, dev_trg_file))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSf5ryjaqRqT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "05b01e9a-dc00-41c7-904e-eac67e800c69",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197733866,
          "user_tz": -540,
          "elapsed": 467,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "EMBED_SIZE = 64\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0ApZPN1csnN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "c05ff1cf-dd0c-49da-ae4f-1d3290a46fbb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197734414,
          "user_tz": -540,
          "elapsed": 415,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVHSambpoHVE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "c470a714-d3c2-4905-cecb-7768f4a00d01",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197792768,
          "user_tz": -540,
          "elapsed": 515,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ParallelCorpus(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "    \n",
        "  def __getitem__(self, ix):\n",
        "    return torch.LongTensor(self.data[ix][0]), torch.LongTensor(self.data[ix][1])\n",
        "  \n",
        "def my_collate_fn(batch):\n",
        "  src, trg = zip(*batch)\n",
        "  src_len, trg_len = list(map(len, src)), list(map(len, trg))\n",
        "  src_maxlen, trg_maxlen = max(src_len), max(trg_len)\n",
        "  \n",
        "  src = torch.stack([F.pad(e, (0, src_maxlen-len(e))) for e in src])\n",
        "  trg = torch.stack([F.pad(e, (0, trg_maxlen-len(e))) for e in trg])\n",
        "  \n",
        "  return src, trg, torch.LongTensor(src_len), torch.LongTensor(trg_len)\n",
        "\n",
        "# my_collate_fn([train_corpus[i] for i in range(4)])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUhplRQvoT9X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "5fa6c506-40f2-49dd-bd18-726ccfdd917a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197795359,
          "user_tz": -540,
          "elapsed": 565,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_corpus = ParallelCorpus(train)\n",
        "train_loader = DataLoader(train_corpus, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, collate_fn=my_collate_fn)\n",
        "\n",
        "dev_corpus = ParallelCorpus(dev)\n",
        "dev_loader = DataLoader(dev_corpus, batch_size=BATCH_SIZE, shuffle=False, num_workers=1, collate_fn=my_collate_fn)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUyrNMJyqVjB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "a1b75bef-f202-43b7-be26-a0cc007cc10a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197795883,
          "user_tz": -540,
          "elapsed": 410,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Especially in early training, the model can generate basically infinitly without generating an EOS\n",
        "#have a max sent size that you end at\n",
        "MAX_SENT_SIZE = 50"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2O2nRqiIXE2r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b0df1586-c187-498f-b212-7ca10c8cd9e2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530197796522,
          "user_tz": -540,
          "elapsed": 441,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, embed_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, embed_size)\n",
        "    self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
        "  \n",
        "  def forward(self, x, x_len):\n",
        "    h0 = self.init_hidden(x_len.shape[0])\n",
        "    encoded = self.embedding(x)\n",
        "    output, _ = self.gru(encoded, h0)\n",
        "    return torch.stack([output[i, x_len[i]-1] for i in range(len(x_len))])\n",
        "    \n",
        "  def init_hidden(self, bs):\n",
        "    return torch.zeros(1, bs, self.hidden_size, device=device)\n",
        "  \n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, output_size, embed_size, hidden_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(output_size, embed_size)\n",
        "    self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "  \n",
        "  def forward(self, x, x_len, hidden):\n",
        "    output = self.embedding(x)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.out(output)\n",
        "    return output, hidden"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSPBW00BtJ0t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "189d26bf-dc54-4e6a-d967-2730042d6452",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530198280936,
          "user_tz": -540,
          "elapsed": 593,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = EncoderRNN(nwords_src, EMBED_SIZE, HIDDEN_SIZE).to(device)\n",
        "decoder = DecoderRNN(nwords_trg, EMBED_SIZE, HIDDEN_SIZE).to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n5stAQfqvuxi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d2e04369-1cc2-4fbe-d325-5c3deb77f66e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530198281596,
          "user_tz": -540,
          "elapsed": 435,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "trainer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoqKmsRjn5lK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "86ac000b-41a2-4ec9-a902-4b585f40eacf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530198676913,
          "user_tz": -540,
          "elapsed": 395180,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch_i in range(20):\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "  total_loss = 0.\n",
        "  for batch_i, (s, t, sl, tl) in enumerate(train_loader):\n",
        "    s, t, si, ti = s.to(device), t.to(device), sl.to(device), tl.to(device)\n",
        "    bs = s.shape[0]\n",
        "    t_in = t[:,:-1]\n",
        "    t_out = t[:, 1:]\n",
        "    encoded = encoder(s, sl)\n",
        "    decoded, hidden = decoder(t_in, tl, encoded.unsqueeze(0))\n",
        "    decoded = torch.cat([decoded[ix, :tl[ix]-1].view(-1, nwords_trg) for ix in range(bs)], 0)\n",
        "    t_out = torch.cat([t_out[ix, :tl[ix]-1].view(-1) for ix in range(bs)], 0)\n",
        "    loss = criterion(decoded, t_out)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    trainer.zero_grad()\n",
        "    loss.backward()\n",
        "    trainer.step()\n",
        "  \n",
        "  print(\"epoch {} | train loss {:5.4f}\".format(epoch_i, total_loss / len(train_loader)))\n",
        "  \n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "  dev_loss = 0.\n",
        "  for batch_i, (s, t, sl, tl) in enumerate(dev_loader):\n",
        "    s, t, si, ti = s.to(device), t.to(device), sl.to(device), tl.to(device)\n",
        "    bs = s.shape[0]\n",
        "    t_in = t[:,:-1]\n",
        "    t_out = t[:, 1:]\n",
        "    encoded = encoder(s, sl)\n",
        "    decoded, hidden = decoder(t_in, tl, encoded.unsqueeze(0))\n",
        "    decoded = torch.cat([decoded[ix, :tl[ix]-1].view(-1, nwords_trg) for ix in range(bs)], 0)\n",
        "    t_out = torch.cat([t_out[ix, :tl[ix]-1].view(-1) for ix in range(bs)], 0)\n",
        "    loss = criterion(decoded, t_out)\n",
        "    dev_loss += loss.item()\n",
        "  print(\"epoch {} | val loss {:5.4f}\".format(epoch_i, dev_loss / len(dev_loader)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 | train loss 5.3064\n",
            "epoch 0 | val loss 4.8202\n",
            "epoch 1 | train loss 4.4170\n",
            "epoch 1 | val loss 4.5080\n",
            "epoch 2 | train loss 4.0233\n",
            "epoch 2 | val loss 4.3865\n",
            "epoch 3 | train loss 3.7268\n",
            "epoch 3 | val loss 4.3373\n",
            "epoch 4 | train loss 3.4771\n",
            "epoch 4 | val loss 4.3153\n",
            "epoch 5 | train loss 3.2524\n",
            "epoch 5 | val loss 4.3187\n",
            "epoch 6 | train loss 3.0453\n",
            "epoch 6 | val loss 4.3423\n",
            "epoch 7 | train loss 2.8557\n",
            "epoch 7 | val loss 4.3697\n",
            "epoch 8 | train loss 2.6793\n",
            "epoch 8 | val loss 4.4174\n",
            "epoch 9 | train loss 2.5186\n",
            "epoch 9 | val loss 4.4596\n",
            "epoch 10 | train loss 2.3700\n",
            "epoch 10 | val loss 4.5049\n",
            "epoch 11 | train loss 2.2313\n",
            "epoch 11 | val loss 4.5617\n",
            "epoch 12 | train loss 2.1050\n",
            "epoch 12 | val loss 4.6232\n",
            "epoch 13 | train loss 1.9879\n",
            "epoch 13 | val loss 4.6945\n",
            "epoch 14 | train loss 1.8748\n",
            "epoch 14 | val loss 4.7524\n",
            "epoch 15 | train loss 1.7748\n",
            "epoch 15 | val loss 4.8228\n",
            "epoch 16 | train loss 1.6802\n",
            "epoch 16 | val loss 4.9006\n",
            "epoch 17 | train loss 1.5937\n",
            "epoch 17 | val loss 4.9615\n",
            "epoch 18 | train loss 1.5085\n",
            "epoch 18 | val loss 5.0572\n",
            "epoch 19 | train loss 1.4307\n",
            "epoch 19 | val loss 5.1177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AhYQeSVm6avG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d95e23a8-e3f0-4e16-dcc8-e6d51034ae76",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530198245944,
          "user_tz": -540,
          "elapsed": 925,
          "user": {
            "displayName": "Sungjun Lee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107995332831641667384"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 9 | loss 4.4261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H0E2M8PZ50WV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6j7z2TYAWiMJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def calc_loss(sents):\n",
        "    dy.renew_cg()\n",
        "\n",
        "    # Transduce all batch elements with an LSTM\n",
        "    src_sents = [x[0] for x in sents]\n",
        "    tgt_sents = [x[1] for x in sents]\n",
        "    src_cws = []\n",
        "\n",
        "    src_len = [len(sent) for sent in src_sents]        \n",
        "    max_src_len = np.max(src_len)\n",
        "    num_words = 0\n",
        "\n",
        "    for i in range(max_src_len):\n",
        "        src_cws.append([sent[i] for sent in src_sents])\n",
        "\n",
        "\n",
        "    #initialize the LSTM\n",
        "    init_state_src = LSTM_SRC_BUILDER.initial_state()\n",
        "\n",
        "    #get the output of the first LSTM\n",
        "    src_output = init_state_src.add_inputs([dy.lookup_batch(LOOKUP_SRC, cws) for cws in src_cws])[-1].output()\n",
        "    #now decode\n",
        "    all_losses = []\n",
        "\n",
        "    # Decoder\n",
        "    #need to mask padding at end of sentence\n",
        "    tgt_cws = []\n",
        "    tgt_len = [len(sent) for sent in sents]\n",
        "    max_tgt_len = np.max(tgt_len)\n",
        "    masks = []\n",
        "\n",
        "    for i in range(max_tgt_len):\n",
        "        tgt_cws.append([sent[i] if len(sent) > i else eos_trg for sent in tgt_sents])\n",
        "        mask = [(1 if len(sent) > i else 0) for sent in tgt_sents]\n",
        "        masks.append(mask)\n",
        "        num_words += sum(mask)\n",
        "\n",
        "\n",
        "\n",
        "    current_state = LSTM_TRG_BUILDER.initial_state().set_s([src_output, dy.tanh(src_output)])\n",
        "    prev_words = tgt_cws[0]\n",
        "    W_sm = dy.parameter(W_sm_p)\n",
        "    b_sm = dy.parameter(b_sm_p)\n",
        "\n",
        "    for next_words, mask in zip(tgt_cws[1:], masks):\n",
        "        #feed the current state into the \n",
        "        current_state = current_state.add_input(dy.lookup_batch(LOOKUP_TRG, prev_words))\n",
        "        output_embedding = current_state.output()\n",
        "\n",
        "        s = dy.affine_transform([b_sm, W_sm, output_embedding])\n",
        "        loss = (dy.pickneglogsoftmax_batch(s, next_words))\n",
        "        mask_expr = dy.inputVector(mask)\n",
        "        mask_expr = dy.reshape(mask_expr, (1,),len(sents))\n",
        "        mask_loss = loss * mask_expr\n",
        "        all_losses.append(mask_loss)\n",
        "        prev_words = next_words\n",
        "    return dy.sum_batches(dy.esum(all_losses)), num_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jQISLyUWl_P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generate(sent):\n",
        "    dy.renew_cg()\n",
        "\n",
        "    # Transduce all batch elements with an LSTM\n",
        "    sent_reps = [LSTM_SRC.transduce([LOOKUP_SRC[x] for x in src])[-1] for src, trg in sents]\n",
        "\n",
        "    dy.renew_cg()\n",
        "\n",
        "    # Transduce all batch elements with an LSTM\n",
        "    src = sent[0]\n",
        "    trg = sent[1]\n",
        "\n",
        "\n",
        "    #initialize the LSTM\n",
        "    init_state_src = LSTM_SRC_BUILDER.initial_state()\n",
        "\n",
        "    #get the output of the first LSTM\n",
        "    src_output = init_state_src.add_inputs([LOOKUP_SRC[x] for x in src])[-1].output()\n",
        "\n",
        "    #generate until a eos tag or max is reached\n",
        "    current_state = LSTM_TRG_BUILDER.initial_state().set_s([src_output, dy.tanh(src_output)])\n",
        "\n",
        "    prev_word = sos_trg\n",
        "    trg_sent = []\n",
        "    W_sm = dy.parameter(W_sm_p)\n",
        "    b_sm = dy.parameter(b_sm_p)\n",
        "\n",
        "    for i in range(MAX_SENT_SIZE):\n",
        "        #feed the previous word into the lstm, calculate the most likely word, add it to the sentence\n",
        "        current_state = current_state.add_input(LOOKUP_TRG[prev_word])\n",
        "        output_embedding = hidden_state.output()\n",
        "        s = dy.affine_transform([b_sm, W_sm, output_embedding])\n",
        "        probs = -dy.log_softmax(s).value()\n",
        "        next_word = np.argmax(probs)\n",
        "\n",
        "        if next_word == eos_trg:\n",
        "            break\n",
        "        prev_word = next_word\n",
        "        trg_sent.append(i2w_trg[next_word])\n",
        "    return trg_sent\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBtCQ1bcdml1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for ITER in range(100):\n",
        "  # Perform training\n",
        "  train.sort(key=lambda t: len(t[0]), reverse=True)\n",
        "  dev.sort(key=lambda t: len(t[0]), reverse=True)\n",
        "  train_order = create_batches(train, BATCH_SIZE) \n",
        "  dev_order = create_batches(dev, BATCH_SIZE)\n",
        "  train_words, train_loss = 0, 0.0\n",
        "  start = time.time()\n",
        "  for sent_id, (start, length) in enumerate(train_order):\n",
        "    train_batch = train[start:start+length]\n",
        "    my_loss, num_words = calc_loss(train_batch)\n",
        "    train_loss += my_loss.value()\n",
        "    train_words += num_words\n",
        "    my_loss.backward()\n",
        "    trainer.update()\n",
        "    if (sent_id+1) % 5000 == 0:\n",
        "      print(\"--finished %r sentences\" % (sent_id+1))\n",
        "  print(\"iter %r: train loss/word=%.4f, ppl=%.4f, time=%.2fs\" % (ITER, train_loss/train_words, math.exp(train_loss/train_words), time.time()-start))\n",
        "  # Evaluate on dev set\n",
        "  dev_words, dev_loss = 0, 0.0\n",
        "  start = time.time()\n",
        "  for sent_id, (start, length) in enumerate(dev_order):\n",
        "    dev_batch = dev[start:start+length]\n",
        "    my_loss, num_words = calc_loss(dev_batch)\n",
        "    dev_loss += my_loss.value()\n",
        "    dev_words += num_words\n",
        "    trainer.update()\n",
        "  print(\"iter %r: dev loss/word=%.4f, ppl=%.4f, time=%.2fs\" % (ITER, dev_loss/dev_words, math.exp(dev_loss/dev_words), time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}